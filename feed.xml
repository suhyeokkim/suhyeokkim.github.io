<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="ko">
  <generator uri="http://jekyllrb.com" version="3.9.0">Jekyll</generator>
  
  
  <link href="https://suhyeokkim.github.io/feed.xml" rel="self" type="application/atom+xml" />
  <link href="https://suhyeokkim.github.io/" rel="alternate" type="text/html" hreflang="ko" />
  <updated>2022-04-09T10:47:23+00:00</updated>
  <id>https://suhyeokkim.github.io//</id>

  
    <title type="html">Appocrypha</title>
  

  
    <subtitle>store limitless knowledges</subtitle>
  

  
    <author>
        <name>Su-Hyeok Kim</name>
      
      
    </author>
  

  
  
    <entry>
      
      <title type="html">Deferred Shading On Mobile</title>
      
      <link href="https://suhyeokkim.github.io/2021/05/12/deferred-shading-on-mobile" rel="alternate" type="text/html" title="Deferred Shading On Mobile" />
      <published>2021-05-12T00:00:00+00:00</published>
      <updated>2021-05-12T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2021/05/12/deferred-shading-on-mobile</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2021/05/12/deferred-shading-on-mobile">&lt;p&gt;VR을 제외한 PC 및 콘솔 플랫폼에선 보통은 deferred shading 을 많이 사용한다. 거의 대부분은 MRT를 사용하여 각각의 프레임 버퍼로 픽셀 데이터를 저장하고, 마지막 패스에서 이를 다시 참조하여 계산한다. 이 방식은 필자가 아는 것 기준으로 10년이 넘어서도 주가되는 방식이다.&lt;/p&gt;

&lt;p&gt;하지만 모바일 기기가 등장하고, 거의 대부분의 모바일 GPU 에서는 절대적으로 유닛 갯수가 부족하기 때문에 픽셀을 처리하는 ROP 유닛이 관여하는 부분을 타일로 나누어 &lt;em&gt;locality&lt;/em&gt; 를 이용하여 처리한다. (정점 처리는 그대로 간다. 그래서 절대적으로 정점의 한계는 명확하다.) 이 때문에 OpenGL ES 3.x 버젼이 현역인 때의 절대적인 문제점은 deferred shading 을 성능상의 문제로 사용할 수 없다는 점이였다. deferred shading 을 구현하는 방법은 무식하게 프레임버퍼를 크게 할당하여 하나하나 인코딩하는 방법이였는데, 픽셀을 타일 단위로 처리하는 방법을 가진 모바일 GPU 에서는 이전의 방법으로는 만족할만한 성능을 내기 어려웠다.&lt;/p&gt;

&lt;p&gt;그래서 2014/2015 년에 MALI 제품군과 몇몇 PowerVR 제품군에서 사용 가능한 &lt;em&gt;pixel local storage&lt;/em&gt; 를 OGLES 에 &lt;em&gt;multi-vendor extension&lt;/em&gt; 분류로 등록되었다. 사용 방법은 GLES 쉐이더 소스를 수정하면 쉽게 변경 가능하다. &lt;em&gt;deferred shading&lt;/em&gt; 을 사용하기 위한 구체적인 예시를 아래에 가져와보았다. 역시 2 패스로 이루어진다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     (1) Use the extension to write data.

    #version 300 es
    #extension GL_EXT_shader_pixel_local_storage : enable

    __pixel_localEXT FragDataLocal {
        layout(r11f_g11f_b10f) mediump vec3 normal;
        layout(rgb10_a2) highp vec4 color;
        layout(rgba8ui) mediump uvec4 flags;
    } gbuf;

    void main()
    {
        /* .... */
        gbuf.normal = v;
        gbuf.color = texture(sampler, coord);
        gbuf.flags = material_id;
    }
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위 코드에서는 입력받은 기하를 PLS 에 저장하고, 아래 코드에서는 PLS 에서 참조하여 합치는 작업을 수행한다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    (2) Use the extension to resolve the data.

    #version 300 es
    #extension GL_EXT_shader_pixel_local_storage : enable

    __pixel_localEXT FragDataLocal {
        layout(r11f_g11f_b10f) mediump vec3 normal;
        layout(rgb10_a2) highp vec4 color;
        layout(rgba8ui) mediump uvec4 flags;
    } gbuf;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;하지만 &lt;em&gt;pixel local storage&lt;/em&gt; 는 &lt;em&gt;ARB Extension&lt;/em&gt; 이 아니기 때문에 모든 벤더가 구현되었다고 볼 수 없고, 실제로 &lt;em&gt;adreno&lt;/em&gt; 제품군의 OpenGL 드라이버에는 구현되어 있지 않은 것으로 범용적으로는 쓰일 수 없는 것으로 보인다. OpenGL 드라이버를 사용하여 모바일 환경의 deffered 렌더링을 완벽하게 MRT 를 사용하여 최적화 할 수 없다.&lt;/p&gt;

&lt;p&gt;Vulkan 을 사용하여 deffered rendering 을 고안한 방법을 &lt;a href=&quot;https://www.khronos.org/assets/uploads/developers/library/2016-vulkan-devday-uk/6-Vulkan-subpasses.pdf&quot;&gt;khronos : Vulkan Subpasses&lt;/a&gt; 에서 볼 수 있다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://community.arm.com/developer/tools-software/graphics/b/blog/posts/pixel-local-storage-on-arm-mali-gpus&quot;&gt;Pixel Local Storage on ARM Mali GPUs&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.imgtec.com/Framework_DevGuide/topics/Tips_and_Tricks/Renderpass-PLS_Strategies/c_PVRFramework_subpasses_pls.html&quot;&gt;PowerVR Framework Tips and Tricks : Render pass/Pixel Local Storage (PLS) Strategies&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.apple.com/documentation/metal/gpu_features/understanding_gpu_family_4/about_imageblocks&quot;&gt;Apple Developer : About Imageblocks&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khronos.org/registry/OpenGL/extensions/EXT/EXT_shader_pixel_local_storage.txt&quot;&gt;khronos : EXT_shader_pixel_local_storage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khronos.org/registry/OpenGL/extensions/EXT/EXT_shader_pixel_local_storage2.txt&quot;&gt;khronos : EXT_shader_pixel_local_storage2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.khronos.org/assets/uploads/developers/library/2016-vulkan-devday-uk/6-Vulkan-subpasses.pdf&quot;&gt;khronos : Vulkan Subpasses&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="opengles" />
      
        <category term="deferred_shading" />
      

      

      
        <summary type="html">VR을 제외한 PC 및 콘솔 플랫폼에선 보통은 deferred shading 을 많이 사용한다. 거의 대부분은 MRT를 사용하여 각각의 프레임 버퍼로 픽셀 데이터를 저장하고, 마지막 패스에서 이를 다시 참조하여 계산한다. 이 방식은 필자가 아는 것 기준으로 10년이 넘어서도 주가되는 방식이다. 하지만 모바일 기기가 등장하고, 거의 대부분의 모바일 GPU 에서는 절대적으로 유닛 갯수가 부족하기 때문에 픽셀을 처리하는 ROP 유닛이 관여하는 부분을 타일로 나누어 locality 를 이용하여 처리한다. (정점 처리는 그대로 간다. 그래서 절대적으로 정점의 한계는 명확하다.) 이 때문에 OpenGL ES 3.x 버젼이 현역인 때의 절대적인 문제점은 deferred shading 을 성능상의 문제로 사용할 수 없다는 점이였다. deferred shading 을 구현하는 방법은 무식하게 프레임버퍼를 크게 할당하여 하나하나 인코딩하는 방법이였는데, 픽셀을 타일 단위로 처리하는 방법을 가진 모바일 GPU 에서는 이전의 방법으로는 만족할만한 성능을 내기 어려웠다. 그래서 2014/2015 년에 MALI 제품군과 몇몇 PowerVR 제품군에서 사용 가능한 pixel local storage 를 OGLES 에 multi-vendor extension 분류로 등록되었다. 사용 방법은 GLES 쉐이더 소스를 수정하면 쉽게 변경 가능하다. deferred shading 을 사용하기 위한 구체적인 예시를 아래에 가져와보았다. 역시 2 패스로 이루어진다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Open Gl Es Programming Tips Kor</title>
      
      <link href="https://suhyeokkim.github.io/2021/03/21/open-gl-es-programming-tips-kor" rel="alternate" type="text/html" title="Open Gl Es Programming Tips Kor" />
      <published>2021-03-21T00:00:00+00:00</published>
      <updated>2021-03-21T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2021/03/21/open-gl-es-programming-tips-kor</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2021/03/21/open-gl-es-programming-tips-kor">&lt;p&gt;※ &lt;a href=&quot;https://docs.nvidia.com/drive/drive_os_5.1.6.1L/nvvib_docs/index.html#page/DRIVE_OS_Linux_SDK_Development_Guide/Graphics/graphics_opengl.html&quot;&gt;docs.nvidia : OpenGL ES Programming Tips&lt;/a&gt;의 내용을 번역하는 포스팅입니다. 시간이 꽤 지난 내용으로 글의 내용은 현재 상황과 다를 수 있습니다. 또한 모든 내용이 번역되어 있지 않을 수도 있습니다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;This topic is for readers who have some experience programming OpenGL ES and want to improve the performance of their OpenGL ES application. It aims at providing recommendations on getting the most out of the API and hardware resources without diving into too many architectural details.&lt;/p&gt;

&lt;p&gt;해당 주제는 OpenGL ES 의 익숙한 경험을 가지고 있고 OpenGL ES 응용프로그램의 성능을 향상시키고 싶어하는 독자를 위해 작성되었습니다. 해당 문서는 아키텍쳐적인 디테일에 너무 들어가지 않고 API와 하드웨어 자원을 최대한 활용하는 방법을 제공하는 것에 초점이 맞춰져 있습니다.&lt;/p&gt;

&lt;h1&gt;프로그래밍 효율&lt;/h1&gt;

&lt;p&gt;Some of the recommendations in this topic are incompatible with each other. One must consider the trade-offs between CPU load, memory, bandwidth, shader processing power, precision, and image quality. Premature assumptions about the effectiveness of trade-offs should be avoided. The only definite answers come from benchmarking and looking at rendered images!&lt;/p&gt;

&lt;p&gt;이 토픽의 몇몇 사항들은 서로 호환되지 않습니다. 반드시 CPU 부하, 메모리, 대역폭, 쉐이더 처리 능력, 정확도, 이미지 퀄리티 사이의 trade-off 를 고려해야 합니다. trade-off의 효율에 대하여 섣부른 가정은 피해야 합니다. 오직 결정론적인 답은 벤치마킹과 렌더링된 이미지를 봄으로써 알 수 있습니다.&lt;/p&gt;

&lt;p&gt;The items below are not ordered according to importance or potential performance increase. The identifiers in parentheses exist only for reference.&lt;/p&gt;

&lt;p&gt;아래의 항목은 중요성 혹은 잠재적인 성능 향상에 대해 정렬되지 않았습니다. 레퍼런스를 위해 괄호안의 식별자만 제공됩니다.&lt;/p&gt;

&lt;h1&gt;상태&lt;/h1&gt;

&lt;p&gt;Inefficient management of GL state leads to increased CPU load that may limit the amount of useful work the CPU could be doing elsewhere. Reducing the number of times rendering is paused due to GL state change will increase the chance of realizing the potential throughput of the GPU. The main point in this section is: do not modify or query GL state unless absolutely necessarily.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GL state&lt;/em&gt; 의 비효율적인 관리는 CPU 부하를 증가시키고, 이는 어디서든 CPU의 유용한 일을 제한시키게 될 것입니다. &lt;em&gt;GL State&lt;/em&gt; 의 상태 변경을 위한 렌더링이 일시 중지되는 경우를 줄이는 것은 GPU의 잠재적인 처리량을 실현시킬 기회를 늘릴 수 있습니다. 이 섹션에서 중요한 점은, 완전히 필요한 경우가 아니라면 &lt;em&gt;GL state&lt;/em&gt; 를 바꾸거나 query하지 않는 것입니다.&lt;/p&gt;

&lt;h2&gt;쓸모없이 &lt;em&gt;GL State&lt;/em&gt; 를 변경하지 마십시오. (S1)&lt;/h2&gt;

&lt;p&gt;All relevant GL state should be initialized during application initialization and not in the main render loop. For instance, occasionally glClearDepthf, glColorMask, or glViewport finds its way into the application render loop even though the values passed to these functions are always constant. Other times they are set unconditionally in the loop, just in case their values have changed per frame. Only call these functions when the values actually do need to change. Additionally, do not automatically set state back to some predefined value (e.g., the GL defaults). That idiom might be useful while developing your application as it makes it easier to re-order pieces of rendering code, but it should not be done in production code without a very good reason.&lt;/p&gt;

&lt;p&gt;모든 관련된 &lt;em&gt;GL state&lt;/em&gt; 는 메인 렌더링 루프가 아닌 응용프로그램의 초기화 동안 초기화 되어야 합니다. 예를 들면, &lt;em&gt;glClearDepthf, glColorMask, glViewport&lt;/em&gt; 는 전달되는 값이 항상 상수이더라도, 렌더링 루프에 들어갑니다. 다른 때에 프레임별로 값이 달라지는 케이스만 고려하여 루프에서 조건없이 계속 세팅됩니다. 값이 진짜로 바뀔 때, 함수를 호출하십시오. 추가적으로, GL에 의해 미리 제공된 값으로 자동으로 &lt;em&gt;GL state&lt;/em&gt; 를 돌리지 마세요. 이는 당신의 응용 프로그램을 개발할 때 렌더링 코드 조각을 재정렬하기 쉽게 만들어주므로 유용하지만, 아주 중요한 이유 없이는 제품의 코드에 들어가서는 안됩니다.&lt;/p&gt;

&lt;h2&gt;렌더 루프에서 &lt;em&gt;GL state&lt;/em&gt; 쿼리를 피하십시오 (S2)&lt;/h2&gt;

&lt;p&gt;When a GL context is created, the state is initially well-defined. Every state variable has a default value that is described in the OpenGL ES specification (“State Tables”). Except when compiling shaders, determining available extensions, or the application needs to query implementation specific constants, there should be no need to query any GL state. These queries can almost always be done in initialization. Well-written applications check for GL errors in debug builds. If no errors are reported as a result of changing state, it is assumed that the changes are now part of the new GL state. For these two reasons, the current state is always known and you should almost never need to query any GL state in a loop. If an application frequently calls functions that begin with glIs* or glGet*, these calls should be tracked down and eliminated.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GL context&lt;/em&gt; 가 생성되었을 때, &lt;em&gt;GL state&lt;/em&gt; 는 초기에 잘 정의되어 있습니다. 모든 &lt;em&gt;GL state&lt;/em&gt; 의 변수는 OpenGL ES 스펙에(“State Tables”) 묘사되어 있는 기본 값으로 설정되어 있습니다. 쉐이더를 컴파일 할 때, 가능한 확장을 결정하는 때, 응용 프로그램이 특정 상수를 가져오는 구현이 필요할 때를 제외하면 &lt;em&gt;GL state&lt;/em&gt; 를 쿼리할 필요는 없습뇌다. 이 쿼리들은 초기화 과정에서 거의 끝나있기 때문 입니다. 잘 정의된 응용 프로그램은 디버그 빌드 시에 GL 에러를 체크합니다. 이러한 두가지 이유 덕분에 현재 상태는 언제나 알고 있고, 루프에서 GL 상태를 쿼리할 필요가 ‘절대’ 없습니다. 만약 응용 프로그램이 glIs&lt;em&gt;, glGet&lt;/em&gt; 같은 함수를 빈번하게 호출한다면, 추적하고 제거해야 합니다.&lt;/p&gt;

&lt;h2&gt;공유된 상태를 한번에 실행하십시오. (S3)&lt;/h2&gt;

&lt;p&gt;An efficient approach to reduce the number of state changes is batching together all draw calls that use the same state (shaders, blending, textures, etc.). For instance, not batching on the shader changes has the form:
&lt;em&gt;GL state&lt;/em&gt; 의 상태 변경을 줄이는 효과적인 접근 방법은 같은 상태를 공유하는(쉐이더, 블렌딩모드, 텍스쳐, 등..) &lt;em&gt;drawwcall&lt;/em&gt; 을 한번에 합쳐서 실행하는(&lt;em&gt;batch&lt;/em&gt;) 것입니다. 예를 들면 쉐이더 변화를 배칭하지 않은 것은 아래와 같은 형태를 띕니다:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[ UseProgram(21), DrawX1, UseProgram(59), DrawY1, UseProgram(21), DrawX2, UseProgram(59), DrawY2 ]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Batching on the shaders leads to an improvement (fewer shader changes):&lt;/p&gt;

&lt;p&gt;쉐이더로 배칭하면 다음과 같이 개선시킬 수 있습니다.(적은 쉐이더 변경):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[ UseProgram(21), DrawX1, DrawX2, UseProgram(59), DrawY1, DrawY2 ]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;It is quite effective to group draw calls based on the shader programs they use. Reprogramming the GPU by switching between shaders is a relatively costly operation. Within each batch, a further optimization can be made by grouping draw calls that use the same uniforms, texture objects and other state. Generating a log of all function calls into the OpenGL ES API is a good approach for revealing poor batching. A tool such as PerfHUDES can conveniently generate this log without rebuilding the GL application; no change to the source code is necessary.&lt;/p&gt;

&lt;p&gt;사용하는 쉐이더 프로그램을 기반으로 &lt;em&gt;drawcall&lt;/em&gt; 을 모으는 것은 꽤 효과적입니다. 쉐이더에 따른 변경으로 GPU를 재-프로그래밍 하는 것은 상대적으로 값 비싼 연산입니다. 같은 uniform, 같은 텍스쳐 오브젝트, 이외의 같은 상태를 가진 것끼리 묶는 각각의 &lt;em&gt;batch&lt;/em&gt; 를 통하여 더 나은 최적화를 할 수 있습니다. PerfHUDES 같은 도구는 GL 응용 프로그램을 다시 만드는 것 없이 편리하게 이런 로그를 만들 수 있어 소스 코드를 변경할 필요가 없습니다.&lt;/p&gt;

&lt;h2&gt;바인딩 할 때 오브젝트 별 상태를 반복하지 마십시오. (S4)&lt;/h2&gt;

&lt;p&gt;Recall that some state is bound to the object it affects. As that state is stored in the object, you do not need to repeat it when you rebind the object. A very common mistake is setting the texture parameters for filtering and wrapping every time a texture object is bound. Another common mistake is updating uniform variables that have not changed value since the last time the particular shader program was used. In particular, when batching opportunities are limited, repeating per object state generates enormously inefficient GL code that can easily have a measurable impact on framerate.&lt;/p&gt;

&lt;p&gt;다시 말하자면, 어떤 상태는 영향을 받는 오브젝트에 바인딩 되어 있습니다. 그 상태는 오브젝트의 상태에 저장되어 있으므로, 다시 오브젝트를 바인딩 할때, 이를 반복할 필요가 없습니다. 가장 일반적인 실수는 텍스쳐 오브젝트를 바인딩 할 때 모든 경우에 필터링과 래핑 텍스쳐 파라미터를 설정하는 것입니다. 다른 일반적인 실수는 특정 쉐이더가 마지막으로 사용되었고 값이 바뀌지 않았을 때, uniform 변수에 업데이트 하는 것입니다. 특히 배칭할 기회가 제한되어 있을 때, 오브젝트 상태를 반복하는 것은 프레임레이트에 관측가능한 임팩트를 쉽게 측정 가능한 방대한 비효율적인 GL 코드를 생성합니다.&lt;/p&gt;

&lt;h2&gt;backface culling 은 가능하면 켜십시오. (S5)&lt;/h2&gt;

&lt;p&gt;Always enable face culling whenever the back-faces are not visible. Rendering the back-faces of primitives is often not necessary.&lt;/p&gt;

&lt;p&gt;표면의 뒷면이 안보일 때는 언제나 &lt;em&gt;face culling&lt;/em&gt; 을 켜십시오. 프리미티브의 뒷면을 그리는건 거의 필요 없습니다.&lt;/p&gt;

&lt;p&gt;Note: The default GL state has backface culling disabled, so this is one state that should almost always be set during application initialization and be left enabled for the application lifetime.&lt;/p&gt;

&lt;p&gt;참고: 기본적인 &lt;em&gt;GL state&lt;/em&gt; 는 &lt;em&gt;backface culling&lt;/em&gt; 이 꺼져 있기에, 응용 프로그램을 초기화 할때 거의 대부분 한 상태에 이를 적용시켜야 하고 응용 프로그램이 켜진 동안에 항상 켜져 있어야 합니다.&lt;/p&gt;

&lt;h1&gt;기하&lt;/h1&gt;

&lt;p&gt;The amount of geometry, as well as the way it is transferred to the GL, can have a very large impact on both CPU and GPU load. If the application sends geometry inefficiently or too frequently, that alone can create a bottleneck on the CPU side that does not give the GPU enough data to work efficiently. Geometry must be submitted in sizable chunks to realize the potential of the GPU. At the same time, geometry should be minimally defined, stored on the server side, and it should be accessed in a way to get the most out of the two GPU caches that exist before and after vertices are transformed.&lt;/p&gt;

&lt;p&gt;기하의 양과 GL로 전송되는 방법은 CPU/GPU 부하에 아주 많은 영향을 끼친다. 만약에 응용프로그램이 기하를 비효율적으로 혹은 너무 자주 보낸다면, 그것 만으로도 CPU 쪽에서 GPU가 충분히 효율적으로 일하게에 불충분하게 전송하는 병목이 생길 수 있다. 기하는 반드시 GPU의 잠재적인 성능을 현실화하기 위해 큰 덩어리로 보내져야 합니다. 동시에 기하는 최소한으로 정의되어야 하며, 서버에 저장되어야 하고, 정점이 변환된 전후에 존재하는 두 GPU 캐시를 최대한 활용하는 방법으로 엑세스 되어야 합니다.&lt;/p&gt;

&lt;h2&gt;인덱스된 프리미티브를 이용하십시오. (G1)&lt;/h2&gt;

&lt;p&gt;The vertex processing engine contains a cache where previously transformed vertices are stored. It is called Post-TnL vertex cache. Taking full advantage of this cache can lead to very large performance improvement when vertex processing is the bottleneck. To fully utilize it, it is necessary for the GPU to be able to recognize previously transformed vertices. This can only be accomplished by specifying indexed primitives for the geometry. However, for any non-trivial geometry the optimal order of indices will not be obvious to the programmer. If some geometry is complex, and the application bottleneck is vertex processing, then look into computing a vertex order that maximizes the hit ratio of the Post TnL cache. The topic has been thoroughly studied for years and even simple greedy algorithms can provide a substantial performance boost. Good results have been reported with the algorithm described at the below locations.&lt;/p&gt;

&lt;p&gt;정점 처리 엔진은 이전에 변환된 정점을 저장하는 캐시를 가지고 있습니다. 이는 Post-T&amp;amp;L 정점 캐시로 불립니다. 이 캐시를 최대한으로 이용하는 것은 버텍스 처리에 병목이 있을 때 매우 큰 성능 향상을 이뤄낼 수 있습니다. 최대한 사용하기 위해, GPU에서는 이전에 변환된 정점을 확인하는 것이 필요합니다. 이는 기하를 위해 인덱싱된 프리미티브를 명시하는 것으로 이뤄질 수 있습니다. 하지만 어떤 중요한 가히를 위해 인덱스의 최적화된 순서는 프로그래머에겐 중요하지 않을 수 있습니다. 만약 어떤 기하가 복잡하고 응용 프로그램이 정점 처리에 병목이 있다면 Post T&amp;amp;L 캐시의 히트율을 최대화 하기 위해 정점의 순서를 살펴보세요. 이 토픽은 몇년간 전체적으로 연구되었고, 심지어 간단한 그리디 알고리즘으로 실질적인 성능 향상을 제공합니다. 아래 언급된 알고리즘은 좋은 결과를 보고한 적 있습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;document&lt;/th&gt;
      &lt;th&gt;URL to latest&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Linear-Speed Vertex Cache Optimisation, by Tom Forsyth, RAD Game Tools (28th September 2006)&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;https://tomforsyth1000.github.io/papers/fast_vert_cache_opt.html&quot;&gt;URL&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;There is a free implementation of the algorithm in a library called vcacne.&lt;/p&gt;

&lt;p&gt;이는 vcacne 이라는 라이브러리에 무료로 제공되어 있습니다.&lt;/p&gt;

&lt;p&gt;Note: The number of vertex attributes and the size of each attribute may determine the efficiency of this cache—it has storage for a fixed number of bytes or active attributes, not a fixed number of vertices. A lot of attribute data per vertex increases the risk of cache misses, resulting in potentially redundant transformations of the same vertices.&lt;/p&gt;

&lt;p&gt;참고:  많은 버텍스 어트리뷰트와 각각의 어트리뷰트의 크기는 이 캐시의 효율성을 결정할 것입니다―이는 고정된 수의 정점의 갯수가 아닌 고정된 바이트 혹은 활성된 어트리뷰트를 가지고 있기 때문입니다. 버텍스별 많은 어트리뷰트 데이터는 캐시 미스의 리스크를 증가시키며, 잠재적으로 같은 정점의 불필요한 변환을 일으킵니다.&lt;/p&gt;

&lt;h2&gt;버텍스 어트리뷰트의 크기와 그 갯수를 줄이십시오. (G2)&lt;/h2&gt;

&lt;p&gt;It is important to use an appropriate attribute size and minimize the number of components to avoid wasting memory bandwidth and to increase the efficiency of the cache that stores pre-transformed vertices. This cache is called Pre-TnL vertex cache. For instance, you rarely need to specify attributes in 32 bit FLOATs. It might be possible to define the object-space geometry using 3 BYTEs per vertex for a simple object, or 3 SHORTs for a more complex or larger object. If the geometry requires floating-point representation, half-floats (available in extension OES_vertex_half_float.txt) may be sufficient. Per vertex colors are accurately stored with 3 x BYTEs with a flag to normalize in VertexAttributePointer. Texture coordinates can sometimes be represented with BYTEs or SHORTs with a flag to normalize (if not tiling).&lt;/p&gt;

&lt;p&gt;메모리 대역폭을 낭비하는 것을 피하고, 변환 이전의 정점을 저장하기 위한 캐시의 효율을 높이기 위해 적절한 어트리뷰트 사이즈의 사용 및 그 수를 줄이는 것은 중요한 작업입니다. 이 캐시는 Pre T&amp;amp;L 정점 캐시라고 불리는데, 예를 들어, 32비트 부동소수점을 사용하는 일은 거의 없습니다. 보통 오브젝트 공간 기하를 간단한 오브젝트를 정점별로 3개의 BYTE를 사용하거나 복잡한 오브젝트의 경우 3개의 SHORT를 사용합니다. 만약에 기하가 부동소수점 표현이 필요하다면 half-precision 부동소수점이면 충분할 것입니다.(available in extension &lt;em&gt;OES_vertex_half_float.txt&lt;/em&gt;) 정점별 색은 정확하게 정규화하기 위한 &lt;em&gt;VertexAttributepointer&lt;/em&gt; 플래그와 함께 3개의 BYTE에 저장합니다. 텍스쳐 좌표는 종종 정규화하기 위한 플래그와 함께 몇개의 BYTE나 몇개의 SHORT로 표현됩니다. (타일링 하지 않는 경우)&lt;/p&gt;

&lt;p&gt;Note: The exception case that normalizing texture coordinates is not necessary if they are only used to sample a cube map texture.
참고: 예외적인 케이스는 큐브맵 텍스쳐를 샘플링 할 때만 텍스쳐 좌표가 정규화가 필요 없는 경우입니다.&lt;/p&gt;

&lt;p&gt;Vertex normals can often be represented with 3 SHORTs (in a few cases, such as for cuboids, even as 3 BYTEs) and these should be normalized. Normals can even be represented with 2 components if the direction (sign) of the normal is implicit, given its length is known to be 1. The remaining coordinate can be derived in a vertex shader (e.g. z = SQRT(1 - x * x + y * y)) if memory or bandwidth (rather than vertex processing) is a likely bottleneck.&lt;/p&gt;

&lt;p&gt;정점 법선은 종종 3개의 SHORT 표현되고 (몇개의 경우, cuboid의 경우, 3 BYTE로 충분합니다.) 정규화 되어야 합니다. 심지어 법선은 방향인(부호화된) 경우 길이가 1이므로 두 컴포넌트로 표현될 수 있습니다. 만약 메모리나 대역폭이 병목인 경우 남은 컴포넌트는 버텍스 쉐이더에서 계산될 수 있습니다.&lt;/p&gt;

&lt;p&gt;An optimal OpenGL ES application will take advantage of any characteristics specific to the geometry. For instance, a smooth sphere uses the normalized vertex coordinates as normal—these are trivially computed in a vertex shader. It is important to benchmark intermediate results to ensure the vertex processing engine is not already saturated. Finally remember, if some attribute for a primitive or a number of primitives is constant for the same draw call, then disable the particular vertex attribute index and set the constant value with &lt;em&gt;VertexAttrib&lt;/em&gt; instead of replicating the data.&lt;/p&gt;

&lt;p&gt;최적의 OpenGL ES 응용 프로그램은 기하에 대한 모든 세부적인 특성을 이용합니다. 예를 들어 매끄러운 구는 정규화된 정점 위치를 법선으로 사용 가능하고―이는 보통 정점 쉐이더에서 계산됩니다. 정점 처리 엔진이 아직 과부하 되지 않은 경우를 보장하가 위해 중간 결과를 벤치마크 하는 것은 중요합니다. 마지막으로 기억할 것은 어떤 혹은 다수의 프리미티브를 위한 어트리뷰트가 같은 &lt;em&gt;drawcall&lt;/em&gt; 에서 상수라면, 그 정점 어트리뷰트 인덱스를 비활성화 하고 데이터를 복사하는 대신 &lt;em&gt;VertexAttrib&lt;/em&gt; 와 함께 상수 값으로 설정하는 것입니다.&lt;/p&gt;

&lt;h2&gt;정점 어트리뷰트를 압축하십시오. (G3)&lt;/h2&gt;

&lt;p&gt;Vertex attributes normally have different sets of attributes that are completely unrelated. Unlike uniform and varying variables in shader programs, vertex attributes do not get automatically packed, and the number of vertex attributes is a limited resource. Failure to pack these attributes together may lead to limitations sooner than expected. It is more efficient to pack the components into fewer attributes even though they may not be logically related. For instance, if each vertex comes with two sets of texture coordinates for multi-texturing, these can often be combined these into one attribute with four components instead of two attributes with two components. Unpacking and swizzling components is rarely a performance consideration.&lt;/p&gt;

&lt;p&gt;정점 어트리뷰트는 보통 서로 완전히 상관없는 다른 어트리뷰트 집합을 가집니다. 쉐이더 프로그램 내의 &lt;em&gt;uniform&lt;/em&gt; 과 &lt;em&gt;varying&lt;/em&gt; 변수와는 다르게, 정점 어트리뷰트는 자동으로 압축되어지지 않고, 버텍스 어트리뷰트의 크기는 제한된 자원입니다. 이 어트리뷰트들을 압축하는 것에 실패는 예상한 바와 다르게 빠르게 제한이 발생할 수 있습니다. 논리적으로 관련되지 않은 것이라도, 컴포넌트들을 압축하여 적은 어트리뷰트를 사용하는 것은 더 효율적입니다. 예를 들어, 각각의 정점에 여러 텍스쳐를 사용하기 위해 두개의 텍스쳐 좌표를 사용한다고 가정한다면, 두 컴포넌트를 위해 두 어트리뷰트를 사용하는 것 보다, 하나의 어트리뷰트에 4개의 컴포넌트를 결합하는 경우가 종종 있습니다. 압축을 풀고, 컴포넌트를 뒤섞는 것은 대부분 고려되지 않습니다.&lt;/p&gt;

&lt;h2&gt;적절한 정점 어트리뷰트 레이아웃을 선택하세요. (G4)&lt;/h2&gt;

&lt;p&gt;There are two commonly used ways of storing vertex attributes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Array of structures&lt;/li&gt;
  &lt;li&gt;Structures of arrays&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;An &lt;strong&gt;array of structures&lt;/strong&gt; stores the attributes for a given vertex sequentially with an appropriate offset for each attribute and a non-zero stride. The stride is computed from the number of attribute components and their sizes. An array of structures is the preferred way of storing vertex attributes due to more efficient memory access. If the vertex attributes are constant (not updated in the render loop) there is no question that an array of structures is the preferred layout.&lt;/p&gt;

&lt;p&gt;보통 두 방법으로 정점 어트리뷰트를 저장합니다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;구조체의 배열&lt;/li&gt;
  &lt;li&gt;배열의 구조체&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;구조체의 배열&lt;/strong&gt; 은 주어진 정점을 각각의 어트리뷰트에 적절한 오프셋과 &lt;em&gt;non-zero stride&lt;/em&gt; 와 함께 주어진 정점을 순차적으로 저장합니다. 이 &lt;em&gt;stride&lt;/em&gt; 는 어트리뷰트의 갯수와 각각의 크기에 따라 계산됩니다. &lt;strong&gt;구조체의 배열&lt;/strong&gt; 은 정점 어트리뷰트를 저장하는 더 효율적인 메모리 접근으로 선호되는 방법입니다. 만약에 정점 어트리뷰트가 상수라면(렌더 루프에서 업데이트 되지 않는다면) 당연히 &lt;strong&gt;구조체의 배열&lt;/strong&gt; 은 선호되는 레이아웃 입니다.&lt;/p&gt;

&lt;p&gt;In contrast, a &lt;strong&gt;structure of arrays&lt;/strong&gt; stores the vertex attributes in separate buffers using the same offset for each attribute and a stride of zero. This layout forces the GPU to jump around and fetch from different memory locations as it assembles the needed attributes for each vertex. The structure of arrays layout is therefore less efficient than an array of structures in most cases. The only time to consider a structure of arrays layout is if one or more attributes must be updated dynamically. Strided writes in array of structures can be expensive relative to the number of bytes modified. In this scenario, the recommendation is to partition the attributes such that constant and dynamic attributes can be read and written sequentially, respectively. The attributes that remain constant should be stored in an array of structures. The attributes that are updated dynamically should be stored in smaller separate buffer objects (or perhaps just a single buffer if the attributes are updated with the same frequency).&lt;/p&gt;

&lt;p&gt;반면에 &lt;strong&gt;배열의 구조체&lt;/strong&gt; 는 정점 어트리뷰트를 같은 어트리뷰트 오프셋과 &lt;em&gt;zero stride&lt;/em&gt; 으로 각각의 다른 버퍼에 저장합니디ㅏ. 이 레이아웃은 필요한 정점별 어트리뷰트를 조합하기 위해 GPU가 다른 메모리 위치에 점프하여 가져오게 만듭니다. &lt;strong&gt;배열의 구조체&lt;/strong&gt; 레이아웃은 그러므로 &lt;strong&gt;구조체의 배열&lt;/strong&gt; 보다 대부분의 경우에 비효율적입니다. 오직 &lt;strong&gt;배열의 구조체&lt;/strong&gt; 를 고려해야할 때는 하나 혹은 여러개의 어트리뷰트가 동적으로 업데이트 될 때 입니다. &lt;strong&gt;배열의 구조체&lt;/strong&gt; 에서 &lt;em&gt;strided&lt;/em&gt; 쓰기는 얼마만큼의 바이트가 수정된 만큼 비싸질 수 있습니다. 이 시나리오에서 추천할 방법은, 순차적으로 읽기/쓰기가 가능하도록 동적인 어트리뷰트와 정적인 어트리뷰트를 나누는 것입니다. 정적으로 남은 어트리뷰트는 __구조체의 배열__에 저장합니다. 동적으로 업데이트되는 어트리뷰트는 비교적 적인 분리된 버퍼 오브젝트에 저장되어야 합니다.(혹은 같은 주기로 업데이트 될 때 같은 버퍼에 저장합니다.)&lt;/p&gt;

&lt;h2&gt;일관적인 시계/반시계 순서를 사용하십시오. (G5)&lt;/h2&gt;

&lt;p&gt;The geometry winding (clockwise or counter-clockwise) should be determined up front and defined in code. The geometry face that is culled by GL can be changed with the FrontFace function, but having to switch back and forth between winding for different geometry batches during rendering is not optimal for performance and can be avoided in most cases.&lt;/p&gt;

&lt;p&gt;기하 감기(시계 혹은 반시계 방향)는 반드시 미리 코드에서 정의되어야 합니다. GL에서 컬링된 기하 표면은 FrontFace 함수를 통하여 변경될 수 있지만 렌더링 중에 다른 기하 &lt;em&gt;batch&lt;/em&gt; 를 위해 앞뒤를 바꾸는 것은 성능에 최적이 아니며, 대부분의 경우 피할 수 있습니다.&lt;/p&gt;

&lt;h2&gt;항상 버텍스, 인덱스 버퍼를 사용하십시오. (G6)&lt;/h2&gt;

&lt;p&gt;Recall that vertices for geometry can either be sourced from application memory every time it is rendered or from buffers in graphics memory where it has been stored previously. The same applies to vertex array indices. To achieve good performance, you should never continuously source the data from application memory with DrawArrays. Buffer objects should always be used to store both geometry and indices. Check that no code is calling DrawArrays, and that no code is calling DrawElements without a buffer bind.
The default buffer usage flag when allocating buffer objects is &lt;strong&gt;STATIC_DRAW&lt;/strong&gt;. In many cases this will lead to fastest access.
Note: &lt;strong&gt;STATIC_DRAW&lt;/strong&gt; does not mean one can never write to the buffer (although any writing to a buffer should always be avoided as much as possible). A &lt;strong&gt;STATIC_DRAW&lt;/strong&gt; flag may in fact be the appropriate usage flags, even if the buffer contents are updated every few frames. Only after careful benchmarking and arriving at conclusive results should changing the usage flag to one of the alternatives (&lt;strong&gt;DYNAMIC_DRAW&lt;/strong&gt; or &lt;strong&gt;STREAM_DRAW&lt;/strong&gt;) be considered.&lt;/p&gt;

&lt;p&gt;기하를 위한 정점들은 응용 프로그램 메모리에서 어느 때나 렌더링하기 위해, 그래픽 메모리에서 이전에 저장된 것을 위해 참조됩니다. 이는 인덱스 버퍼에도 적용됩니다. 좋은 성능을 얻기 위해서, 당신은 DrawArray를 사용하여 응용 프로그램 메모리에서 연속적으로 참조하면 절대 안됩니다. 버퍼 오브젝트는 언제나 기하와 인덱스를 저장하기위해 사용되어야 합니다. DrawArrays를 사용하는 코드가 없는지 확인하고, 버퍼 바인딩 없이 DrawElements를 호출하는 코드가 없는지 확인하세요. 할당 시 버퍼 오브젝트의 디폴트 버퍼 사용 플래그는 &lt;strong&gt;STATIC_DRAW&lt;/strong&gt; 입니다.&lt;/p&gt;

&lt;p&gt;참고 : &lt;strong&gt;STATIC_DRAW&lt;/strong&gt; 는 버퍼에 한번도 쓰지 않을 수 있다는 것을 의미하지 않습니다.(모든 버퍼에 쓰기는 최대한 피해야 함에도 불구하고) 심지어 버퍼의 내용이 모든 몇 프레임에 업데이트 되더라도, &lt;strong&gt;STATIC_DRAW&lt;/strong&gt; 플래그는 적절한 사용 플래그가 될 것입니다. 오직 조심스러운 벤치마킹과 이의 결과를 통한 추론이 고려된 여러 대안 중의 하나로 바꾸어야 합니다.(&lt;strong&gt;DYNAMIC_DRAW&lt;/strong&gt; or &lt;strong&gt;STREAM_DRAW&lt;/strong&gt;)&lt;/p&gt;

&lt;h2&gt;기하를 적은 버퍼와 드로우콜로 묶으십시오.(&lt;em&gt;batch&lt;/em&gt;) (G7)&lt;/h2&gt;

&lt;p&gt;There are only so many draw calls, or batches of geometry, that can be submitted to GL before the application becomes CPU bound. Each draw call has an overhead that is more or less fixed. Therefore, it is very important to increase the sizes of batches whenever possible. There does not need to be a one-to-one correspondence between a draw call and a buffer—a large vertex buffer can store geometry with a similar layout for multiple models. One or more index buffers can be used to select the subset of vertices needed from the vertex buffer. A common mistake is to have too many small buffers, leading to too many draw calls and thus high CPU load. If the number of draw calls issued in any given frame goes into many hundreds or thousands, then it is time to consider combining similar geometry in fewer buffers and use appropriate offsets when defining the attribute data and creating the index buffer.
Unconnected geometry can be stitched together with degenerate triangles (alternatively, by using extension NV_primitive_restart2 when available). Degenerate triangles are triangles where two or more vertices are coincident leading to a null surface. These are trivially rejected and ignored by the GPU. The benefit from stitching together geometry with degenerate triangles, such that fewer and larger buffers are needed, tends to outweigh the minor overhead of sending degenerates triangles down the pipeline. If geometry batches are being broken up to bind different textures, then look at combining several images into fewer textures (T5).&lt;/p&gt;

&lt;p&gt;응용 프로그램이 CPU 바운드에 걸리기 전에는, 오직 GL에 의해 제공된 수많은 드로우콜 혹은 기하의 &lt;em&gt;batch&lt;/em&gt; 돌이 있습니다. 각각의 드로우콜은 더 많거나 적게 고정된 오버헤드를 가지고 있습니다. 그러므로 가능한 만큼 &lt;em&gt;batch&lt;/em&gt; 들의 크기를 늘리는 것은 굉장히 중요합니다. 버퍼와 드로우콜 사이에 일대일 상관관계는 필요하지 않고―큰 정점 버퍼는 같은 레이아웃의 여러 모델을 저장할 수 있습니다. 하나 혹은 그 이상의 인덱스 버퍼는 정점 버퍼에서 필요한 하위의 정점을 선택하도록 사용합니다. 일반적인 실수는 수많은 작은 버퍼를 가지는 것입니다. 이는 수많은 드로우 콜, 높은 CPU 부하로 이어집니다. 만약 수많은 &lt;em&gt;drawcall&lt;/em&gt; 이 주어진 프레임에 주어지고, 그 프레임이 수백,수천만큼 이어진다면, 그때는 비슷한 기하를 몇개의 버퍼로 합치고, 어트리뷰트 데이터에 적절한 오프셋을 사용하고, 인덱스 버퍼를 만들어야 합니다. 연결되지 않은 기하는 &lt;em&gt;degenerate triangle&lt;/em&gt; 을 통해 붙여질 수 있습니다.(대안으로, NV_primitive_restart2 를 사용할 수 있습니다.) &lt;em&gt;degenerate triangle&lt;/em&gt; 은 두 혹은 더 많은 정점이 없는 표면(&lt;em&gt;null surface&lt;/em&gt;)에 일치하는 삼각형 입니다.이는 보통 GPU에 의해 거부되거나 무시됩니다. 기하를 &lt;em&gt;degenerate triangle&lt;/em&gt; 을 통해 붙이는 것의 장점은, 적은 갯수의 더 큰 버퍼가 필요할 때, &lt;em&gt;degenerate triangle&lt;/em&gt; 의 부하를 능가하는 경향이 있기 때문입니다. 만약 기하 &lt;em&gt;batch&lt;/em&gt; 들이 다른 텍스쳐를 가지고 있어 부서진다면, 그때는 여러 텍스쳐럴 더 적은 텍스쳐로 합치는 것을 보세요. (T5)&lt;/p&gt;

&lt;h2&gt;인덱스를 위해 가장 적지만 가능한 데이터를 사용하십시오. (G8)&lt;/h2&gt;

&lt;p&gt;When the geometry uses relatively few vertices, an index buffer should specify vertices using only UNSIGNED_BYTE instead of UNSIGNED_SHORT (or an even larger integer type if the ES2 implementation supports it). Count the number of unique vertices per buffer and choose the right data type. When batching geometry for several unrelated models into fewer buffer objects (G7), then a larger data type for the indices may be required. This is not a concern compared to the larger performance benefits of batching.&lt;/p&gt;

&lt;p&gt;기하가 상대적으로 작은 정점들을 사용할 때, 인덱스 버퍼에서 버텍스의 인덱스를 표현할 때 UNSIGNED_SHORT 대신 UNSIGNED_BYTE를 사용하세요.(혹은 ES2 구현이 제공하는 더 큰 정수 타입). 버퍼별 유일한 버텍스를 세고 적절한 데이터 타입을 선택하세요. 여러 관련되지 않은 모델를 위해 적은 버퍼 오브젝트에 있는 기하를 &lt;em&gt;batch&lt;/em&gt; 할 때, 더 큰 데이터 타입의 인덱스가 필요할 것 입니다. 이는 &lt;em&gt;batch&lt;/em&gt; 로 얻을 더 나은 성능과 비교하면 걱정할 것이 아닙니다.&lt;/p&gt;

&lt;h2&gt;렌더링 루프에서 새로운 버퍼를 할당하는 것을 피하십시오. (G9)&lt;/h2&gt;

&lt;p&gt;If the application frequently updates the geometry, then allocate a set of sufficiently large buffers when the application initializes. A BufferData call with a NULL data pointer will reserve the amount of memory you specify. This eliminates the time spent waiting for an allocation to complete in the rendering loop. Reusing pre-allocated buffers also helps to reduce memory fragmentation.&lt;/p&gt;

&lt;p&gt;만약 응용 프로그램이 자주 기하를 업데이트 한다면, 그때는 충분히 큰 버퍼 세트를 응용 프로그램의 초기화시 할당하세요. null 데이터 포인터와 함께 &lt;em&gt;BufferData&lt;/em&gt; 호출은 당신이 명시한 메모리를 예약할 수 있습니다. 이는 렌더링 루프에서 할당을 완료하기 위한 시간을 제거합니다. 미리 할당한 버퍼의 재사용은 메모리 파편화를 줄이는데 도움이 됩니다.&lt;/p&gt;

&lt;p&gt;Note: Writing to a buffer object that is being used by the GPU can introduce bubbles in the pipeline where no useful work is being done. To avoid reducing throughput when updating buffers, consider cycling between multiple buffers to minimize the possibility of updating the buffer from which content is currently being rendered.&lt;/p&gt;

&lt;p&gt;참고: GPU에서 사용되는 버퍼 오브젝트에 쓰는 것은 파이프라인에 작업을 끝내기에 적절하지 않은 거품을 초래합니다. 버퍼에 업데이트할 때 처리량을 줄이는 것을 피하기 위해, 내용이 렌더링될 때 버퍼를 업데이트 하는 가능성을 최소화 하게 위해 여러 버퍼를 돌려가면서 쓰는 것으로 고려하세요.&lt;/p&gt;

&lt;h2&gt;이전에, 많이 컬링하십시오. (G10)&lt;/h2&gt;

&lt;p&gt;The GPU will not rasterize primitives when all of its vertices fall outside the viewport. It also avoids processing hidden fragments when the depth test or stencil test fails (P4). However, this does not mean that the GPU should do all the work in deciding what is visible. In the case of vertices, they need to be loaded, assembled and processed in the vertex shader, before the GPU can decide whether to cull or clip parts of the geometry. Testing a single, simple bounding volume that encloses the geometry against the current view frustum on the CPU side is a lot faster than testing hundreds of thousands of vertices on the GPU. If an application is limited by vertex processing, this is definitely the place to begin optimizing. Spheres are the most efficient volumes to test against and the volume of choice if geometry is rotational symmetrical. For some geometry, spheres tend to lead to overly conservative visibility acceptance. A rectangular cuboid (box) is only a slightly more expensive test but can be made to fit more tightly on most geometry. Hierarchical culling can often be employed to reduce the number of tests necessary on the CPU. Efficient and advanced culling algorithms have been heavily researched and published for many years. You can find a good introduction in the survey at the below locations.&lt;/p&gt;

&lt;p&gt;GPU는 &lt;em&gt;viewport&lt;/em&gt; 의 바깥으로 모든 정점이 떨어질 때 래스라이즈를 하지 않습니다. 이는 또한 &lt;em&gt;depth test&lt;/em&gt; 혹은 &lt;em&gt;stencil test&lt;/em&gt; 가(P4) 실패 할때 숨겨진 &lt;em&gt;fragment&lt;/em&gt; 를 피합니다. 하지만 이는 GPU가 모든 가시성을 결정하기 위한 일을 한다는 의미는 아닙니다. 정점의 경우, 로딩이 되고, 정점 쉐이더에서 조합과 처리가, GPU가 기하의 일부분을 컬링하거나 클리핑할지 말지 정하기 이전에 됩니다. 간단한 하나의 테스트, 기하를 감싸는 경계 볼륨을 현재 뷰 프러스텀을 CPU에서 비교하는 것은 GPU에서 수천개의 정점을 테스트 하는 것 보다 빠릅니다. 만약에 응용 프로그램이 정점 처리에 한계가 왔다면, 이건 최적화를 시작할 지점이 틀림없습니다. 어떤 기하의 경우, 구가 큰 보수적인 가시성 수락을 이끄는 경향이 있습니다. 직육면체는 오직 조금 더 비싼 테스트이나 대부분의 기하에 잘 맞출 수 있습니다. 위계적 컬링(hierarchical culling)은 CPU에서의 보통 테스트의 숫자를 줄이는데 종종 사용됩니다. 효율적이고 심화된 컬링 알고리즘은 몇년에 이어서 많이 연구되고 출판되었습니다. 아래의 서베이에서 좋은 소개를 볼 수 있습니다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Document&lt;/th&gt;
      &lt;th&gt;URL to Latest&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Visibility in Computer Graphics, by Jiří Bittner and Peter Wonka&lt;/td&gt;
      &lt;td&gt;&lt;a href=&quot;http://www.cg.tuwien.ac.at/research/publications/2003/Bittner-2003-VCG/TR-186-2-03-03Paper.pdf&quot;&gt;URL&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h1&gt;쉐이더 프로그램&lt;/h1&gt;

&lt;p&gt;Writing efficient shaders is critical to achieving good performance. One should treat shaders like pieces of code that run in the inner-most loops on a CPU. There is a very high cost to littering these with conditionals or recomputing loop invariants. Before optimizing an expensive vertex shader, make sure geometry that is entirely outside the view frustum is being culled on the CPU. Before optimizing an expensive fragment shader, make sure the application is not generating an excess number of fragments with it.&lt;/p&gt;

&lt;p&gt;효율적인 쉐이더 작성은 좋은 성능을 얻기 위해서 중요합니다. 쉐이더는 CPU에서의 루프 내부에서 실행되는 코드의 일부분으로 다루어야 합니다. 조건문과 &lt;em&gt;loop-invariant&lt;/em&gt; 를 재계산하여 쉐이더 코드를 어지르는 것은 굉장히 큰 비용이 듭니다. 값 비싼 정점 쉐이더를 최적화하기 전에, CPU에서 뷰 프러스텀 밖의 기하들을 컬링해주세요. 값 비싼 픽셀(&lt;em&gt;fragment&lt;/em&gt;) 쉐이더를 최적화하기 전에, 응용 프로그램이 수많은 &lt;em&gt;fragment&lt;/em&gt; 를 생성하지 않게 하세요.&lt;/p&gt;

&lt;p&gt;Note: When optimizing shaders, any source code that does not contribute to its output variables is optimized out by the compiler. This feature can be exploited to gain knowledge about whether the shader is part of the current bottleneck by multiplying the output variable with a null vector to reduce the workload and then measure if frame rate improves. Conversely, at the final stages of optimization one can quickly measure if there is headroom for increasing workload to offload computations to shader unit or to improve image quality by adding meaningless but expensive ALU instructions, or texture sampling, to the output variables.&lt;/p&gt;

&lt;p&gt;참고: 쉐이더를 최적화 할때, 출력과 상관없는 모든 소스코드는 컴파일러에 의해 제외됩니다. 이 기능을 활용하여 출력 변수에 null 벡터를 곱하여 작업 부하를 줄인 다음, 프레임 속도가 향상되는지 측정하여 어떤 쉐이더가 병목의 한 부분을 차지하는지 알 수 있습니다. 반대로 최적화의 마지막 단계에서, 쉐이더 유닛에서 연산을 더 부담하거나, 값비싼 ALU 명령어들을 이미지 퀄리티를 향상시키기 위해 추가하거나, 텍스쳐 샘플링, 출력 변수들을 위한 여유분이 있는지 빠르게 측정할 수 있습니다.&lt;/p&gt;

&lt;h2&gt;파이프라인 윗단계로 계산을 올리십시오. (P1)&lt;/h2&gt;

&lt;p&gt;As the rendering pipeline is traversed from the CPU to the vertex processor and then to the fragment processor, the required workload tends to increase a few orders of magnitude each time. Computations constant per model, per primitive or per vertex do not belong in the fragment processor and should be moved up to the vertex processor or earlier. Per draw call computations do not belong in the vertex processor and should be moved to the CPU. For instance, if lighting is done in eye-space, the light vector should be transformed into eye-space and stored in a uniform rather than repeating this for each vertex or, even worse, per fragment. The light vector should naturally be stored pre-normalized. Usually the light vector computations are constant for the draw call, so they do not belong in any shader.&lt;/p&gt;

&lt;p&gt;렌더링 파이프라인이 CPU에서 정점 프로세서로 그리고 &lt;em&gt;fragment&lt;/em&gt; 프로세서로 향할 수록, 필요한 처리량은 각 때마다 극단적으로 증가합니다. 모델별, 프리미티브 별 혹은 정점 별 계산 상수는 &lt;em&gt;fragment&lt;/em&gt; 처리에 속하지 않고, 반드시 정점 처리나, 그 전 단계로 이동시켜야 합니다. &lt;em&gt;drawcall&lt;/em&gt; 별 계산은 정점 처리에서 속하지 않고, CPU로 옮겨야 합니다. 예를 들어, &lt;em&gt;lighting&lt;/em&gt; 이 &lt;em&gt;eye-space&lt;/em&gt; 에서 끝난다면, 광원 벡터는 반드시 &lt;em&gt;eye-space&lt;/em&gt; 로 변환되어야 하고, 각각의 정점별로, 더 안좋은 경우 &lt;em&gt;fragment&lt;/em&gt; 별로 반복하는 것 보다 &lt;em&gt;uniform buffer&lt;/em&gt; 에 저장해야 합니다. 광원 벡터는 자연스럽게 미리 정규화되어 저장되어야 합니다. 보통 광원 벡터 계산은 &lt;em&gt;drawcall&lt;/em&gt; 마다 상수이므로 어떤 쉐이더에도 포함되지 않습니다.&lt;/p&gt;

&lt;h2&gt;크거나 일반화된 쉐이더를 작성하지 마십시오. (P2)&lt;/h2&gt;

&lt;p&gt;It is critical to resist the temptation to write shader programs that take different code paths depending on whether one or more constant variable have a particular value. Uniforms are intended as constants for one (or hopefully many) primitives—they are not substitutes for calling UseProgram. Shaders should be minimal and specialized to the task they perform. It is much better to have many small shaders that run fast than a few large shaders that all run slow. Code re-use (when source shaders are supported) should be handled at the application level using the ShaderSource function. If the advice here of not writing generalized shaders goes against the conflicting goal of minimizing shader and state changes, smaller and more specialized shaders are generally preferred. Additionally, be careful with writing shader functions intended for concatenation into the final shader source code - shared functions tend to be overly generic and make it harder to exploit possible shortcuts.&lt;/p&gt;

&lt;p&gt;상수가 특정 값을 가지냐에 따라 코드 분기를 달리하는 쉐이더를 작성하고 싶은 유혹에 저항하는 것은 굉장히 중요합니다. &lt;em&gt;uniform buffer&lt;/em&gt; 는 하나(다다익선) 프리미티브에 대한 상수로 사용되며, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UseProgram&lt;/code&gt; 을 대체하진 않습니다. 쉐이더는 반드시 목적에 맞게 특화되고 최소화 되어야 합니다. 느리게 실행되는 큰 쉐이더 몇개 보다, 빠르게 실행되는 수많은 작은 쉐이더가 더 낫습니다. 코드 재사용은 (소스 쉐이더 프로그램이 지원될 때) &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ShaderSource&lt;/code&gt; 함수를 통하여  응용 프로그램 레벨에서 제어되어야 합니다. 여기서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;일반화된 쉐이더를 작성하지 마라&lt;/code&gt; 라는 조언이 쉐이더 크기와 상태 변화를 최소화 하는 목표와 상충된다면, 일반적으론 더 작고 특화된 쉐이더 작성을 선택합니다. 또한, 마지막 쉐이더 소스 코드에 덧붙일 쉐이더 함수를 사용할 때 주의해야 합니다. 쉐이더 함수는 심하게 일반화 되고, 가능한 &lt;em&gt;shortcut&lt;/em&gt; 을 이용하는 것을 어렵게 만듦니다.&lt;/p&gt;

&lt;h2&gt;응용프로그램의 특정한 지식을 활용하십시오. (P3)&lt;/h2&gt;

&lt;p&gt;Application specific knowledge can be used to simplify or avoid computations. Math shortcuts should be pursued everywhere because there are optimizations that the shader compiler or the GPU cannot make. For instance, rendering screen-aligned primitives is common for 2D user interface and post-processing effects. In this case, the entire modelview transformation is avoided by defining the vertices in NDC (normalized device coordinates). A full-screen quad has its vertex coordinates in the [-1.0,1.0] range so these can be passed directly from the vertex attribute to gl_Position. The types of matrix transformations applied in the application when creating the modelview matrix should be tracked and exploited when possible. For instance, an orthonormal matrix (e.g. no non-uniform scaling) leads to an opportunity to avoid computations when transforming normals with the inverse-transpose sub-matrix.&lt;/p&gt;

&lt;p&gt;특정한 응용 프로그램만의 케이스는 계산을 피하거나 단순화할 수 있습니다. 쉐이더 컴파일러나 GPU 가 만들 수 없는 수학적 계산 최적화가 있기 때문에 모든 곳에서 신경써야합니다. 예를 들면, &lt;em&gt;screen-aligned primitive&lt;/em&gt; 는 (화면에 정렬된 도형) 2D UI 나 &lt;em&gt;post-processing&lt;/em&gt; 효과에 자주 쓰입니다. 이 경우, 모든 모델-뷰 변환은 정점을 미리 NDC(normalized device coordinates) 로 정의하여 피할 수 있습니다. 전체 화면 &lt;em&gt;quad&lt;/em&gt; 는 (사각 폴리곤) [-1.0, 1.0] 범위에서 정점 위치를 가지기때문에 &lt;em&gt;vertex attribute&lt;/em&gt; 에서 직접 &lt;em&gt;gl_Position&lt;/em&gt; 으로 통과할 수 있습니다. 이 행렬 변환의 타입들은 모델-뷰 행렬을 만드는 것이 가능한한 추적되거나 활용될 때 응용 프로그램에서 적용 됩니다. 예를 들어 &lt;em&gt;orthonormal&lt;/em&gt; (정규직교) 행렬은 &lt;em&gt;inverse-transpose&lt;/em&gt; 부 행렬과 함께 법선 벡터를 변환시킬 때, 계산을 피할 수 있는 기회를 이끌어 냅니다.&lt;/p&gt;

&lt;h2&gt;깊이, 스텐실 컬링을 최적화하십시오. (P4)&lt;/h2&gt;

&lt;p&gt;The GPU can quickly reject fragments based on depth or stencil testing before the fragment shader is executed. The depth complexity of a scene is the number of times each fragment gets written. Depth complexity can be measured by incrementing values in a stencil buffer. A high depth complexity in a 3D scene can be a result of rendering opaque objects in a non-optimal order. The worst case is rendering back-to-front (aka painter’s algorithm) because it leads to a large number of fragments being overdrawn. An application with high depth complexity should ensure that opaque objects are rendered sorted front-to-back order with depth testing enabled. Straightforward rendering of 2D user interfaces also leads to a high depth complexity that can often be decreased with the same technique but also by using the stencil buffer to mask fragments. Applications that are heavily fragment limited can be sped up significantly with clever use of these techniques—sometimes up to a factor of 10 or more.&lt;/p&gt;

&lt;p&gt;GPU 는 &lt;em&gt;fragment&lt;/em&gt; 쉐이더가 실행되기 전, 깊이 혹은 스텐실 테스팅을 기반으로 &lt;em&gt;fragment&lt;/em&gt; 쉐이더를 빠르게 제외할 수 있습니다. 환경의 &lt;em&gt;depth complexity&lt;/em&gt; (깊이 복잡도)는 각각의 &lt;em&gt;Fragment&lt;/em&gt; 에 쓰는 횟수입니다. &lt;em&gt;depth complexity&lt;/em&gt; 는 스텐실 버퍼를 1씩 증가시켜가며 측정 가능합니다. 3D 환경에서 높은 &lt;em&gt;depth complexity&lt;/em&gt;  은 최적의 순서가 아닌 불투명 오브젝트 렌더링의 결과로 나타날 수 있습니다. 가장 나쁜 경우는 &lt;em&gt;back-to-front&lt;/em&gt; 렌더링 입니다. (다른 말로는, 화가의 알고리즘) 왜냐면, 이는 많은 &lt;em&gt;fragment&lt;/em&gt; 들을 덮어씌우기 때문입니다. 높은 &lt;em&gt;depth complexity&lt;/em&gt; 를 지닌 응용 프로그램은 반드시 &lt;em&gt;depth test&lt;/em&gt; (깊이 검사) 와 함께 정렬된 &lt;em&gt;front-to-back&lt;/em&gt; 순서로 불투명 오브젝트의 렌더링을 보장해야 합니다. 2D UI 의 단순한 렌더링 또한 같은 테크닉 뿐만 아니라 &lt;em&gt;fragment&lt;/em&gt; 마스킹을 위해 스텐실 버퍼를 이용하여 높은 &lt;em&gt;depth complexity&lt;/em&gt; 를 줄일 수 있습니다. 심하게 &lt;em&gt;fragment&lt;/em&gt; 비용이 제한된 응용 프로그램은 이러한 똑똑한 방법의 사용으로 속도를 10배 혹은 그 이상 높일 수 있습니다.&lt;/p&gt;

&lt;p&gt;If vertex processing is not a bottleneck, it is worthwhile to run experiments that prime the depth buffer in a first pass. Disable all color writes with ColorMask on the first pass. The fragments in the depth buffer can then serve as occluders in a second pass when color writes are enabled and the expensive fragment shaders are executed. Disable depth writes with DepthMask in the second pass since there is no point in writing it twice.&lt;/p&gt;

&lt;p&gt;만약 정점 처리가 병목이 아니라면, 첫번째 &lt;em&gt;pass&lt;/em&gt; 에서 깊이 버퍼를 쓰는 실험을 실행하는 것이 의미 있습니다. 첫 &lt;em&gt;pass&lt;/em&gt; 에서 &lt;em&gt;ColorMask&lt;/em&gt; 와 함께 모든 색 쓰기를 비활성화합니다. 깊이 버퍼의 &lt;em&gt;fragment&lt;/em&gt; 는 색 쓰기가 가능하고, 비싼 &lt;em&gt;fragment&lt;/em&gt; 쉐이더가 실행될 때, 두번째 &lt;em&gt;pass&lt;/em&gt; 에서 &lt;em&gt;occluders&lt;/em&gt; (가리는 오브젝트) 를 대신할 수 있습니다. 두번이나 쓸 필요는 없기 때문에, 두번째 &lt;em&gt;pass&lt;/em&gt; 에서는 &lt;em&gt;DepthMask&lt;/em&gt; 와 함께 깊이 쓰기를 비활성화 합니다.&lt;/p&gt;

&lt;h2&gt;픽셀 처리 조각(&lt;em&gt;fragment&lt;/em&gt;)를 버리거나, 깊이를 수정하지 마십시오. 완전히 필요한게 아니라면, (P5)&lt;/h2&gt;

&lt;p&gt;Some operations prevent the hardware from enabling its automatic optimization that rejects fragments early in the pipeline (early-Z). In particular, the discard operation that discards fragments based on some criteria will disable early-Z on some platforms. It is critical to limit the use of discarding as much as possible (e.g., alpha testing)—unless depth writing can be disabled. Another example is found in the GL_NV_fragdepth extension available on some platforms, where the depth value can be written from the fragment shader. This operation also forces the GPU to opt out of Early-Z reject in order to ensure correct rendering.&lt;/p&gt;

&lt;p&gt;몇몇 명령은 파이프라인에서 일찍 &lt;em&gt;fragment&lt;/em&gt; 연산을 제외하는(ealry-Z) 자동 최적화를 하드웨어가 하지 못하도록 합니다. 특히, 특정 기준에 따라서 &lt;em&gt;fragment&lt;/em&gt; 를 버리는 &lt;em&gt;discard&lt;/em&gt; 명령은 몇몇 플랫폼에서 &lt;em&gt;early-Z&lt;/em&gt; 를 비활성화 시킵니다. 깊이 쓰기를 비활성화 할 수 없는 경우, &lt;em&gt;discard&lt;/em&gt; 연산을 최대한 제한하는 것은 중요합니다. 다른 예시를 깊이 값을 &lt;em&gt;fragment&lt;/em&gt; 쉐이더에서 쓰기 가능하고, 특정 플랫폼에서 가능한 &lt;em&gt;GL_NV_fragdepth&lt;/em&gt; 확장에서 찾을 수 있습니다. 이 명령은 또한 정확한 렌더링을 보장하기 위해 &lt;em&gt;early-Z&lt;/em&gt; 거부를 강제로 비활성화 시킵니다.&lt;/p&gt;

&lt;h2&gt;조건문을 최대한 피하십시오. (P6)&lt;/h2&gt;

&lt;p&gt;Fragments are processed in chunks and both branches of a conditional may need to be evaluated before the result of the false branch can be discarded by the GPU. Be careful with assuming that conditionals skip computations and reduce the workload. This warning is particularly relevant to fragment shaders. Benchmarking shaders can determine if conditionals in the vertex or fragment shaders actually end up decreasing the workload. Some conditional code can be rewritten in terms of algebra and/or built-in functions. For instance, the dot product between a normal and a light vector may be negative in which case the result is not needed in a lighting equation. Instead of:&lt;/p&gt;

&lt;p&gt;GPU에 의해 &lt;em&gt;false branch&lt;/em&gt; 의 (실행되지 않을 코드 흐름) 결과를 제외하기 전, &lt;em&gt;fragment&lt;/em&gt; 들은 한꺼번에 처리되고, 각각의 분기내의 코드 흐름을 아마 평가할 필요가 있습니다. 조건문이 계산을 건너 뛴거나, 워크로드를 줄인다는 가정을 조심하십시오. 이 경고는 특히 &lt;em&gt;fragment&lt;/em&gt; 쉐이더와 연관되어 있습니다. 쉐이더 벤치마킹은 정점 혹은 &lt;em&gt;fragment&lt;/em&gt; 쉐이더에서의 조건이 실질적으로 끝내어 워크로드를 줄이는지에 따라 결정됩니다. 몇몇 조건문 코드는 대수 and/or 내장 함수로 다시 쓰일 수 있습니다. 예를 들어 법선 벡터와 빛의 방향 벡터를 내적의 결과가 음수 일 수 있으며, 이 경우 &lt;em&gt;light equation&lt;/em&gt; 내에서 결과가 필요하지 않습니다.&lt;/p&gt;

&lt;p&gt;대신에:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;if (nDotL &amp;gt; 0.0) ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;the value can be clamped with:&lt;/p&gt;

&lt;p&gt;이 값은 &lt;em&gt;clamp&lt;/em&gt; 로 대체할 수 있습니다:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;clamp(nDotL, 0.0, 1.0)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;and unconditionally used in the result (the negative value results in a zero-product). Clamp may be faster than max and/or min for the 0.0 and 1.0 cases, but as always benchmarking will have the final say in the matter. Another reason to make an effort of avoiding conditionals in fragment shaders is that mipmapped textures return undefined results when executed in a block statement that is conditional on run-time values. Although the GLSL functions &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;texture*Lod&lt;/code&gt; can be used to bias or specify the mipmap LOD, it is expensive to manually derive the mipmap LOD. In addition, these LOD biasing samplers may not run as fast as the non-LOD samplers.&lt;/p&gt;

&lt;p&gt;그리고 조건문 없이 결과에 사용될 수 있습니다.(음수가 0 곱하기로 표현되는 경우) &lt;em&gt;clamp&lt;/em&gt; 연산은 아마도 &lt;em&gt;max&lt;/em&gt; ,&lt;em&gt;min&lt;/em&gt; 을 0과 1사이에서 실행하는 것보다 빠를 수 있습니다. &lt;em&gt;fragment&lt;/em&gt; 쉐이더에서 조건문을 피하기 위한 노력의 다른 이유는 밉맵을 가진 텍스쳐는 런타임에 달라지는 조건에 따른 &lt;em&gt;block statement&lt;/em&gt; (조건에 블록 형태로 존재하는 문장: 여러 코드 줄) 에서 실행 될 때, 정의되지 않은 결과를 반환하기 때문입니다. GLSL 함수 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;texture*Lod&lt;/code&gt;를 사용하여 밉맵 LOD 를 &lt;em&gt;bias&lt;/em&gt; (오프셋 처리) 하거나, 지정할 수 있지만, 직접 밉맵 LOD 를 파생시키는 것은 비쌉니다. 또한 이러한 &lt;em&gt;LOD-biasing&lt;/em&gt; 샘플러는 &lt;em&gt;LOD-biasing&lt;/em&gt; 이 아닌 샘플러보다 빠르지 않을 것입니다.&lt;/p&gt;

&lt;h2&gt;적절한 정확도 한정자를 사용하십시오. (P7)&lt;/h2&gt;

&lt;p&gt;Recall that the default precision in vertex shaders is highp, and that fragment shaders have no default precision until explicitly set. Precision qualifiers can be valuable hints to the compiler to reduce register pressure and may improve performance for several reasons. Low precision may run twice as fast in hardware as high precision. These optimizations can be approached by initially using highp and gradually reducing the precision to lowp until rendering artifacts appear; if it looks good enough, then it is good enough. As a rule of thumb, vertex position, exponential and trigonometry functions need highp. Texture coordinates may need anything from lowp to highp depending on texture width and height. Many application-defined uniform variables, interpolated colors, normals and texture samples can usually be represented using lowp. However, floating-point texture samplers need more than low precision - this is one of several reasons to minimize the use of floating-point textures (T6).&lt;/p&gt;

&lt;p&gt;정점 쉐이더에서 기본 부동소수점 정확도는 &lt;em&gt;highp&lt;/em&gt; 이지만, &lt;em&gt;fragment&lt;/em&gt; 쉐이더는 기본 부동소수점 정확도는 명시저긍로 정해주어야 합니다. 정확도 한정자는 컴파일러에게 레지스터 압박을 줄이거나, 여러 이유로 성능을 향상시킬 수 있는 가치있는 힌트가 될 수 있습니다. 낮은 정확도는 높은 정확도 보다 하드웨어에서 두배로 빠를 것 입니다. 이런 최적화는 처음에는 &lt;em&gt;highp&lt;/em&gt; 를 사용하고, 점진적으로 정확도를 &lt;em&gt;lowp&lt;/em&gt;  로 렌더링 &lt;em&gt;artifact&lt;/em&gt; 가 생길 때까지 줄여나가며 접근할 수 있습니다. 그 &lt;em&gt;artifact&lt;/em&gt; 에도 충분하다면, 그것은 충분한 것입니다. 경험적으로, 정점의 위치, 지수 및 삼각 함수는 &lt;em&gt;highp&lt;/em&gt; 가 필요합니다. 텍스쳐 좌표는 텍스쳐의 크기에 따라서, &lt;em&gt;lowp&lt;/em&gt; 부터 &lt;em&gt;highp&lt;/em&gt; 까지 다르게 필요합니다. 많은 응용 프로그램에서 정의된 &lt;em&gt;uniform variables&lt;/em&gt;, &lt;em&gt;interpolated colors&lt;/em&gt;, &lt;em&gt;normals&lt;/em&gt;, &lt;em&gt;texture samples&lt;/em&gt; 는 보통 &lt;em&gt;lowp&lt;/em&gt; 를 사용하여 표현될 수 있습니다. 하지만 부동 소수점 텍스쳐 샘플러는 &lt;em&gt;lowp&lt;/em&gt; 보다 나은 정확도가 필요합니다. 이는 여러 부동 소수점 텍스쳐의 사용을 최소화해야되는 여러 이유 중에 하나입니다. (T6)&lt;/p&gt;

&lt;h2&gt;빌트인 함수와 변수를 사용하십시오. (P8)&lt;/h2&gt;

&lt;p&gt;The built-ins have a higher chance of compiling optimally and may even be implemented in hardware. For instance, do not write shader code to determine the forward primitive face or compute the reflection vector in terms of dot-products and algebra; instead, use the built-in variable gl_FrontFacing or the built-in function reflect, respectively.&lt;/p&gt;

&lt;p&gt;빌트인 함수 및 변수는 최적의 컴파일의 중요한 기회 가지고, 하드웨어에서 구현된 것일 수도 있습니다. 예를 들어, &lt;em&gt;primitive&lt;/em&gt; 정면 혹은 반사 벡터를 내적 그리고 대수로 결정하는 쉐이더 코드를 작성하는 것 대신, &lt;em&gt;gl_FrontFacing&lt;/em&gt; 혹은 &lt;em&gt;reflect&lt;/em&gt; 빌트인 함수를 사용하세요.&lt;/p&gt;

&lt;h2&gt;복잡한 함수는 텍스쳐에 인코딩하는 것을 고려하십시오. (P9)&lt;/h2&gt;

&lt;p&gt;Shaders normally contain both arithmetic (ALU) and texture operations. A batch of ALU operations may hide the latency of fetching samples from texture because they occur in parallel. If a shader is the primary bottleneck, and when the ALU operations significantly outnumber the texture operations, it is worthwhile to investigate if some of these operations can be encoded in textures. Sub-expressions in shaders can sometimes be stored in LUTs (look-up-tables). LUTs can sometimes be implemented in textures with sufficient precision and accessed as 1D or 2D textures with NEAREST filtering.&lt;/p&gt;

&lt;p&gt;보통 쉐이더는 계산 유닛과(ALU) 텍스쳐 유닛을 둘다 가집니다. ALU 명령의 &lt;em&gt;batch&lt;/em&gt; 는 (한꺼번에 처리) 병렬적으로 실행되기 때문에 텍스쳐에서 샘플을 가져오는 지연 시간을 감춥니다. (hide of latency) 만약 쉐이더가 주요한 병목이라면, ALU 명령이 텍스쳐 명령보다 훨씬 많을 때, 특정 연산을 텍스쳐에 인코딩 하는 것을 조사하는 것은 의미있는 일입니다. 쉐이더의 일부(sub-expression)은 가끔 LUT들에 (look-up-table)저장될 수 있습니다. LUT는 가끔 충분한 정확도 그리고 NEAREST 필터링과 함께 1D 혹은 2D 텍스쳐로 구현될 수 있습니다.&lt;/p&gt;

&lt;p&gt;Note: The old trick of using cubemaps to normalize vectors is most likely a performance loss on discrete GPUs. If you pursue this idea, then make sure to benchmark to determine if you have improved or worsened the performance!&lt;/p&gt;

&lt;p&gt;참고: 벡터 정규화를 위해 큐브맵을 사용하는 오래된 트릭은 discrete GPU 에서 성능 손실을 가져올 가능성이 높습니다. 만약 당신이 이를 주장한다면, 성능을 향상시킬지, 나쁘게 하는 것인지 결정하기 위해 벤치마크를 하세요.&lt;/p&gt;

&lt;h2&gt;간접 텍스쳐링의 사용을 제한하십시오. (P10)&lt;/h2&gt;

&lt;p&gt;Indirect texturing can sometimes be useful, but when the result of a texture operation depends on another texture operation, the latency of texture sampling is difficult to hide. It also tends to lead to scattered reads that minimize the benefit of the texture cache. Indirect texturing can sometimes be reduced, or avoided, at the expense of memory. Whether that trade-off makes sense should of course be analyzed and benchmarked.&lt;/p&gt;

&lt;p&gt;간접 텍스쳐링은 가끔 유용하지만, 텍스쳐 연산의 결과가 다른 텍스쳐 연산에 의존한다면, 텍스쳐 샘플링의 지연 시간을 감추기 어렵습니다. 또한 텍스쳐 캐시의 장점을 최소화 하는 파편화된 읽기를 이끄는 경향이 있습니다. 간접 텍스쳐링은 가끔은 메모리 비용 면에서 줄이거나, 피할 수 있습니다. 이 트레이드 오프가 타당한지 분석하고, 벤치마크 되어야 합니다.&lt;/p&gt;

&lt;h2&gt;수치 계산 최적화를 모호하게 GLSL 구문을 작성하지 마십시오. (P11)&lt;/h2&gt;

&lt;p&gt;The GLSL shading language conveniently overloads arithmetic operators for vectors and matrices. Care must be taken to not miss optimization opportunities due to this syntax simplification. For instance, a rotation matrix can, but should not, be defined as homogenous 4x4 matrix just because the other operand is a vec4 vector. A generalized rotation matrix should be described only as a 3 x 3 matrix and applied to vec3 vectors. And a rotation around basic vectors can be done even more efficiently than mat3 * vec3 by directly accessing the relevant vector and matrix components with cos and sin. Take advantage of any specific application knowledge to reduce the number of needed scalar instructions.&lt;/p&gt;

&lt;p&gt;GLSL 쉐이딩 언어는 벡터와 행렬을 위해 산수 계산을 편리하게 오버로드합니다. 이 syntax 단순화 때문에 최적화 기회를 날리지 않기 위해 신경써야 합니다. 예를 들어, 회전 행렬은 가능하지만, 불가능 할 수도 있는데, 동차 좌표계의 4x4 행렬으로 다른 인자가 vec4 이기 때문에 정의될 수 있습니다. 일반화된 회전 행렬은 오직 3x3 행렬로 묘사되고 vec3 벡터에 적용되어야 합니다. 그리고 기본 벡터의 회전은 직접 관련된 벡터 및 행렬의 요소에 cos와 sin과 함께 직접 접근하여 mat3 * vec3 보다 더 효율적으로 끝낼 수 있습니다. 필요한 스칼라 명령의 수를 줄이기 위해 응용 프로그램의 특정 지식을 이용하세요.&lt;/p&gt;

&lt;h2&gt;정규화는 필요할 때만 하십시오. (P12)&lt;/h2&gt;

&lt;p&gt;Normalization of vectors is required to efficiently calculate the angle between them, or perhaps more typically, the diffuse component in many commonly used lighting equations. In theory, normalization is required for geometry normals after having transformed them with the normal matrix. In practice, it may not matter depending on the composition of the matrix. It is a common mistake to normalizing vectors where it is not necessary, or at least not visually discernible. As a result, the application may run slower for no good reason. For instance, consider the case of interpolating vertex normals in order to compute lighting per fragment (i.e., Phong shading). If the normal matrix only rotates, there is little reason to normalize the normal vectors before interpolating.&lt;/p&gt;

&lt;p&gt;벡터의 정규화는 두 벡터의 각이나, 아마도 더 일반적으로, 가장 많이 사용되는 &lt;em&gt;lighting equation&lt;/em&gt; 의 &lt;em&gt;diffuse&lt;/em&gt; 컴포넌트에서 효율적으로 계산하기 위해 필요합니다. 이론상으로, 법선 행렬과 함께 변환된 이후에 지오메트리 법선 벡터를 위해 정규화가 필요합니다. 실전에서는 행렬의 합성에서 딱히 별일이 없습니다. 이는 필요하지 않거나, 적어도 시각적으로 보고 알 수 있지 않아도 정규화를 하는 일반적인 실수입니다. 결과적으론, 별 이유 없이 응용 프로그램은 더 느려집니다. 예를 들어 정점 법선 벡터를 &lt;em&gt;fragment&lt;/em&gt; 별 라이팅 계산을 위해 보간(정점 단계 -&amp;gt; 픽셀 단계에서, 래스터라이저를 거치며 일어나는) 하는 경우를 생각해 봅시다.(즉, 퐁 쉐이딩) 만약에 법선 행렬이 오직 회전만 한다면, 보간 전에 법선 벡터를 정규화할 조그만 이유가 있습니다.&lt;/p&gt;

&lt;p&gt;Note: Barycentric interpolation will not preserve the unit length of these vectors. So normals that are interpolated in varying variables do must be normalized to ensure the dot-product with the light vector obeys the cosine emission law.&lt;/p&gt;

&lt;p&gt;참고: 무게 중심 보간은 정규화를 보장하지 못합니다. 그래서 &lt;em&gt;varying variable&lt;/em&gt; 에서 (래스터라이저를 이후에) 보간된 법선 벡터는 &lt;em&gt;lambert cosine law&lt;/em&gt; 를 따르는 광원 벡터와의 내적을 보장하기 위해 정규화를 해야 합니다.&lt;/p&gt;

&lt;h1&gt;텍스쳐&lt;/h1&gt;

&lt;p&gt;Textures consume the largest amount of the available memory and bandwidth in many applications. One of the best places to look for improvements when short on memory or bandwidth to optimize texture size, format and usage. Careless use of texturing can degrade the frame rate and can even result in inferior image quality.&lt;/p&gt;

&lt;p&gt;텍스쳐는 많은 응용 프로그램에서 가장 많은 가용 메모리와 대역폭을 소모합니다. 메모리와 대역폭이 부족할 때, 텍스쳐 크기, 포맷 및 사용을 최적화하여 성능 향상을 꾀할 수 있는 가장 좋은 곳 중 하나입니다. 무분별한 텍스쳐의 사용은 프레임을 감소시키고, 심지어 이미지 품질이 저하될 수 도 있습니다.&lt;/p&gt;

&lt;h2&gt;텍스쳐 압축은 가능한 사용하십시오. (T1)&lt;/h2&gt;

&lt;p&gt;Texture compression brings several benefits that result from textures taking up less memory: compressed textures use less of the available memory bandwidth, reduces download time, and increases the efficiency of the texture cache. The texture_compression_s3tc and texture_compression_latc extensions both provide block-based lossy texture compression that can be decompressed efficiently in hardware. The S3TC extension gives 8:1 or 4:1 compression ratio and is suitable for color images with 3 or 4 channels (with or without alpha) with relatively low-frequency data. Photographs and other images that compress satisfactory with JPEG are great candidates for S3TC. Images with hard and crisp edges are less good candidates for S3TC and may appear slightly blurred and noisy. The LATC extension yields a 2:1 compression ratio, but improves on the quality and can be useful for high resolution normal maps. The third coordinate is derived in the fragment shader—be sure to benchmark if the application can afford this trade-off between memory and computations! Unlike S3TC, the channels in LATC are compressed separately, and quantization is less hard. Using texture compression does not always result in lower perceived image quality, and with these extensions one can experiment with increasing the texture resolution for the same memory. There are off-line tools to compress textures (even if a GL extension supports compressing them on-the-fly). Search the NVIDIA developer website for “Texture Tools”.&lt;/p&gt;

&lt;p&gt;텍스쳐 압축은 적은 메모리를 사용하는 텍스쳐로 부터 여러 이익을 가져다 줍니다: 압축된 텍스쳐는 적은 메모리 대역폭, 적은 다운로드 시간 및 텍스쳐 캐시 효율을 증대시켜 줍니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;texture_compression_s3tc&lt;/code&gt; 와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;texture_compression_latc&lt;/code&gt; 확장은 둘 다 하드웨어에서 효율적으로 해제 가능한 블록 기반의 손실 텍스쳐 압축을 제공합니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;S3TC&lt;/code&gt; 확장은 8:1 혹은 4:1 압축 비율을 가지며, 비교적 낮은 주파수의 데이터를 가진 3 혹은 4 채널의 색 이미지에 적합합니다. JPEG를 사용하여 만족할 정도로 압축된 사진이나 다른 이미지는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;S3TC&lt;/code&gt; 의 좋은 후보입니다. 튀고 뾰족한 선을 가진 이미지는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;S3TC&lt;/code&gt; 의 덜 좋은 후보이고, 아마도 희미하거나, 노이즈가 끼어있을 수 있습니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LATC&lt;/code&gt; 확장은 2:1 압축 비율을 가지지만, 이는 질을 향상시키고, 높은 해상도의 노말맵에 유용합니다. 세번째 좌표는 &lt;em&gt;fragment&lt;/em&gt; 쉐이더에서 유도됩니다-반드시 메모리와 계산 사이에서 응용 프로그램이 수용 가능한지 벤치마크하세요! &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;S3TC&lt;/code&gt; 와 다르게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LATC&lt;/code&gt;에서는 채널을 분리하여 압축하고, 양자화는 비교적 덜 강하게 됩니다. 텍스쳐 압축을 쓰는 것은 무조건 낮은 퀄리티의 이미지를 만드는게 아니기 때문에 같은 메모리를 사용할 때 해상도를 증가시키는 실험을 앞선 확장과 함께 할 수 있습니다. 오프라인 텍스쳐 압축 툴도 있습니다.(심지어 GL 확장은 바로 압축 또한 지원합니다.)&lt;/p&gt;

&lt;h2&gt;적절하게 밉맵을 사용하십시오. (T2)&lt;/h2&gt;

&lt;p&gt;Mipmaps should be used when there is not an obvious one-to-one mapping between texels and framebuffer pixels. If texture minification occurs in a scene and there are no mipmaps to access, texture cache utilization will be poor due to the sparse sampling. If texture minification occurs more often than not, then the texture size may be too large to begin with. Coloring the mipmap levels differently can provide a visual clue to the amount of minification that is occurring. When reducing the texture size, it may also be worthwhile to perform experiments to see if some degree of magnification is visually acceptable and if it improves frame rate.&lt;/p&gt;

&lt;p&gt;밉맵은 &lt;em&gt;texel&lt;/em&gt; 과 프레임버퍼 픽셀간의 1대1 매핑을 중요하지 않은 경우엔 사용되어야 합니다. 만약 환경에서 텍스쳐 축소가 일어나고 밉맵 접근이 불가능하다면, 텍스쳐 캐시 활용은 드문 드문 샘플링하는 것 때문에 나쁜 성능을 가질 것입니다. 만약 텍스쳐 축소가 자주 일어난다면, 텍스쳐 크기는 시작부터 너무 큰 크기를 가질 것입니다. 밉맵 레벨별로 다르게 색칠하는 것은 축소가 얼마나 일어나는지에 대한 시각적 증거를 제공합니다. 또한 텍스쳐 크기를 줄일 때, 어느 정도의 확대가 시각적으로 괜찮은지, 얼마나 &lt;em&gt;frame rate&lt;/em&gt; 를 올려줄 지 보기 위해 실험을 하는 것 또한 가치있을 것입니다.&lt;/p&gt;

&lt;p&gt;Although the GenerateMipmap function is convenient, it should not be the only option for generating a mipmap chain. This function emphasizes execution speed over image quality by using a simple box filter. Generating mipmaps off-line using more advanced filters (e.g. Lanczos/Sinc) will often yield improved image quality at no extra cost. However, GenerateMipmap may be preferable when generating textures dynamically due to speed. One of the only situations where you do not want to use mipmaps is if there is always a one-to-one mapping between texels and pixels. This is sometimes the case in 3D, but more often the case for 2D user interfaces. Recall that a mipmapped texture takes up 33% more storage than un-mipmapped, but they can provide much better performance and even better image quality through reduced aliasing.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;GenerateMipmap&lt;/code&gt; 함수가 간편함에도 불구하고, 이는 밉맵 체인을 생성하는 단 하나만의 옵션은 아닙니다. 이 함수는 간단한 &lt;em&gt;box filter&lt;/em&gt; 를 사용하여 이미지 퀄리티와 상관 없이 실행 속도를 강조합니다. 오프라인에서 더 나은 필터를 사용하는 밉맵 생성은 보통 추가적인 비용 없이 이미지 퀄리티를 올릴 수 있습니다. 하지만 &lt;em&gt;GenerateMipmap&lt;/em&gt; 은 동적으로 텍스쳐를 만들어 낼 때, 아마 속도 때문에 선호됩니다. 당신이 밉맵을 사용하지 않을 상황은 텍셀과 픽셀이 언제나 일대일 매핑되어야 할 때 입니다. 3D 환경에서 근근히 있는 케이스이지만, 2D UI에서 더 자주 있는 일입니다. 정리하자면, 밉맵이 있는 텍스쳐가 33%의 메모리를 더 차지하지만, 더 나은 성능과 심지어 줄여진 &lt;em&gt;aliasing&lt;/em&gt; 을 통해 더 나은 이미지 퀄리티를 제공할 수 있습니다.&lt;/p&gt;

&lt;h2&gt;가능한 최소한의 텍스쳐 사이즈를 사용하십시오. (T3)&lt;/h2&gt;

&lt;p&gt;Always use the smallest possible texture size for any content that gives acceptable image quality. The appropriate size of a texture should be determined by the size of the framebuffer and the way the textured geometry is projected onto it. But even when you have a one-to-one mapping between texels and framebuffer pixels, there may be cases where a smaller size can be used. For instance, when blending a texture on the existing content in the entire framebuffer, the texture does not necessarily have to be the same width and height as the framebuffer. It may be the case that a significantly smaller texture that is magnified will produce results that are good enough. The bandwidth that is saved from using a smaller and more appropriately sized texture can instead be spent where it actually contributes to better image quality or performance.&lt;/p&gt;

&lt;p&gt;무엇이든 간에 수용 가능한 이미지 퀄리티를 제공하는 선에서 항상 최소한의 가능한 텍스쳐 사이즈를 사용해야 합니다. 텍스쳐의 적절한 크기는 프레임 버퍼의 크기와 텍스쳐가 입힌 기하가 어떻게 투영되는지에 따라 결정되어야 합니다. 하지만 심지어 &lt;em&gt;texel&lt;/em&gt; 과 프레임 버퍼의 픽셀의 일대일 매핑을 원할 때도 사용 가능한 가장 작은 크기를 고르게 될 것입니다. 예를 들어 있던 전체 프레임 버퍼와 텍스쳐를 블렌딩 할 때, 텍스쳐는 프레임 버퍼와 같은 가로,세로 크기를 가져야 합니다. 아마도 확대된 상당히 작은 텍스쳐가 충분히 괜찮은 결과를 만들 수 있습니다. 더 작고 적절한 크기의 텍스쳐를 사용하여 얻은 대역폭은 실질적으로 더 나은 이미지 퀄리티와 성능을 위해 대신 사용될 수 있습니다.&lt;/p&gt;

&lt;h2&gt;가능한 최소한의 텍스쳐 포맷과 데이터 타입을 사용하십시오. (T4)&lt;/h2&gt;

&lt;p&gt;If hardware accelerated texture compression cannot be used for some textures, then consider using a texture format with fewer components and/or fewer bits per component. Textures for user interface elements sometimes have hard edges or color gradients that result in inferior image quality when compressed. The S3TC algorithm make assumptions that changes are smooth and colors values can be quantized. If these assumptions do not fit a particular image, but the number of unique colors is still low, then experiment with storing these in a packed texture format using 16 bit/texel (e.g. UNSIGNED_SHORT_5_6_5). Although the colors are remapped with less accuracy it may not be noticeable in the final application. Grayscale images should be stored as LUMINANCE and tinted images can sometimes be stored the same way with the added cost of a dot product with the tint color. If normal maps do not compress satisfactory with the LATC format, then it may be possible to store two of the normals coordinates in uncompressed LUMINANCE_ALPHA and derive the third in a shader assuming the direction (sign) of the normal is implicit (as is the case of a heightmap terrain).&lt;/p&gt;

&lt;p&gt;특정 텍스쳐에서 하드웨어 가속 압축을 사용할 수 없을 때, 컴포넌트나 컴포넌트 별 비트 수를 줄이는 것을 고려해 보세요. UI 요소를 위한 텍스쳐는 가끔 압축을 사용할 때 낮은 이미지 퀄리티를 보여주는 하드 엣지나 컬러 그래디언트를 가질때가 가끔 있습니다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;S3TC&lt;/code&gt; 알고리즘은 부드럽고 양자회 될 수 있는 색을 변화시킨다고 가정합니다. 만약 이 가정이 특정 이미지에 맞지 않고 유일한 색의 갯수는 여전히 적다면, &lt;em&gt;texel&lt;/em&gt; 별 16비트를 사용하는 패킹된 텍스쳐 포맷을 사용하여 이를 저장하는 실험을 해보세요.(예를들어 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNSIGNED_SHORT_5_6_5&lt;/code&gt;) 색이 조금 부정확해지더라도, 마지막 결과에서는 눈에 띄지 않을 것입니다. 그레이스케일 이미지는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LUMINANCE&lt;/code&gt; 로 저장되어야 하고, &lt;em&gt;tinted&lt;/em&gt; 이미지의 경우 가끔 &lt;em&gt;tint color&lt;/em&gt; 와 내적하는 비용과 함께 같은 방법으로 저장될 수 있습니다. 노말 맵을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LATC&lt;/code&gt; 포맷으로 만족할만큼 압축하지 못한다면, 압축되지 않은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;LUMINANCE_ALPHA&lt;/code&gt; 에 두 좌표값을 저장하고, 세번째 좌표값은 쉐이더에서 암시적인 방향을 설정하여 계산할 수 있습니다.(heightmap 지형의 경우)&lt;/p&gt;

&lt;p&gt;Note: When optimizing uncompressed textures, the exception case that 24-bit (RGB) textures are not necessarily faster to download or smaller in memory than 32-bit (RGBA) on most GPUs. In this case, it may be possible to use the last component for something useful. For instance, if there already is an 8-bit greyscale texture that is needed at the same time as an opaque color texture, that single component texture can be stored in the unused alpha component of a 32-bit (RGBA). The component could define a specular/reflectance map that describe where and to what degree light is reflected. This is useful for terrain satellite imagery or land cover textures with water/snow/ice areas or for car textures with their metal and glass surfaces or for textures for buildings with glass windows.&lt;/p&gt;

&lt;p&gt;참고: 압축되지 않은 텍스쳐를 최적화할 때, 24-bit(RGB) 텍스쳐가 빠르게 다운로드 하지 않아도 되거나, 32-bit(RGBA) 보다 메모리가 작을 때는 대부분의 GPU에선 예외입니다. 이 경우, 마지막 컴포넌트를 유용하게 사용할 수 있을 것입니다. 예를들어 이미 8-bit 그레이스케일 텍스쳐가 불투명 색 텍스쳐와 함께 사용될 때, 32-bit(RGBA)의 미사용 알파 컴포넌트를 사용할 수 있습니다. 이 컴포넌트는 어디에, 어느 각도에 빛이 반사되는지 사용하기 위한 &lt;em&gt;specular&lt;/em&gt; 혹은 &lt;em&gt;refelectance&lt;/em&gt; 맵으로 정의할 수 있습니다. 이는 지형 위성 이미지 생성, 땅의 물/눈/얼음 영역, 차의 철과 유리 표면의 구분, 빌딩의 유리창의 구분에 유용하게 사용될 수 있습니다.&lt;/p&gt;

&lt;h2&gt;각각의 텍스쳐 오브젝트에 여러 이미지를 저장하십시오. (T5)&lt;/h2&gt;

&lt;p&gt;There is no requirement that there is a one-to-one mapping between an image and a texture object. Textures objects can contain multiple distinct images. These are sometimes referred to as a “texture atlas” or a “texture page”. The geometry defines texture coordinates that only reference a subset of the texture. Texture atlases are useful for minimizing state changes and enables larger batches when rendering. For example, residential houses and office buildings and factories might all use distinct texture images. But the geometry and vertex layout for each is most likely identical so these could share the same buffer object. If the distinct images are stored in a texture atlas instead of as separate textures, then these different kinds of buildings can all be rendered more efficiently in the same draw call (G7). The texture object could be a 2D texture, a cubemap texture or an array texture.&lt;/p&gt;

&lt;p&gt;이미지와 텍스쳐 오브젝트 간의 반드시 일대일 매핑이 되어야 한다는 요구 사항은 없습니다. 텍스쳐 오브젝트는 여러 구분가능한 이미지를 가질 수 있습니다. 이는 텍스쳐 아틀라스 혹은 텍스쳐 페이지로 종종 불립니다. 기하는 텍스쳐 내의 참조만을 위한 텍스쳐 좌푤르 저장합니다. 텍스쳐 아틀라스는 상태 변화를 최소화 시키고, 한꺼번에 더 많은 렌더링을 가능하게 합니다.(larger batch) 예를들어 단독 주택, 사무실 빌딩 그리고 공장은 서로 다른 텍스쳐 이미지를 사용합니다. 하지만 각각의 기하와 정점 레이아웃은 거의 비슷하기 때문에 같은 버퍼 오브젝트를 공유할 수 있습니다. 만약 다른 이미지가 분리된 텍스쳐 대신 텍스쳐 아틀라스에 저장된다면, 다른 종류의 빌딩이 같은 드로우콜에서 효율적으로 전부 렌더링될 수 있습니다.(G7) 텍스쳐 오브젝트는 2D 텍스쳐, 큐브맵 텍스쳐 혹은 배열 텍스쳐가(array texture) 될 수 있습니다.&lt;/p&gt;

&lt;p&gt;Note: Note that if mipmapping is enabled, the sub-textures in an atlas must have a border wide enough to ensure that smaller mipmaps are not generated using texels from neighboring images. And if texture tiling (REPEAT or MIRRORED_REPEAT) is needed for a sub-image then it may be better to store it outside the texture atlas.&lt;/p&gt;

&lt;p&gt;참고: 밉맵이 활성화 되어 있다면, 각 아틀라스별 실질적인 텍스쳐는 근처 텍셀을 통해 밉맵이 만들어지지 않도록 반드시 적절히 넓은 경계를 가져야 합니다. 만약 텍스쳐 타일링(REPAT, MIRRORED_REPEAT) 이 실질적인 텍스쳐에서 필요하다면 텍스쳐 아틀라스의 바깥에 저장하는 것이 나을 것 입니다.&lt;/p&gt;

&lt;p&gt;Emulating either wrapping mode in a shader by manipulating texture coordinates is possible, but not free. A cubemap texture can sometimes be useful since wrapping and filtering apply per face, but the texture coordinates used must be remapped to a vec3 which may be inconvenient. If all the sub-images have the same or similar size, format and type (e.g. image icons), the images are a good candidate for the array texture extension if supported. Array textures may be more appropriate here than a 2D texture atlas where mipmapping and wrapping restrictions have to be taken into consideration.&lt;/p&gt;

&lt;p&gt;텍스쳐 좌표를 사용하여 쉐이더 내에서 &lt;em&gt;wrapping mode&lt;/em&gt; 를 조작하는 것은 가능하나, 공짜는 아닙니다. 큐브맵 텍스쳐는 &lt;em&gt;wrapping&lt;/em&gt; 및 &lt;em&gt;filtering&lt;/em&gt; 을 표면별로 해주기 때문에 종종 유용하지만, 텍스쳐 좌표가 반드시 vec3 으로 만들어져야해서 불편합니다. 만약 모든 실질적인 텍스쳐가 같거나 더 작은 크기, 포맷 그리고 타입을 가진다면, 이미지는 만약 제공된다면 &lt;em&gt;array texture&lt;/em&gt; 의 좋은 후보입니다. &lt;em&gt;array texture&lt;/em&gt; 들은 밉맵이나 &lt;em&gt;wrapping&lt;/em&gt; 한계를 고려할 때 2D 텍스쳐 아틀라스보다 더 적절합니다.&lt;/p&gt;

&lt;h2&gt;single-precision floating 텍스쳐는 언제나 비쌉니다. (T6)&lt;/h2&gt;

&lt;p&gt;Textures with a floating-point format should be avoided whenever possible. If these textures are simply being used to represent a larger range of values, it may be possible to replace these with fixed point textures and scaling instructions. For instance, unsigned 16-bit integers cannot even accurately be represented by half-precision floats (FP16). These would have to be stored using single precision (FP32) leading to twice the memory and bandwidth requirements. It might be better to store these values in two components using 8 bits (LA8) and spend ALU instructions to unpack them in a shader.&lt;/p&gt;

&lt;p&gt;단일 부동 소수점 포맷 텍스쳐는 가능하면 피하세요. 이런 텍스쳐가 큰 범위의 값을 표현하기 위해 보통 사용된다면, 이는 고정 소수점 텍스쳐와 스케일링 명령으로 바뀔 수 있습니다. 예를 들어 무부호 16-bit 정수는 심지어 반 부동 소수점 숫자로(FP16) 표현할 수 없습니다. 이를 단일 부동 소수점에 저장하는 것은 두배의 메모리와 대역폭을 필요로 하게 됩니다. 이는 8-bit 두 컴포넌트에 저장하고, 이를 쉐이더에서 언팩하는 계산 명령을 소모하는 것이 더 나을 것입니다.&lt;/p&gt;

&lt;p&gt;Note: Floating-point textures may not support anything better than nearest filtering.&lt;/p&gt;

&lt;p&gt;부동 소수점 텍스쳐는 &lt;em&gt;nearest filtering&lt;/em&gt; 보다 더 나은 것을 제공하지 않습니다.&lt;/p&gt;

&lt;h2&gt;거의 대부분의 경우 POT(power-of-two) 텍스쳐를 사용하십시오. (T7)&lt;/h2&gt;

&lt;p&gt;Although Non-Power-of-Two (NPOT) textures are supported in ES2 they come with a CLAMP_TO_EDGE restriction on the wrapping mode (unless relaxed by an extension). More importantly, they cannot be mipmapped (unless relaxed by an extension). For that reason, POT textures should be used when there is not significant memory and bandwidth to be saved from using NPOT. However, an NPOT texture may be padded internally to accommodate alignment restrictions in hardware and that the amount of memory saved might not be quite as large as the width and height suggests. As a rule of thumb, only large (i.e., hundreds of texels) NPOT textures will effectively save a significant amount of memory over POT textures.&lt;/p&gt;

&lt;p&gt;2의 제곱이 아닌(NPOT) 텍스쳐는 ES2 에서 제공되지만, &lt;em&gt;wrapping mode&lt;/em&gt; 에서의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;CLAMP_TO_EDGE&lt;/code&gt; 한계를 가집니다. 더 중요한 것은, 밉맵을 사용할 수 없습니다.(확장으로 늘어나지 않는다면) 이 이유 때문에 POT 텍스쳐는 NPOT 텍스쳐가 메모리와 대역폭을 줄일 수 없으므로, 사용되어야 합니다. 하지만 NPOT 텍스쳐는 하드웨어에서 &lt;em&gt;alignment&lt;/em&gt; 한계를 수용하기 위해 내부적으로 패딩되지만, width, height 를 더 늘려서 메모리의 양은 충분히 절약되지 못합니다. 경험적으로 오직 큰 NPOT 텍스쳐들이(즉, 수백개의 텍셀들) POT 텍스쳐 보다 의미있는 메모리 양을 아낄 수 있습니다.&lt;/p&gt;

&lt;h2&gt;텍스쳐 업데이트는 드물게 (T8)&lt;/h2&gt;

&lt;p&gt;Writing to GPU resources can be expensive—it applies to textures as well. If texture updates are required, then determine if they really need to be updated per frame or if the same texture can be reused for several frames. For environment maps, unless the lighting or the objects in the environment have been transformed (e.g., moved/rotated) sufficiently to invalidate the previous map, the visual difference may not be noticeable but the performance improvement can be. The same applies to the depth texture(s) used for shadow mapping algorithms.&lt;/p&gt;

&lt;p&gt;GPU 리소스에 쓰기-텍스쳐에 저장하는 것은 비쌀 수 있습니다. 텍스쳐 업데이트가 필요하다면, 프레임별로 업데이트가 필요한지, 몇 프레임 동안 재사용이 가능한지 결정해야 합니다. 환경 맵의 경우, 이전의 맵이 무효화 되기에 충분할 만큼 라이팅이나 환경의 오브젝트들이 바뀌지 않은 경우, 시각적 차이는 크게 보이지 않지만, 성능 향상은 있을 수 있습니다. &lt;em&gt;shadow mapping&lt;/em&gt; 을 위한 깊이 텍스쳐도 같이 적용 가능합니다.&lt;/p&gt;

&lt;h2&gt;텍스쳐 업데이트는 효율적으로 (T9)&lt;/h2&gt;

&lt;p&gt;When updating an existing texture, use TexSubImage instead of re-defining its entire contents with TexImage when possible.&lt;/p&gt;

&lt;p&gt;존재하는 텍스쳐를 업데이트할 때, 가능하다면 전체 내용을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TexImage&lt;/code&gt; 와 함께 재정의 하는 대신 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TexSubImage&lt;/code&gt; 을 사용하세요.&lt;/p&gt;

&lt;p&gt;Note: When using TexSubImage it is important to specify the same texture format and data type with which that the texture object was defined; otherwise, there may be an expensive conversion as texels are being updated.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TexSubImage&lt;/code&gt; 을 사용할 때, 정의된 텍스쳐 오브젝트와 같은 텍스쳐 포맷 및 데이터 타입을 명시하세요; 그렇지 않으면 업데이트 시 각 &lt;em&gt;texel&lt;/em&gt; 들을 비싸게 변환시켜야 합니다.&lt;/p&gt;

&lt;p&gt;If the application is only updating from a sub-rectangle of pixels in client memory, then remember that the driver has no knowledge about the stride of pixels in your image. When the width of the image rectangle differs from the texture width, this normally requires a loop through single pixel rows calling TexSubImage repeatedly while updating the client memory offsets with pointer arithmetic. In this case, the unpack_subimage extension can be used (if supported) to set the UNPACK_ROW_LENGTH pixelstore parameter to update the entire region with one TexSubImage call.&lt;/p&gt;

&lt;p&gt;만약 응용 프로그램이 클라이언트 메모리 내에서 부분 사각형의 픽셀들로부터 업데이트 해야 한다면, 드라이버는 당신의 이미지 내의 픽셀의 스트라이드를 모른다는 것을 기억하세요. 이미지 사각형의 넓이가 텍스쳐 크기에 따라 달라질 때, 보통 한 행별로 클라이언트 메모리에서 포인터 연산을 통해 &lt;em&gt;TexSubImage&lt;/em&gt; 를 호출하는 것을 반복적으로 루프에서 처리해줘야 합니다. 이 경우 &lt;em&gt;unpack_subimage&lt;/em&gt; 확장을(지원한다면) 한번의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TexSubImage&lt;/code&gt; 호출과 함께 전체 영역을 업데이트 하기 위해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;UNPACK_ROW_LENGTH&lt;/code&gt; 픽셀저장 파라미터를 설정하여 사용할 수 있습니다.&lt;/p&gt;

&lt;h2&gt;각각의 알파 테스팅/블렌딩 렌더링을 다른 렌더링과 분리하십시오. (T10)&lt;/h2&gt;

&lt;p&gt;It is sometimes possible to improve performance by splitting up the rendering based on whether alpha blending or alpha testing is required. Use separate draw calls for opaque geometry so these can be rendered with maximum efficiency with blending disabled. Perform other draw calls for transparent geometry with alpha blending enabled, taking into account the draw ordering that transparent geometry requires. As always, benchmarks should be run to determine if this improves or reduces the frame rate since you will be batching less by splitting up draw calls.&lt;/p&gt;

&lt;p&gt;알파 블렌딩이나 알파 테스팅이 필요한지 아닌지에 따라 렌더링을 분리하는 것은 성능 향상의 가능성을 가지고 있습니다. 불투명 오브젝트를 위해 드로우콜을 분리하세요, 그러면 블렌딩이 비활성화 되어 있어 효율적으로 렌더링할 수 있습니다. 알파 블렌딩이 켜진 상태에서 다른 투명 오브젝트의 드로우콜을 실행하고, 필요한 투명 오브젝트의 정렬을 고려하세요. 항상 그렇듯이, 이는 drawcall 의 batching 을 줄이므로, 이 방법이 &lt;em&gt;frame rate&lt;/em&gt; 를 증가시킬지, 감소시키는지 결정하기 위해 벤치마크를 하세요.&lt;/p&gt;

&lt;h2&gt;적절하게 텍스쳐 필터링 하십시오. (T11)&lt;/h2&gt;

&lt;p&gt;Do not automatically set expensive texture filters and enable anisotropic filtering. Remember that nearest-neighbor filtering always fetches one texel, bilinear filtering fetches up to four texels and trilinear fetches up to eight texels. However, it can be incorrect to draw assumptions about the performance cost based on this. Bilinear filtering may not cost four times as much as nearest filtering, and trilinear can be more or less than twice as expensive as bilinear. Even though textures have mipmaps, it does not automatically mean trilinear filtering should be used. That decision should be made entirely from observing the images from the running application. Only then can a judgment be made if any abrupt changes between mipmap levels are visually disturbing enough to justify the cost of interpolating the mipmaps with trilinear filtering. The same applies to anisotropic filtering, which is significantly more expensive and bandwidth intensive than bilinear or trilinear filtering. If the angle between the textured primitives and the projection plane (e.g. near plane) is never very large, there is nothing to be gained from sampling anisotrophically and there is potentially lower performance. Therefore, an application should start off with the simplest possible texture filtering and only enable more expensive filtering after users have inspected the output images. It might be worthwhile to benchmark the changes and take notes along the way. This will provide a better indication of the relative cost of filtering method and if concessions must be made if the performance budget is exceeded.&lt;/p&gt;

&lt;p&gt;자동으로 비싼 텍스쳐 필터를 설정하지 말고, &lt;em&gt;anisotropic filtering&lt;/em&gt; 을 활성화 하세요. &lt;em&gt;nearest-neighbor filtering&lt;/em&gt; 은 하나의 텍셀, &lt;em&gt;bilinear filtering&lt;/em&gt; 은 4개의 텍셀, &lt;em&gt;trilinear filtering&lt;/em&gt; 은 8개의 텍셀을 가져오는 것을 명심하세요. 하지만 이를 기반으로 성능 비용에 대한 가정을 세우는건 부정확합니다. &lt;em&gt;bilinear filtering&lt;/em&gt; 은 &lt;em&gt;nearist filtering&lt;/em&gt;  처럼 4배만큼 비용이 들지 않으며, &lt;em&gt;trilinear filtering&lt;/em&gt; 은 &lt;em&gt;bilinear filtering&lt;/em&gt; 의 두배 내외의 비용을 가질 수 있습니다. 텍스쳐가 밉맵이 있다면, 자동으로 &lt;em&gt;trilinear filtering&lt;/em&gt; 을 사용하는 것을 의미하는 것은 아닙니다. 이 결정은 실행중인 응용프로그램에서부터 이미지를 관찰하며 전체적으로 만들어져야 합니다. &lt;em&gt;anisotropic filtering&lt;/em&gt; 또한 같이 적용되며, 이는 &lt;em&gt;bilinear&lt;/em&gt;, &lt;em&gt;trilinear&lt;/em&gt; 보다 더 비싸고 대역폭도 많이 차지합니다. 텍스쳐화된 도형과 카메라 평면의 각도가 매우 크다면, 비등방성(&lt;em&gt;anisotropic&lt;/em&gt;) 샘플링에서는 아무것도 얻을 수 없고 낮은 성능을 가질 수 있습니다. 그러므로, 응용 프로그램은 처음에는 가능한 제일 간단한 필터링으로 시작하여,사용자가 더 나은 결과 이미지를 보려한 후에 더 비싼 필터링을 활성화하세요. 변화에 따라 기록하며 벤치마크하는 것은 의미있을 것입니다.&lt;/p&gt;

&lt;h2&gt;텍스쳐 타일링을 활용하려 노력하십시오. (T12)&lt;/h2&gt;

&lt;p&gt;It is common for images to contain the same repeated pattern of pixels. Or an image might repeat a few patterns that are close enough in similarity that they could be replaced with a single pattern without impacting image quality. Tiling textures saves on memory and bandwidth. Some image processing applications can identify repeated patterns and can crop them so they can be tiled infinitely without seams when using textures with the REPEAT wrap mode. Sometimes even a quarter of a tile or shingle may be sufficient to store while using MIRRORED_REPEAT. Consider if tiling variation can be restored or achieved with multi-texturing, using for instance a less expensive grey-scale texture that repeats at a different frequency to modulate the texels from the tiled texture.&lt;/p&gt;

&lt;p&gt;같은 반복되는 패턴의 픽셀을 가진 이미지는 흔합니다. 이미지 퀄리티에 영향을 끼치지 않고 하나의 패턴으로 바꿀만한 충분한 유사성을 가진 몇 패턴을 반복할 수도 있습니다. 텍스쳐 타일링은 메모리와 대역폭을 아낄 수 있습니다. 몇몇 이미지 처리 응용 프로그램은 반복되는 패턴을 인지하고 버릴 수도 있습니다. &lt;em&gt;REPEAT&lt;/em&gt; &lt;em&gt;wrap mode&lt;/em&gt; 의 텍스쳐를 사용할 때 &lt;em&gt;seam&lt;/em&gt; 없이 무한한 타일링이 가능합니다. 심지어 가끔 타일 혹은 지붕 덮개를 &lt;em&gt;MIRRORED_REPEAT&lt;/em&gt; 를 사용하고, 4분의 1만 저장해도 충분할 수도 있습니다. 여러가지 타일링 방법이 여러 텍스쳐와 함께 처리될 수 있는지 고려하세요. 예를들어 덜 비싼 그레이스케일 텍스쳐를 타일링된 텍스쳐와 다른 주파수를 통해 섞을 수도 잇습니다.&lt;/p&gt;

&lt;h2&gt;프레임 버퍼 오브젝트를(FBO) 동적으로 생성되는 텍스쳐를 위해 사용하십시오. (T13)&lt;/h2&gt;

&lt;p&gt;OpenGL ES comes with functions for copying previously rendered pixels from a framebuffer into a texture (TexCopyImage, TexCopySubImage). These functions should be avoided whenever possible for performance reasons. It is better to bind a framebuffer object with a texture attachment and render directly to the texture. Make sure you check for framebuffer completeness.&lt;/p&gt;

&lt;p&gt;OpenGL ES 는 프레임버퍼에서 이전에 렌더링된 픽셀을 텍스쳐에 복사하는 기능을 제공합니다. (&lt;em&gt;TexCopyImage&lt;/em&gt;, &lt;em&gt;TexCopySubImage&lt;/em&gt;) 이 기능들은 성능상의 이유로 피해야 합니다. 프레임 버퍼 오브젝트를 참조할 텍스쳐로 사용하여(&lt;em&gt;texture attachment&lt;/em&gt;) 직접 텍스쳐에 렌더링 하는 것이 더 낫습니다. 프레임버퍼 완전성을 확인하세요.&lt;/p&gt;

&lt;p&gt;Note: Not all pixel formats are color-renderable. Formats with 3 or 4 components in 16 or 32 bits are color-renderable in OpenGL ES 2.0, but LUMINANCE and/or ALPHA may require a fall-back to TexCopyImage functions.&lt;/p&gt;

&lt;p&gt;참조: 모든 픽셀이 색 렌더링이 가능한건 아닙니다. 16-bit, 32-bit 컴포넌트를 3,4 개 가진 포맷은 OpenGL ES 2.0 에서 색 렌더링이 가능하지만, &lt;em&gt;LUMINANCE&lt;/em&gt; 와 &lt;em&gt;ALPHA&lt;/em&gt; 는 &lt;em&gt;TexCopyImage&lt;/em&gt; 함수를 사용하는 것을 대비해야 합니다.&lt;/p&gt;

&lt;h1&gt;기타&lt;/h1&gt;

&lt;p&gt;This topic contains miscellaneous OpenGL ES programming tips.&lt;/p&gt;

&lt;p&gt;해당 주제는 기타 OpenGL ES 프로그래밍 팁을 담고 잇습니다.&lt;/p&gt;

&lt;h2&gt;FBO 내용을 다시 읽는 것을 피하십시오. (M1)&lt;/h2&gt;

&lt;p&gt;Reading back the framebuffer flushes the GL pipeline and limits the amount CPU/GPU parallelism. Reading frequently or in the middle of a frame stalls the GPU and limits the throughput with lower frame rate as a result. If the buffer contents must be read back (perhaps for picking 3D objects in a complex scene), it should be done minimally and scheduled at the beginning of the next frame. In the special case that the application is reading back into a sub-rectangle of pixels in client memory, the pack_subimage extension (if supported) is very useful. Setting the PACK_ROW_LENGTH pixel store parameter will reduce the loop overhead that will otherwise be necessary (T9).&lt;/p&gt;

&lt;p&gt;프레임버퍼를 다시 읽는 것은 &lt;em&gt;GL pipeline&lt;/em&gt; 을 비우며, 많은 CPU/GPU 병렬성을 제한합니다. 자주 혹은 프레임 처리 중간에서 읽는 것은 GPU 의 &lt;em&gt;stall&lt;/em&gt; 을 야기하고, 처리량을 제한시켜 결과적으론 낮은 &lt;em&gt;frame rate&lt;/em&gt; 를 가진다. 버퍼 내용이 반드시 다시 읽혀야 한다면(만약에 복잡한 환경에서 3D 오브젝트를 피킹해야 한다면), 최소한으로 실행되고, 다음 프레임의 시작에서 되도록 스케쥴링 해야 합니다. 응용 프로그램이 부분 사각형 내의 픽셀을 클라이언트 메모리로 읽어와야 하는 특별한 경우, &lt;em&gt;pack_subimage&lt;/em&gt; 확장(지원하면)은 유용합니다. &lt;em&gt;PACK_ROW_LENGTH&lt;/em&gt; 파라미터를 설정하여 루프 오버헤드를 필요한 만큼으로 줄일 수 있습니다. (t9)&lt;/p&gt;

&lt;h2&gt;필요없는 버퍼 청소를 피하십시오. (M2)&lt;/h2&gt;

&lt;p&gt;If the application always covers the entire color buffer for each frame, then bandwidth can be saved by not clearing it. It is a common mistake to call Clear(GL_COLOR_BUFFER_BIT) when it is not necessary. If only part of the color buffer is modified, then constrain pixel operations to that region by enabling scissor testing and define a minimal scissor box for the region. The same applies to depth and stencil buffers if full screen testing is not needed.&lt;/p&gt;

&lt;p&gt;응용 프로그램이 항상 각 프레임별로 전체 색 버퍼를 처리하는 경우, 비우지 않음으로써 대역폭을 아낄 수 있습니다. 이는 필요하지 않아도 청소하는(GL_COLOR_BUFFET_BIT) 일반적인 실수입니다. 색 버퍼의 일부만 수정되었다면, &lt;em&gt;scissor testing&lt;/em&gt; 을 활성화하여 픽셀 연산을 제한시키고, 최소한의 &lt;em&gt;scissor box&lt;/em&gt; 를 정의하세요. 전체화면 테스트가 필요하지 않은 경우 깊이 버퍼와 스텐실 버퍼 또한 마찬가지입니다.&lt;/p&gt;

&lt;h2&gt;필요하지 않은 블렌딩은 비활성화 하십시오. (M3)&lt;/h2&gt;

&lt;p&gt;Most blending operations require a read and a write to the framebuffer.&lt;/p&gt;

&lt;p&gt;대부분의 블렌딩 연산은 프레임버퍼 읽기/쓰기 가 필요합니다.&lt;/p&gt;

&lt;p&gt;Note: Memory bandwidth is often doubled when rendering with blending is enabled. The number of blended fragments should be kept to a minimum—it can drastically speed up the GL application.&lt;/p&gt;

&lt;p&gt;보통 메모리 대역폭은 블렌딩이 활성화 된 경우 두배로 커집니다. 블렌드된 _fragment_의 숫자를 최소한으로 유지키세요-이는 GL 응용 프로그램의 엄청난 속도 향상이 가능합니다.&lt;/p&gt;

&lt;h2&gt;메모리 파편화를 최소화 하십시오. (M4)&lt;/h2&gt;

&lt;p&gt;Buffer objects and glTexImage* functions are effectively graphics memory allocations. Reusing existing buffer objects and texture objects will reduce memory fragmentation. If geometry or textures are generated dynamically, the application should allocate a minimal pool of objects for this purpose during application initialization. It may be that two buffers or textures used in a round-robin fashion are optimal for reducing the risk that the GPU is waiting on the resource. Also, recall that sampling a texture that is being rendered to, at the same time, is undefined. This can be another reason to alternate between objects. For more information, see Memory Fragmentation in this appendix.&lt;/p&gt;

&lt;p&gt;버퍼 오브젝트와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;glTexImage*&lt;/code&gt; 류의 함수는 효과적인 그래픽 메모리 할당입니다. 존재하는 버퍼 오브젝트 및 텍스쳐 오브젝트를 재사용하여 메모리 파편화를 줄일 수 있습니다. 만약 기하 혹은 텍스쳐가 동적으로 만들어진다면, 응용 프로그램은 초기화 동안 최소한의 오브젝트 풀을 할당합니다. 이는 두 버퍼와 텍스쳐를 라운드로빈 방법으로 사용하여 GPU가 리소스를 기다리는 리스크를 줄이는 최적의 방법입니다. 또한 텍스쳐를 동시에 샘플링 하는 것은 정의되지 않았습니다. 이는 오브젝트 간의 대체제를 사용할 다른 이유입니다. 더 많은 정보는 Appendix 의 메모리 파편화 항목을 보세요.&lt;/p&gt;

&lt;h1&gt;OpenGL ES 최적화 하기&lt;/h1&gt;

&lt;p&gt;Optimization is an iterative process. It can be time consuming, especially without prior experience determining where bottlenecks tend to occur. Effort should be directed towards the critical areas instead of starting a random place in the rendering code. When the graphics application is complex it may be difficult to know where to start or exactly where optimizations will yield the best return.&lt;/p&gt;

&lt;h2&gt;관리가능한 청크로 분석 나누기 Partition the analysis into manageable chunks&lt;/h2&gt;

&lt;p&gt;Many rendering applications are complex and consist of hundreds of objects. But usually they consist of logically separate rendering code. For example, a rendered image may consist of roads, buildings, landmarks, points of interest, sky, clouds, buildings, water, terrain, icons, and a 2D user interface. It is helpful to write the GL application such that rendering of each type of object can be disabled easily. This allows easy identification of the most expensive objects when benchmarking and therefore makes optimizing the rendering code more manageable.&lt;/p&gt;

&lt;h2&gt;그래픽 파이프라임의 병목에 익숙해지기&lt;/h2&gt;

&lt;p&gt;It is important to begin optimizations by identifying the performance bottlenecks at the different stages in the graphics pipeline. Because the work introduced in the beginning of the pipeline normally affects the work needed at later stages, it often makes sense to work backwards from the end of the pipeline. An introduction to identifying graphics bottlenecks can be found in the GPU Gems book, “Chapter 28. Graphics Pipeline Performance” (Cem Cebenoyan, NVIDIA).&lt;/p&gt;

&lt;h1&gt;메모리 파편화 피하기&lt;/h1&gt;

&lt;p&gt;Memory Fragmentation generally is a bad thing. This is especially true for computer graphics applications. In addition to avoiding system memory fragmentation, a graphics application should strive to avoid video memory fragmentation as well.
Fortunately, controlling video memory fragmentation has techniques very similar to those used to avoid system memory fragmentation. Since system memory fragmentation control is fairly well known, this document will only treat system memory issues in passing and focuses on video memory techniques.&lt;/p&gt;

&lt;h1&gt;비디오 메모리 개괄&lt;/h1&gt;

&lt;p&gt;Video memory is much more heterogenous than system memory.
NVIDIA video memory allocation algorithms have to take the following into account:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;There are multiple types of video memory types. The number and names of the types vary by GPU model, but GPUs generally have at least two; linear, which is essentially unformatted, and one or more GPU specific types. The GPU tracks different types of memory, and will access and write them differently. The types are important because GPU native types can be faster for a given set of operations; in some GPU architectures, the difference is small, on the order of 10-15%. On others, it can be quite large, more than 100% faster than linear memory.&lt;/li&gt;
  &lt;li&gt;Video memory is often banked, especially for mipmapped textures. In most architecture, alternating mipmap levels for a given texture must be put in separate banks. This separation is mandatory in most NVIDIA GPUs.&lt;/li&gt;
  &lt;li&gt;In addition to the restrictions above, different memory regions have different alignment restrictions, to match host pages, improve DMA performance, or speed up framebuffer scan out. These alignment requirements may be orthogonal to the memory types, adding further complication.&lt;/li&gt;
  &lt;li&gt;The allocator may have other special restrictions that enhance performance, such as distributing allocations to a sequence of different banks to improve allocation speed.&lt;/li&gt;
  &lt;li&gt;These extra constraints complicate the video memory allocator, and make allocations much more sensitive to reductions in available video memory. This is the major reason why NVIDIA does not support multiple independent heaps in video memory, instead requiring the application to allocate in such a way as to minimize fragmentation.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1&gt;비디오 메모리 할당/해제&lt;/h1&gt;

&lt;p&gt;This topic describes considerations for allocating and freeing video memory.&lt;/p&gt;

&lt;h2&gt;버퍼 할당&lt;/h2&gt;

&lt;p&gt;When using OpenGL ES/EGL, there is only a small set of APIs that actually lead to long-term video memory buffer allocation:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;glBufferData(enum target, sizeiptr size, const void *data, enum usage)
 
glTexImage2D(enum target, int level, int internalFormat, sizei width, sizei height, int border, enum format, enum type, const void *pixels)
 
glCopyTexImage2D(enum target, int level, enum internalformat, int x, int y, sizei width, sizei height, int border)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note: The glCopyTexImage2D function allocates only when it copies to a null.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;eglCreateWindowSurface(EGLDisplay dpy, EGLConfig config, NativeWindowType win, const EGLint *attrib_list)
 
eglCreatePbufferSurface(EGLDisplay dpy, EGLConfig config, const EGLint *attrib_list)
 
eglCreatePixmapSurface(EGLDisplay dpy, EGLConfig config, NativePixmapType pixmap, const EGLint *attrib_list)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2&gt;버퍼 해제&lt;/h2&gt;

&lt;p&gt;A similar set of APIs free allocated video memory buffers, whether they are textures, VBOs, or surfaces:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;glDeleteBuffers(sizei n, uint *buffers)
 
glDeleteTextures(sizei n const uint *textures)
 
eglDestroySurface(EGLDisplay dpy, EGLSurface surface)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Note: The glDeleteTextures function works only if the texture object is greater than zero; the default texture can’t be explicitly deleted (although it can be replaced with a texture containing one or two dimensions of zero, which accomplishes the same thing).
Conceptually, these calls can be thought of as malloc() and free() for VBOs and texture maps, respectively. The same techniques for avoiding fragmentation can also be applied.&lt;/p&gt;

&lt;h2&gt;버퍼의 부분지역(subregion) 업데이트&lt;/h2&gt;

&lt;p&gt;In many cases, avoiding fragmentation means placing multiple objects into the same shared buffer, or reusing a buffer by deleting or overwriting an older object with a newer one. OpenGL ES provides a method for updating an arbitrary section of allocated VBOs, textures, and surfaces:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;glBufferSubData(enum target, intptr offset, sizeiptr size, const void *data, enum usage)
 
glTexSubImage2D(enum target, int level, int xoffset, int yoffset, sizei width, sizei height, enum format, enum type, const void *pixels)
 
glCopyTexSubImage2D(enum target, int level, int xoffset, int yoffset, int x, int y, sizei width, sizei height)
 
glScissor(int left, int bottom, sizei width, sizei height);
 
glViewport(int x, int y, sizei w, sizei h)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The glTexSubImage2D and glCopyTexSubImage2D function update a subregion of the target texture image. In the first case, the source comes from an application buffer; in the second, from a rendering surface.
The glScissor and glViewport functions limit rendering to a subregion of a rendering surface. The first specifies the region of the buffer that the glClear function will affect; the second updates the transforms to limit rendered OpenGL ES primitives to the specified subregion.&lt;/p&gt;

&lt;h2&gt;버퍼의 부분지역(subregion) 사용&lt;/h2&gt;

&lt;p&gt;Completing the functionality needed to reuse allocated buffers is the ability to use an arbitrary subregion of a texture, VBO, or surface:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;glDrawArrays(enum mode, int first, sizei count)
 
glReadPixels(int x, int y, sizei width, sizei height, enum format, enum type, void *data)
 
glCopyTexImage2D(enum target, int level, int x, int y, sizei width, sizei height)
 
glCopyTexSubImage2D(enum target, int level, int xoffset, int yoffset, int x, int y, sizei width, sizei height)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;For VBOs, the glDrawArrays function allows the application to choose a contiguous subset of a VBO.
For textures, there’s no explicit call to limit texturing source to a particular subregion. But texture coordinates and wrapping modes can be specified in order to render an arbitrary subregion of texture object.
For surfaces, the glReadPixels function can be used to read from a subregion of a display, when copying data back to an application-allocated buffer.&lt;/p&gt;

&lt;p&gt;The glCopyTexImage2D and glCopyTexSubImage2D functions also restrict themselves to copying from a subregion of the display surface when transferring data to a texture map. The only area that’s problematic is controlling the direct display of window surface back buffer. OpenGL ES and EGL have no way to show only a subregion of the backbuffer surface, but the native windowing systems may have this functionality.&lt;/p&gt;

&lt;h1&gt;비디오 메모리 관리 좋은 예시&lt;/h1&gt;

&lt;p&gt;The following is a list of good practices when allocating video memory to avoid or minimize fragmentation:&lt;/p&gt;

&lt;h2&gt;1. 큰 버퍼를 미리 할당하기&lt;/h2&gt;

&lt;p&gt;Ideally allocate large buffers at the start of the program. On average, allocating large surfaces gets more difficult as more allocations occur. When more allocations occur, free space is broken into smaller pieces.&lt;/p&gt;

&lt;h2&gt;2. 수많은 적은 메모리 할당을 적은 갯수의 많은 할당으로 합치기&lt;/h2&gt;

&lt;p&gt;Small allocations can disproportionately reduce available free space. Not only does the allocator have a fixed overhead per allocation, regardless of size, but small allocations tend to break up large areas of free space into smaller pieces.
The ability to load a subregion of a VBO or texture map, and the ability to render that subregion independently, makes it possible to combine VBOs and textures together. For textures, a large texture can be used to hold a grid of smaller images. For VBOs, multiple vertex arrays can be combined end to end into a larger one. Besides reducing fragmentation, combining related images into a single texture, and related vertex arrays into a single VBO often improves rendering time, since it reduces the number of glBindBuffer or glBindTexture calls required to render a set of related objects.&lt;/p&gt;

&lt;h2&gt;3. 할당된 버퍼 사이즈의 분포를 줄이고, 이상적으로 하나의 사이즈로 만들기&lt;/h2&gt;

&lt;p&gt;Allocating buffers of varying sizes, especially sizes that aren’t small multiples of each other, is disruptive of memory space and causes fragmentation. The ability to load and render a subset of a VBO or texture means that data loaded doesn’t have to match the size of the allocated buffer; as long as it’s smaller, it will work.
This approach does waste space, in that some of the allocated buffer isn’t used, but this waste is often offset by the saving in reduced fragmentation and fixed allocation overhead. This approach can often be combined with approach (2) (combining multiple objects into one allocated buffer) to reduce total wastage. Generally, it’s safe to ignore wastage it it’s a small percentage of the allocated buffer size (say &amp;lt; 5%).
This approach is particularly good for dynamically allocated data, since fixed size blocks can often be freed and reallocated with little or no fragmentation. If wastage is excessive, a set of buffer sizes can be chosen (often a consecutive set of power of two sizes), and the smallest free buffer that will contain the data is used.&lt;/p&gt;

&lt;h2&gt;4. 가능한 버퍼를 해제/재할당 하지말고 재사용하기&lt;/h2&gt;

&lt;p&gt;The ability to reload a previously allocated buffer with new data for both VBOs and textures makes this technique practical. Reuse is particularly important for large buffers; it is often better to create a large buffer at program start, and reuse it during mode switches, etc., even if it requires allocating a larger buffer to handle all possible cases.&lt;/p&gt;

&lt;h2&gt;5. 동적할당 최소화 하기&lt;/h2&gt;

&lt;p&gt;If possible, take memory allocation and freeing out of the inner loop of your application. The ability to reuse buffers makes this practical, even for algorithms that require dynamic allocation. Even with reuse, however, it’s still better to organize the code to minimize allocations and frees, and to move the remaining ones out of the main code path as much as possible.&lt;/p&gt;

&lt;h2&gt;6. 여러 동적 할당을 묶으려 노력하기&lt;/h2&gt;

&lt;p&gt;If dynamic allocation is mandatory, try to group similar allocations and frees together. Ideally, an allocation of a buffer is followed by freeing it before another allocation happens. This rarely can be done in practice, but combining a group of related allocations is often nearly as effective.
Again, allocations and frees should be replaced whenever possible. Grouping them is a last resort.&lt;/p&gt;

&lt;h1&gt;그래픽 드라이버 CPU 사용량&lt;/h1&gt;

&lt;p&gt;In some cases, the reported graphics driver CPU usage may be high, but in fact the yield is related to other CPUs. To reduce the reported CPU usage, set the environment variable as follows:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ export __GL_YIELD=USLEEP

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1&gt;성능 가이드라인&lt;/h1&gt;

&lt;p&gt;The NVIDIA Tegra system on a chip (SOC) includes an extremely powerful and flexible 3D GPU whose power is well matched to the OpenGL ES APIs. For basic guidelines and tips on optimal content rendering, see &lt;a href=&quot;https://docs.nvidia.com/drive/drive_os_5.1.6.1L/nvvib_docs/DRIVE_OS_Linux_SDK_Development_Guide/baggage/tegra_gles2_performance.pdf&quot;&gt;OpenGL ES Performance for the Tegra Series Guidelines.&lt;/a&gt;&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="opengles" />
      
        <category term="optimization" />
      

      

      
        <summary type="html">※ docs.nvidia : OpenGL ES Programming Tips의 내용을 번역하는 포스팅입니다. 시간이 꽤 지난 내용으로 글의 내용은 현재 상황과 다를 수 있습니다. 또한 모든 내용이 번역되어 있지 않을 수도 있습니다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Eastl Allocator</title>
      
      <link href="https://suhyeokkim.github.io/2021/01/31/eastl-allocator" rel="alternate" type="text/html" title="Eastl Allocator" />
      <published>2021-01-31T00:00:00+00:00</published>
      <updated>2021-01-31T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2021/01/31/eastl-allocator</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2021/01/31/eastl-allocator">&lt;p&gt;C++ 에서 메모리 관리는 중요한 문제다. &lt;em&gt;garbage collector&lt;/em&gt; 를 지원하는 현대의 많은 언어들과 달리 C++은 OS에서 제공하는 시스템콜을 사용하여 메모리를 직접 할당 받고 반환한다. 하지만 메모리 할당/해제 시스템콜은 가상 페이지 로드 및 병합 비용이 큰 편이고, 성능에 민감한 프로그래머들은 이를 줄이기 위해 고민의 벽에 부딫친다. 이를 개선시키기 위해 많은 사람들이 방법을 고민했다. 그 중에서 필자가 일반적으로 사용하는 방법은 영구/가변 메모리 영역 처럼 단계를 나누어 가상 메모리 페이지 크기 이상의 단위로 할당받아 각각의 뭉텅이에서 공간을 나눠쓰는 방법이다.&lt;/p&gt;

&lt;p&gt;그렇지만 단순히 할당자를 구현하는 것만으로 끝날 문제는 아니다. 직접 컨테이너를 구현하면 입맛에 맞게 쓸 수 있겠지만 여러 비용이 허락해야 가능하고, 사용자 정의 할당자를 지원하는 표준 STL은 여러 제약사항이 존재하기에 쉽지 않다. 하지만 표준 STL과 비슷하게 게임 응용 프로그램을 위해 표준 STL을 개량한 EASTL이라는 대체제를 통해 원하는 메모리 할당자 기능을 쉽게 구현할 수 있었다. 이 글에서는  EASTL에서의 커스텀 메모리 할당자 및 이의 장단점을 서술한다. 해당 포스팅은 EASTL 3.17.06을 기준으로 작성되었다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;누군가의 프로젝트에 EASTL을 처음부터 적용하기 위해선 추가적인 세팅이 몇가지 필요하다. 기본적인 세팅 방법은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;EASTL은 cmake로 프로젝트 파일을 생성해준다. 즉 cmake가 설치되어야 한다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/electronicarts/EASTL&quot;&gt;깃헙 레포지토리&lt;/a&gt;에서 소스를 가져온다.&lt;/li&gt;
  &lt;li&gt;해당 경로에 가서 &lt;em&gt;cmake ./&lt;/em&gt; 를 커맨드라인에서 실행해주면 OS와 프로그램에 맞게 파일을 생성해준다. (conan, vcpkg 를 사용해서도 설치 가능하다고 한다.)&lt;/li&gt;
  &lt;li&gt;cmake가 만든 프로젝트 파일을 통해 정적 라이브러리 파일을 생성한다.&lt;/li&gt;
  &lt;li&gt;라이브러리와 인클루드 헤더를 프로젝트에 적용시킨다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;여기까지는 플랫폼 별로, 사용하는 프로그램 별로 전부 다를 수 있다. 그러니 각자의 상황에 맞게 세팅해야 한다.&lt;/p&gt;

&lt;p&gt;문제는 이대로 사용할 수 없다는 점이다. 링크 에러가 나기 때문이다. 이는 EASTL에서 오버로딩한 new 연산자를 내부에서 참조하고, EASTL 내부에는 참조할 new 연산자가 없기 때문이다. 아래에 명시된 두 new 연산자를 정의해주어야 실행을 위한 프로그램을 빌드할 수 있다. 함수안의 메모리 할당에서 유의할 점은 정렬된 메모리를 항상 할당 해주어야 한다. 아닌 경우에도 최소한의 정렬을 정의해 놓은 &lt;em&gt;EASTL_ALLOCATOR_MIN_ALIGNMENT&lt;/em&gt; 을 사용하여 정렬된 메모리 할당이 필요하다. 아래 소스에서는 정렬된 메모리를 할당하는 vc 기반의 코드를 볼 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;debugFlags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_aligned_offset_malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTL_ALLOCATOR_MIN_ALIGNMENT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alignment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alignmentOffset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pName&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;debugFlags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;file&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;line&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_aligned_offset_malloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alignment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alignmentOffset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기까지 실행하고 빌드한다면 동작은 된다. 이제 EASTL에서 제공하는 컨테이너를 돌려보며 확인해볼 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;eastl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FbxNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodeVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nodeVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fbxScene&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRootNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;여기까지 왔다면 기본적인 세팅은 끝났다. 이제 사용자 지정 할당자를 어떻게 구현했는지 소개해보겠다.&lt;/p&gt;

&lt;p&gt;필자가 원하는 방식대로 구현하기 위해선 사용자 지정 메모리 할당자를 구현해야 했다. 자세한 구현은 아래에서 볼 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EASTLAllocator&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;nl&quot;&gt;public:&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
			&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__FILE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__LINE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)];&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;strcpy_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
			&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__FILE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__LINE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)];&lt;/span&gt;
			&lt;span class=&quot;n&quot;&gt;strcpy_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;strlen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__FILE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__LINE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;sizeof&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)];&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;strcpy_s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allocate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__FILE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__LINE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;allocate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alignment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;flags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;new&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;alignment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;offset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__FILE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__LINE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deallocate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bytes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
		&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;delete&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__FILE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__LINE__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;set_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;nl&quot;&gt;protected:&lt;/span&gt;
	&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 EASTLAllocator는 단순하게 오버로딩한 new/delete를 감싼 구현으로, 중요한 점은 할당될 영역의 이름을 통하여 영역을 선택한다는 것과 EASTL에서 allocate/deallocate로 메모리 할당/해제를 한다는 점이다. 
 처음 보는 사람의 입장에서 의문이 들만한 부분은, delete 또한 오버로딩하여 사용한다는 점이다. 이유는 아래와 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;논리적으로 new/delete는 한 쌍이어서 이를 구현하는게 직관적이다.&lt;/li&gt;
  &lt;li&gt;컨테이너가 아닌 경우에도 new/delete를 사용하여 원하는 방식의 메모리 할당이 가능하다.&lt;/li&gt;
  &lt;li&gt;(필자의 특수한 케이스)작업 당시 이동 생성자는 작동하지 않고 복사 생성자만 작동했다. 그래서 할당자 클래스에서의 구현에서 연산자 오버로딩으로 일반화 했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 구현한 할당자를 바탕으로, 표준 STL에서 사용하든 템플릿 선언을 통해 사용하면 된다. 방법은 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-cpp highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
&lt;span class=&quot;cp&quot;&gt;#define EASTL_TEMPARARY_NAME &quot;temp&quot;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;eastl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;FbxNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EASTLAllocator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nodeVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EASTL_TEMPARARY_NAME&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nodeVector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fbxScene&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;GetRootNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위의 소스에서 표준 STL과 사용 방법이 다른 점은 컨테이너의 생성자에 할당자를 식별하기 위한 문자열을 넣는다는 점이다. 이를 통해 컨테이너는 추가적인 메모리 할당이 필요할 시 오버로딩된 new/delete 함수를 호출하여 할당을 받으려 할 것이다. 필자가 구현한 new/delete 는 &lt;a href=&quot;https://github.com/suhyeokkim/RenderFromScratch/blob/master/Framework/source/allocators.cpp&quot;&gt;RenderFromScratch: allocators.cpp&lt;/a&gt; 에서 볼 수 있다.&lt;/p&gt;

&lt;p&gt;소개한 커스텀 할당자의 구현 이외에도 EASTL은 SSE 지원을 위한 메모리 정렬을 구현하게 만들고, 고정된 크기의 컨테이너와 컨테이너에서 하나의 노드를 사용자가 직접 정의할 수 있는 instrutive 컨테이너도 지원하고, 이외에도 게임 프로그램에서 필요한 세심한 경우들을 처리해 놓았고, 여러 플랫폼(콘솔, PC 등)에서 테스트가 되었다고 한다. 만약 자신이 게임을 밑바닥부터 구현하고, STL의 사용법을 조금이라도 안다면 EASTL을 사용하는 것도 좋은 방법이라고 생각된다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/electronicarts/EASTL&quot;&gt;github : EASTL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://eastl.docsforge.com/&quot;&gt;EASTL docsforge&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html&quot;&gt;open-std : EASTL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://jacking75.github.io/Cpp_EASTL/&quot;&gt;C++ - EASTL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://ohyecloudy.com/pnotes/archives/250/&quot;&gt;EASTL - 할당자(allocator)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="cpp" />
      
        <category term="unmanaged_language" />
      
        <category term="memory_management" />
      
        <category term="game_programming" />
      

      

      
        <summary type="html">C++ 에서 메모리 관리는 중요한 문제다. garbage collector 를 지원하는 현대의 많은 언어들과 달리 C++은 OS에서 제공하는 시스템콜을 사용하여 메모리를 직접 할당 받고 반환한다. 하지만 메모리 할당/해제 시스템콜은 가상 페이지 로드 및 병합 비용이 큰 편이고, 성능에 민감한 프로그래머들은 이를 줄이기 위해 고민의 벽에 부딫친다. 이를 개선시키기 위해 많은 사람들이 방법을 고민했다. 그 중에서 필자가 일반적으로 사용하는 방법은 영구/가변 메모리 영역 처럼 단계를 나누어 가상 메모리 페이지 크기 이상의 단위로 할당받아 각각의 뭉텅이에서 공간을 나눠쓰는 방법이다. 그렇지만 단순히 할당자를 구현하는 것만으로 끝날 문제는 아니다. 직접 컨테이너를 구현하면 입맛에 맞게 쓸 수 있겠지만 여러 비용이 허락해야 가능하고, 사용자 정의 할당자를 지원하는 표준 STL은 여러 제약사항이 존재하기에 쉽지 않다. 하지만 표준 STL과 비슷하게 게임 응용 프로그램을 위해 표준 STL을 개량한 EASTL이라는 대체제를 통해 원하는 메모리 할당자 기능을 쉽게 구현할 수 있었다. 이 글에서는 EASTL에서의 커스텀 메모리 할당자 및 이의 장단점을 서술한다. 해당 포스팅은 EASTL 3.17.06을 기준으로 작성되었다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Eastl Kor</title>
      
      <link href="https://suhyeokkim.github.io/2021/01/31/EASTL-KOR" rel="alternate" type="text/html" title="Eastl Kor" />
      <published>2021-01-31T00:00:00+00:00</published>
      <updated>2021-01-31T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2021/01/31/EASTL-KOR</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2021/01/31/EASTL-KOR">&lt;p&gt;※ &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html&quot;&gt;open-std : EASTL&lt;/a&gt;의 내용을 번역하는 포스팅입니다. 시간이 꽤 지난 내용으로 글의 내용은 현재 상황과 다를 수 있습니다. 또한 모든 내용이 번역되어 있지 않을 수도 있습니다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2&gt;Abstract&lt;/h2&gt;

&lt;p&gt;Gaming platforms and game designs place requirements on game software which differ from requirements of other platforms. Most significantly, game software requires large amounts of memory but has a limited amount to work with. Gaming software is also faced with other limitations such as weaker processor caches, weaker CPUs, and non-default memory alignment requirements. A result of this is that game software needs to be careful with its use of memory and the CPU. The C++ standard library’s containers, iterators, and algorithms are potentially useful for a variety of game programming needs. However, weaknesses and omissions of the standard library prevent it from being ideal for high performance game software. Foremost among these weaknesses is the allocator model. An extended and partially redesigned replacement (EASTL) for the C++ standard library was implemented at Electronic Arts in order to resolve these weaknesses in a portable and consistent way. This paper describes game software development issues, perceived weaknesses of the current C++ standard, and the design of EASTL as a partial solution for these weaknesses.&lt;/p&gt;

&lt;p&gt;게이밍 플랫폼과 게이밍 디자인은 다른 플랫폼과 차별화된 것들을 요구한다. 가장 중요한 것은 게임 소프트웨어는 한정된 양의 많은 메모리를 필요로 한다. 또한 게이밍 소프트웨어는 부족한 캐시 히트, 부족한 코어 연산량, 정렬되지 않은 메모리 상태에 직면해있다. 이의 결과는 게임 소프트웨어가 메모리와 CPU의 사용을 조심하도록 만들었다. C++ 표준 라이브러리의 컨테이너, 반복자, 알고리즘은 게임 프로그래밍의 필요의 여러 방면으로 인해 잠재적인 유용함을 가진다. 하지만 표준 라이브러리의 약점과 누락은 고성능이 필요한 게임 소프트웨어의 경우 이상적이지 않다. C++ 표준 라이브러리를 위한 부분적으로 재설계된, 확장된 대체제:EASTL은 portable 하고 일관적인 방법으로 표준 STL의 약점을 보완하기 위해 구현되었다.&lt;/p&gt;

&lt;h2&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The purpose of this document is to explain the motivation and design of EASTL so that it may help the C++ community better understand the needs of game software development. This document is not a proposal, though some of EASTL’s changes and extensions could form the basis for such discussions. The large majority of EASTL would be useful to any kind of C++ software development.&lt;/p&gt;

&lt;p&gt;이 문서는 C++ 커뮤니티에서 게임 소프트웨어의 개발 시의 요구사항을 이해하는데 도움이 되도록, EASTL의 개발 동기와 구조를 설명한다. 이 문서는 표준 제안이 아니지만 EASTL의 일부 변경 및 확장 사항들이 제안의 기초를 닦을 수 있다고 생각한다. EASTL의 주요 사항들이 여러 C++ 소프트웨어 개발에 유용할 것이기 때문이다.&lt;/p&gt;

&lt;p&gt;This document describes an STL implementation (EASTL) developed within Electronic Arts as an alternative to and extension of the STL defined by the C++ standard library. By STL, we mean the container, iterator, and algorithm components of the C++ standard library, hereafter referred to as std STL (with std referring to the std namespace, whereas the S in STL refers to standard C++). By C++ standard, we mean &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#cpp_standard&quot;&gt;ISO 14882 (1998)&lt;/a&gt; and the 2003 update. The large majority of the design of std STL is excellent and achieves its intended purpose. However, some aspects of it make it hard to use and other aspects prevent it from performing as well as it could. Among game developers the most fundamental weakness is the std allocator design, and it is this weakness that was the largest contributing factor to the creation of EASTL. Secondarily was the lack of std STL containers designed to be memory-friendly. There are additional reasons that will be discussed below.&lt;/p&gt;

&lt;p&gt;이 문서는 Electronic Art 에서 개발된 C++ 표준 라이브러리에 정의된 STL의 대안 및 확장한 EASTL 구현을 설명한다. STL 이라함은, C++ 표준 라이브러리의 컨테이너, 반복자(iterator) 및 알고리즘 같은 구성 요소를 통칭하는 단어이며 해당 문서에서는 이를 EASTL과 구별하기 위하여 표준 STL이라 칭한다. (표준은 std namespace를 말하고, STL의 S는 stardard C++을 의미함) 여기서의 표준은 ISO 140882(1998)을 말한다. 표준 STL의 큰 범위를 커버하는 설계는 훌륭하고 의도된 바를 이룬다. 하지만 특정 경우에 사용하기 힘들고, 또 다른 경우에서는 성능 저하를 일으킬 수 있다. 게임 소프트웨어 개발자 사이에서 가장 근본적인 약점은 표준 STL의 할당자 설계이며, 이는 EASTL 개발의 가장 큰 동기이다. 두번째 이유는 표준 STL이 메모리-친화적이지 않은 것이다. 이외의 여러 이유를 아래에서 논의될 것이다.&lt;/p&gt;

&lt;p&gt;We hope that those reading this document have an open mind to the idea that std STL may not be ideal for all purposes. Before this document was written, sketches of it were shown to some outside of the game development industry. In some cases we found that there was an initial reaction to dismiss an alternative STL and assume that the somebody must be misunderstanding or misusing the STL. But upon explaining game development and high performance software issues and comparing these to std STL’s design and implementation by current vendors, people usually reduce their skepticism. Indeed we have found that those have the most extensive and deep STL experience have been those most enthusiastic about EASTL. We nevertheless have a great respect for the C++ standard library and the great work that has gone into its design and implementation, especially after having gone through the long and difficult process of implementing it.&lt;/p&gt;

&lt;p&gt;이 문서를 읽는 분들이 std STL이 모든 목적에 이상적이지 않을 수 있다는 생각에 열린 마음을 갖기를 바란다. 이 문서가 쓰여지기 전에, 게임 산업 외부의 일부 사람들에게 스케치가 공개되었다. 어떤 경우에는 대체 STL을 무시하고 STL을 오해하거나 오용한다고 가정하는 반응을 보인다. 그러나 게임 개발 및 고성능 소프트웨어 상의 문제를 설명하고, 이를 표준 STL 설계 및 구현과 비교하면 보통 회의론적인 의견을 줄인다. 실제로 우리는 가장 광범위하고 깊은 STL 경험을 겪은 사람들이 EASTL에 대해 가장 열정적이라는 것을 발견했다. 그럼에도 불구하고 우리는 C++ 표준 라이브러리와 특히 그것을 구현하는 길고 어려운 과정을 거친 후 설꼐 및 구현한 작업에 대해 큰 존경을 표한다.&lt;/p&gt;

&lt;p&gt;This document is divided into the following sections. The first section summarizes the motivation for the creation of EASTL and its design; the subsequent sections flow from this.&lt;/p&gt;

&lt;p&gt;이 문서는 아래에 명기된 섹션으로 나뉜다. 첫번째 섹션은 EASTL의 개발 동기와 설계에 대하여, 이후의 섹션들은 이후의 흐름이다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#abstract&quot;&gt;Abstract&lt;/a&gt;
&lt;a href=&quot;#itroduction&quot;&gt;Introduction&lt;/a&gt;
&lt;a href=&quot;#motivation-for-eastl&quot;&gt;Motivation for EASTL&lt;/a&gt;
&lt;a href=&quot;#differences-between-std-stl-and-eastl&quot;&gt;Differences between std STL and EASTL&lt;/a&gt;
&lt;a href=&quot;#&quot;&gt;EASTL functionality summary&lt;/a&gt;
&lt;a href=&quot;#&quot;&gt;Game software issues&lt;/a&gt;
&lt;a href=&quot;#&quot;&gt;std::allocator&lt;/a&gt;
&lt;a href=&quot;#&quot;&gt;eastl::allocator&lt;/a&gt;
&lt;a href=&quot;#&quot;&gt;EASTL containers&lt;/a&gt;
&lt;a href=&quot;#&quot;&gt;EASTL flaws&lt;/a&gt;
&lt;a href=&quot;#&quot;&gt;Appendix&lt;/a&gt;
&lt;a href=&quot;#Acknowledgements&quot;&gt;Acknowledgements&lt;/a&gt;
&lt;a href=&quot;#References&quot;&gt;References&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Throughout this document there are references to the Appendix. The Appendix contains supplementary material which provides more detail about some item of discussion. This material is placed there in order to avoid getting in the way of the primary text, as the material is a bit verbose and is sometimes tangential to the discussion of EASTL. It was nevertheless felt to be important that the Appendix exist in order to provide a better understanding of practical game development issues.&lt;/p&gt;

&lt;p&gt;이 문서를 전체에 Appendix에 대한 참조가 있다. Appendix에는 특정 경우에 대한 논의에 대한 더 디테일한 정보를 담고있는 참고자료가 있다. 이 참고자료는 본문의 주된 논의인 EASTL에서 벗어나지 않고, 디테일한 정보를 담기 위하여 분리되었다. 그럼에도 불구하고 실제 게임 개발의 문제에 대한 더 나은 이해를 제공하기 위해 Appendix를 수록했다.&lt;/p&gt;

&lt;h2&gt;Motivation for EASTL&lt;/h2&gt;

&lt;p&gt;The following is a listing of some of the reasons why std STL and its current implementations are not currently ideal for game development. There are additional reasons, but the list here should hopefully convey to you some sense of the situation. Each of the items listed below deserves a document of its own, as a single sentence alone cannot fully convey the nature or significance of these items. Some of the items refer to the STL design, whereas some of the items refer to existing STL implementations. It would be best if these were discussed independently, but to many users this distinction is often of little practical significance because they have little choice but to use the standard library that comes with their compiler.&lt;/p&gt;

&lt;p&gt;아래 사항들은 표준 STL과 이의 구현이 왜 게임 개발에 이상적이지 않은 이유들이다. 추가적인 이유가 있지만, 명기된 이유들은 상황에 대한 몇가지 이해를 얻을 수 있을 것이다. 아래에 리스팅된 각각의 이유들은 몇개의 문장으로는 의미를 전달할 수 없고 더 자세한 문서화가 필요하다. 몇몇 이유들은 STL의 설계를 이야기 하고, 몇몇 이유들은 존재하는 STL의 구현에 대하여 말한다. 각각 논의된다면 좋겠지만, 많은 사용자들에게  컴파일러와 함께 제공되는 표준 라이브러리를 사용하는 것 외에는 선택의 여지가 거의 없기 때문에 이런 구별은 쓸모있지는 않다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;std STL allocators are painful to work with and lead to code bloat and sub-optimal performance. This topic is addressed &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#std_allocator&quot;&gt;separately within this document&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;표준 STL 할당자는 작업하기 어렵고, 코드를 부풀리고 최선의 퍼포먼스를 이끌지 못한다. 이 주제는 &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#std_allocator&quot;&gt;여기&lt;/a&gt;에서 다룬다.&lt;/li&gt;
  &lt;li&gt;Useful STL extensions (e.g. slist, hash_map, shared_ptr) found in some std STL implementations are not portable because they don’t exist in other versions of STL or are inconsistent between STL versions (though they are present in the current C++09 draft).&lt;/li&gt;
  &lt;li&gt;어떤 표준 STL 구현에서 발견된 유용한 STL 확장은 포터블하지 않다. 해당 확장은 다른 버젼의 STL에서 존재하지 않거나, STL 버젼별로 일관적이지 않다.(하지만 C++09 드래프트에 존재한다.)&lt;/li&gt;
  &lt;li&gt;The STL lacks functionality that game programmers find useful (e.g. &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#intrusive_containers&quot;&gt;intrusive containers&lt;/a&gt;) and which could be best optimized in a portable STL environment. See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_16&quot;&gt;Appendix item 16&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;STL은 게임 프로그래머가 유용하게 사용할 기능이 부족하고(예: &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#intrusive_containers&quot;&gt;intrusive containers&lt;/a&gt;), 그 기능들은 포터블한 STL환경에서 최대한의 최적화될 수 있다. &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_16&quot;&gt;Appendix item 16&lt;/a&gt;를 보라.&lt;/li&gt;
  &lt;li&gt;Existing std STL implementations use deep function calls. This results in low performance with compilers that are weak at inlining, as is the currently prevalent open-source C++ compiler. See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_15&quot;&gt;Appendix item 15&lt;/a&gt; and &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_10&quot;&gt;Appendix item 10&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;존재하는 표준 STL 구현은 깊은 함수 호출을 사용한다. 이는 인라이닝 기능이 약한 컴파일러에서(현재 나타난 오픈소스 C++ 컴파일러) 낮은 성능이 나타난다. &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_15&quot;&gt;Appendix item 15&lt;/a&gt; 와 &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_10&quot;&gt;Appendix item 10&lt;/a&gt;를 보라.&lt;/li&gt;
  &lt;li&gt;Existing STL implementations are hard to debug. For example, you typically cannot browse the contents of a std::list container with a debugger due to std::list’s usage of void pointers. On the other hand, EASTL allows you to view lists without incurring a performance or memory cost. See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_2&quot;&gt;Appendix item 2&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;존재하는 STL 구현은 디버깅이 힘들다. 예를 들어 std::list 컨테이너는 void 포인터를 사용하기 때문에 디버거에서 컨테이너의 아이템을 관찰할 수 없다. 반면, EASTL은 성능이나 추가적인 메모리 비용없이 리스트를 들여다 볼 수 잇다. &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_2&quot;&gt;Appendix item 2&lt;/a&gt;를 보라.&lt;/li&gt;
  &lt;li&gt;The STL doesn’t explicitly support alignment requirements of contained objects, yet non-default alignment requirements are common in game development. A std STL allocator has no way of knowing the alignment requirements of the objects it is being asked to allocate, aside from compiler extensions. Granted, this is part of the larger problem of the C++ language providing minimal support for alignment requirements. Alignment support is proposed for C++09.&lt;/li&gt;
  &lt;li&gt;STL은 명시적으로 컨테이너 내의 개체에 대해 정렬을 지원하지 않지만 아직 디폴트가 아닌 정렬은 게임 개발에서 일반적이다. 표준 STL 할당자는 컴파일러 확장을 제외하면, 할당을 요청하는 객체의 정렬 여부 및 디테일을 알 수 없다. 물론 이는 메모리 정렬에 대한 최소한의 지원을 제공하는 C++언어의 더 큰 문제의 일부다. C++09에서는 이러한 제안이 있긴하다.&lt;/li&gt;
  &lt;li&gt;STL containers won’t let you insert an entry into a container without supplying an entry to copy from. This can be inefficient in the case of elements that are expensive to construct.
The STL implementations that are provided by compiler vendors for the most popular PC and console (box connected to TV) gaming platforms have performance problems. EASTL generally outperforms all existing STL implementations; it does so partly due to algorithmic improvements but mostly due to practical improvements that take into account compiler and hardware behavior. See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_20&quot;&gt;Appendix item 20&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;1234&lt;/li&gt;
  &lt;li&gt;Existing STL implementations are hard to debug/trace, as some STL implementations use cryptic variable names and unusual data structures and have no code documentation. See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_2&quot;&gt;Appendix item 2&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;1234&lt;/li&gt;
  &lt;li&gt;STL containers have private implementations that don’t allow you to work with their data structures in a portable way, yet sometimes this is an important thing to be able to do (e.g. node pools). See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_22&quot;&gt;Appendix item 22&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;1234&lt;/li&gt;
  &lt;li&gt;Many current versions of std STL allocate memory in empty versions of at least some of their containers. This is not ideal and prevents optimizations such as container memory resets that can significantly increase performance in some situations. An empty container should allocate no memory.&lt;/li&gt;
  &lt;li&gt;1234&lt;/li&gt;
  &lt;li&gt;All current std STL algorithm implementations fail to support the use of predicate references, which results in inefficient hacks to work around the problem. See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_3&quot;&gt;Appendix item 3&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;1234
The STL puts an emphasis on correctness before practicality and - performance. This is an understandable policy but in some cases (particularly &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#std_allocator&quot;&gt;std::allocator&lt;/a&gt;) it gets in the way of usability and optimized performance.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Differences between std STL and EASTL&lt;/h2&gt;

&lt;p&gt;First, EASTL provides a set of containers, iterators, and algorithms that are identical in interface and behavior to std STL versions with one exception: allocators. EASTL has a different allocator specification which is simpler, more efficient, more flexible, and easier to use than std::allocator. Both &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#std_allocator&quot;&gt;std::allocator&lt;/a&gt; and &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#eastl_allocator&quot;&gt;eastl::allocator&lt;/a&gt; are described below. EASTL follows the &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#defect_report_list&quot;&gt;defect reports&lt;/a&gt; and &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#TR1&quot;&gt;TR1&lt;/a&gt; as well. EASTL additionally provides and uses some of the TR1 functionality as well, including most significantly the smart pointers, type traits, and hashing containers.&lt;/p&gt;

&lt;p&gt;Second, EASTL provides extension functionality to the above containers, iterators, and algorithms. An example of this is the push_back(void), set_capacity(size), and validate() functions added to eastl::vector. The majority of these extensions are driven by the need for higher performance (push_back(void)), higher clarity (set_capacity), or higher debuggability (validate()). There are about 30 such extensions to the various entities in the library. These are described in detail &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#EASTL_augmentations&quot;&gt;below&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Third, EASTL provides additional containers and algorithms that don’t correspond to std STL. These include intrusive_list, vector_map, fixed_hash_set, slist, ring_buffer, radix_sort, has_trivial_relocate, and others. These are described in detail &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#EASTL_additions&quot;&gt;below&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;There are additional differences not related to the functional specification. They include a programming philosophy that emphasizes readability, consistency, and optimal performance on limited hardware. See &lt;a href=&quot;http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2007/n2271.html#Appendix_23&quot;&gt;Appendix item 23&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;EASTL functionality summary&lt;/h2&gt;

&lt;p&gt;(이곳은 생략합니다.)&lt;/p&gt;

&lt;h2&gt;Game software issues&lt;/h2&gt;

&lt;h2&gt;std::allocator&lt;/h2&gt;

&lt;h2&gt;eastl::allocator&lt;/h2&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="EASTL" />
      

      

      
        <summary type="html">※ open-std : EASTL의 내용을 번역하는 포스팅입니다. 시간이 꽤 지난 내용으로 글의 내용은 현재 상황과 다를 수 있습니다. 또한 모든 내용이 번역되어 있지 않을 수도 있습니다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">What Is Color Spaces And Gamuts</title>
      
      <link href="https://suhyeokkim.github.io/2019/07/11/what-is-color-spaces-and-gamuts" rel="alternate" type="text/html" title="What Is Color Spaces And Gamuts" />
      <published>2019-07-11T00:00:00+00:00</published>
      <updated>2019-07-11T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2019/07/11/what-is-color-spaces-and-gamuts</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2019/07/11/what-is-color-spaces-and-gamuts">&lt;p&gt;HDR 에 대한 내용들을 찾다보면 &lt;em&gt;color space&lt;/em&gt; 에 대한 개념을 기본적으로 알고 있어야 수학적인 내용을 배울 때 단계적으로 학습해야 하는 것처럼 대부분의 내용들을 쉽게 이해할 수 있다. 필자의 경우 이에 대한 학습이 전혀 없었고, 직접 자료를 찾아보기 전까지 무슨 소리인지 전혀 몰랐던 상태였다. 다행히 여러 분야에 걸쳐 꽤 많이 알려진 지식들이고 받아들이기에 어려운 개념은 아니라서 이에 대해 글을 쓰면서 정리해보려 한다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;일반적으로 컴퓨터에서 색을 나타내기 위해서 RGB 튜플을 사용한다. YMCK 같은 프린트를 위한 방법도 존재하지만 빛을 이용한 색을 나타내는 방법은 거의 RGB로 빛을 나타내는 방식을 쓰는 것으로 보인다. 이는 사람의 눈에서 빛을 색으로 감지하는 감각기관인 &lt;em&gt;cone cell&lt;/em&gt; 이 총 3가지의 파장 분포 가진 타입을 가진 즉 3가지의 파장 분포를 인식하는 &lt;em&gt;cone cell&lt;/em&gt; 이 존재한다. 아래 그림에서 나온 L, M, S 파장 분포가 &lt;em&gt;cone cell&lt;/em&gt; 이 인식하는 파장이다. 보통은 &lt;em&gt;l-cones&lt;/em&gt;, &lt;em&gt;m-cones&lt;/em&gt;, &lt;em&gt;s-cones&lt;/em&gt; 라고 하는 듯 하다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/1/1e/Cones_SMJ2_E.svg&quot; alt=&quot;Wikipedia : CIE 1931 color space&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/CIE_1931_color_space&quot;&gt;Wikipedia : CIE 1931 color space
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;보면 쉽게 알 수 있겠지만, L은 빨간색, M은 초록색, S는 파란색으로 나타내져 있다. 이렇게 표현된 이유는 아래 그림을 보면 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/c/c4/Rendered_Spectrum.png&quot; alt=&quot;Wikipedia : Visible spectrum&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/Visible_spectrum&quot;&gt;Wikipedia : Visible spectrum
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;가장 높은 경우를 가진, 분포에서 가장 높은 반응을 가지는 포인트를 각 색으로 나타낸 것이다. 즉 빛으로 색을나타낼 떄 RGB로 나타내는 이유 중 하나는 “&lt;em&gt;LMS cone cell&lt;/em&gt; 이 반응하는 가장 큰 경우가 각각 Red,Green,Blue 이기 때문이다.” 라고도 말할 수 있겠다.&lt;/p&gt;

&lt;p&gt;그렇다면 우리는 색을 RGB 튜플로 나타내니, 이에 대한 정의가 있을 것이라 생각할 수 있다. 그리고 이러한 정의가 존재한다. &lt;em&gt;color space&lt;/em&gt; 가 무엇이냐? 라고 묻는다면 단순히 색을 정의한 공간이라고 밖에 설명할 수 밖에 없다. 좀 더 목적에 치중하면, 색을 정량화 하기 위해서 정의한 것이다. 정도에 머무를 것이다. 이에 대한 정의를 먼저 알아야 대강의 이해가 될것이다. 아주 기본적인 &lt;em&gt;color space&lt;/em&gt; 에 대한 정의인 두가지, &lt;em&gt;CIE 1931 RGB color space&lt;/em&gt;, &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 가 있다. 사실상 가장 많이 활용되는 &lt;em&gt;color space&lt;/em&gt; 는 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 이다. 하지만 우선 &lt;em&gt;CIE 1931 RGB color space&lt;/em&gt; 먼저 알아보자. 이 부분이 먼저 시작되는 부분이기 때문이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;CIE 1931 RGB color space&lt;/em&gt; 의 정의에 대해서 언급해보자면, 특정 실험을 통해서 \(\bar{r}(\lambda),\bar{g}(\lambda),\bar{b}(\lambda)\) 함수를 정의한다. 이 실험은 사람을 대상으로 해당 특정 파장의 색을 보여주고 r,g,b 값을 조절하여 색을 실험자가 직접 맞추는 실험이라고 한다. 자세한 내용은 &lt;a href=&quot;https://en.wikipedia.org/wiki/CIE_1931_color_space#CIE_RGB_color_space&quot;&gt;링크&lt;/a&gt;에 나와있다. 정의된 파장에 대한 함수가 아래에 나와있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/6/69/CIE1931_RGBCMF.svg&quot; alt=&quot;Wikipedia : CIE 1931 color space&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/CIE_1931_color_space&quot;&gt;Wikipedia : CIE 1931 color space
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 정의된 함수를 &lt;em&gt;color matching function&lt;/em&gt; 이라 하는데, &lt;em&gt;color matching function&lt;/em&gt; 를 사용해 우리가 실질적으로 사용하는 RGB 값을 정의할 수 있다. 단 여기에 같이 사용되는 또 다른 측정값들이 있는데, &lt;em&gt;spectrum power distribution&lt;/em&gt; 이라는 것이다. 이는 해당 방정식에서 \(S(\lambda)\) 로 표현된다. 이를 간단하게 말하자면 물체가 반사하는 파장의 분포다.&lt;/p&gt;

\[R = \int_0^\infty \bar{r}(\lambda) d\lambda,\;
G = \int_0^\infty \bar{g}(\lambda) d\lambda,\;
B = \int_0^\infty \bar{b}(\lambda) d\lambda\]

&lt;p&gt;위와같이 정의가 가능하며, 해당 값은 절대적인 값들이기 때문에 보통은 이들을 합해 정규화한 값을 쓴다.&lt;/p&gt;

\[r = R/(R+G+B),\; g = G/(R+G+B),\; b = B/(R+G+B)\]

&lt;p&gt;정의에 대한 부분은 이해를 못하더라도 상관없다. 그저 우리가 아는 RGB 표현 방식이 있고, 이를 수학적으로, 명시적으로 정의한게 &lt;em&gt;CIE 1931 RGB color space&lt;/em&gt; 이라고 생각하면된다. 다음은 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 인데, 위에서 정의한 방법: &lt;em&gt;color matching function&lt;/em&gt; 과 &lt;em&gt;spectrum power distribution&lt;/em&gt; 을 &lt;em&gt;convolution&lt;/em&gt; 하여 정의된다. 다만 실험을 통한 &lt;em&gt;color matching function&lt;/em&gt; 의 정의는 다르다. 실험을 통한 \(\bar{x}(\lambda),\bar{y}(\lambda),\bar{z}(\lambda)\) 는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/8/8f/CIE_1931_XYZ_Color_Matching_Functions.svg&quot; alt=&quot;Wikipedia : CIE 1931 color space&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/CIE_1931_color_space&quot;&gt;Wikipedia : CIE 1931 color space
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이렇게 정의된 &lt;em&gt;color matching function&lt;/em&gt; 과 &lt;em&gt;spectrum power distribution&lt;/em&gt; 을 사용하여 다음과 같이 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 의 값들을 나타낼 수 있다.&lt;/p&gt;

\[X = \int_0^\infty \bar{x}(\lambda) d\lambda,\; Y = \int_0^\infty \bar{y}(\lambda) d\lambda,\; Z = \int_0^\infty \bar{z}(\lambda) d\lambda\]

\[x = X/(X+Y+Z),\; y = Y/(X+Y+Z),\; z = Z/(X+Y+Z)\]

&lt;p&gt;위의 &lt;em&gt;CIE 1931 RGB color space&lt;/em&gt; 와 굉장히 비슷하게 정의했지만 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 는 그리 단순하게 설계되진 않았다. 총 5가지의 특징을 가지고 있다. 이는 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;CIE 1931 RGB color space&lt;/em&gt; 와 확실하게 다른점으로 &lt;em&gt;color matching function&lt;/em&gt; 이 음수를 가지지 않는다. 즉 무조건 양수라는 이야기다.&lt;/li&gt;
  &lt;li&gt;\(\bar{y}(\lambda)\) &lt;em&gt;color matching function&lt;/em&gt; 은 해당 &lt;em&gt;spectrum power distribution&lt;/em&gt; 의 &lt;em&gt;luminance&lt;/em&gt; 를 추출해내는 &lt;em&gt;photopic luminous efficiency function&lt;/em&gt; 함수다. 즉 간단하게 말하자면 Y 값이 &lt;em&gt;luminance&lt;/em&gt; 라는 말이다.&lt;/li&gt;
  &lt;li&gt;\(x=y=z=1/3\) 인 지점에서 &lt;em&gt;white point&lt;/em&gt; 가 존재해야 한다고 한다.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;CIE xy chromaticity diagram&lt;/em&gt; 에서 &lt;em&gt;color gamut&lt;/em&gt; 보았을 때, 1사분면, 즉 &lt;em&gt;x,y&lt;/em&gt; 값이 무조건 양수인 상태에서 존재해야 한다고 한다.&lt;/li&gt;
  &lt;li&gt;\(\bar{z}(\lambda)\) 의 값이 650 nm 이상에서는 전부 0으로 세팅된다고 한다. 이는 아마도 실험 측정값의 에러를 잘라내기 위한 것인듯 싶다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;4번의 정의에서 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 자체는 색의 음수영역까지 포함하는 &lt;em&gt;imagenary color space&lt;/em&gt; 인걸 알 수 있다. 이는 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 가 광범위한 &lt;em&gt;color space&lt;/em&gt; 인것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;이렇게 정의된 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 의 쓰임새는 굉장히 다양하다. 우선 위와같은 사항을 고려해서 설계된것이 아마도 가장 큰게 아닐까 싶다. 많은 &lt;em&gt;color space&lt;/em&gt; 들이 &lt;em&gt;luminance&lt;/em&gt; 와 &lt;em&gt;chromaticity&lt;/em&gt; 를 구분해서 정의하는데, &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 는 이미 구분이 되어있기 때문에 여기에서 조금 더 변형을 가해서 원하는 성질을 추가하면 되기 때문이라고 고려된다. 즉 다양한 쓰임새는 &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 자체가 잘 정의되어 있기 때문이라고 고려된다. &lt;em&gt;CIE 1931 XYZ color space&lt;/em&gt; 는 &lt;em&gt;CIE 1931 RGB color space&lt;/em&gt; 로부터 선형변환할 수 있도록 되어있다. 물론 반대의 경우도 가능하다.&lt;/p&gt;

\[\begin{bmatrix}
X\\
Y\\
Z\\
\end{bmatrix} =
\cfrac{1}{0.17697}
\begin{bmatrix}
0.49000&amp;amp;0.31000&amp;amp;0.20000\\
0.17697&amp;amp;0.81240&amp;amp;0.01063\\
0.00000&amp;amp;0.01000&amp;amp;0.99000\\
\end{bmatrix}
\begin{bmatrix}
R\\
G\\
B\\
\end{bmatrix}\]

\[\begin{bmatrix}
R\\
G\\
B\\
\end{bmatrix}  =
\begin{bmatrix}
0.41847&amp;amp;-0.15866&amp;amp;-0.082835\\
-0.091169&amp;amp;0.25243&amp;amp;0.015708\\
0.00092090&amp;amp;-0.0025498&amp;amp;0.17860\\
\end{bmatrix}
\begin{bmatrix}
X\\
Y\\
Z\\
\end{bmatrix}\]

&lt;p&gt;이제 자주 보이는 &lt;em&gt;CIE xy chromaticity diagram&lt;/em&gt; 이라는 것이 있다. 앞에서 정의된 &lt;em&gt;x,y&lt;/em&gt; 값을 사용하여 나타낸다. &lt;em&gt;z&lt;/em&gt; 값은 \(1-x-y\) 로 쉽게 계산이 가능해서 단순하게 &lt;em&gt;x,y&lt;/em&gt; 값을 사용하여 나타낸다. 이는 &lt;em&gt;X,Y,Z&lt;/em&gt; 의 값의 비율로 계산되는 값으로 절대적인 수치와는 상관없이 그저 &lt;em&gt;chromaticity&lt;/em&gt; 만을 나타내기 위한 방법이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;chromaticity&lt;/em&gt; 와 &lt;em&gt;luminance&lt;/em&gt; 에 대한 설명을 명확하게 하자면, &lt;em&gt;luminance&lt;/em&gt; 는 빛 자체의 밝기, 광도라고 말할 수 있겠다. 검은색에서 흰색의 차이는 단지 밝기의 정도만 차이나는 것이다. &lt;em&gt;chromaticity&lt;/em&gt; 는 밝기에 상관없이 보여지는 색 자체가 다른 것을 뜻한다. 예를들어 어두운 파란색과 어두운 빨간색은 비슷한 &lt;em&gt;luminance&lt;/em&gt; 를 가질 수 있지만, &lt;em&gt;chromaticity&lt;/em&gt; 는 전혀 다르다고 말할 수 있다. 아래 다이어그램은 &lt;em&gt;chromaticity diagram&lt;/em&gt; 이기 때문에 밝기에 대한 정보는 없고 단지 색의 차이, 색차만 나와있는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/3/3b/CIE1931xy_blank.svg&quot; alt=&quot;Wikipedia : CIE 1931 color space&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/CIE_1931_color_space&quot;&gt;Wikipedia : CIE 1931 color space
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;CIE xy chromaticity diagram&lt;/em&gt; 에서 밑의 직선을 제외한 말발굽 모양의 숫자가 표시된 부분을 &lt;em&gt;spetral locus&lt;/em&gt; 라고 부르는데, 이는 파장의 길이에 따라 달라지는 가시광선을 나타낸다. 곡선에 표시된 숫자는 파장의 크기를 나타낸다. 아래 직선은 &lt;em&gt;line of purple&lt;/em&gt; 이라고 하는데, 여기서 재미있는 것은 &lt;em&gt;spectral locus&lt;/em&gt; 와 &lt;em&gt;white point&lt;/em&gt; 사이에 있는, 즉 환경에 정해진 흰색 사이에 있는 색은 얼마든지 하나의 파장을 가진 빛으로 나타낼 수 있고, 그게 아닌 &lt;em&gt;line of purple&lt;/em&gt; 과 &lt;em&gt;white point&lt;/em&gt; 사이에 있는 색은 하나의 파장을 가진 빛으로 나타낼 수 없다.&lt;/p&gt;

&lt;p&gt;위에서도 언급했지만 &lt;em&gt;CIE XYZ&lt;/em&gt; 는 다른 &lt;em&gt;color space&lt;/em&gt; 와 변환으로 연결되어있는 이론상으로 기본적인 &lt;em&gt;color space&lt;/em&gt; 이다. &lt;em&gt;CIE XYZ&lt;/em&gt; 에서 파생된 여러가지 &lt;em&gt;color space&lt;/em&gt; 들이 존재하는데 몇가지만 살펴보겠다. 첫번째는 &lt;em&gt;CIE LAB&lt;/em&gt; 이라는 &lt;em&gt;color space&lt;/em&gt; 인데 이는 사람이 인지할 수 있는 색의 변화에 맞게 개선되었으며, 프린터가 주로 사용하는 &lt;em&gt;CMYK Color Model&lt;/em&gt;, 디스플레이에서 주로 사용되는 &lt;em&gt;RGB Color Model&lt;/em&gt; 둘다 포함한다고 한다. 두번째는 &lt;em&gt;CIE LUV&lt;/em&gt; 로, 주로 빛으로 색을 나타내는 컴퓨터 그래픽에서 사용되고, 이 또한 &lt;em&gt;perceptual uniformity&lt;/em&gt; 를 개선하였다고 한다. 이 외에도 꽤 많은 &lt;em&gt;color space&lt;/em&gt; 들이 존재한다.&lt;/p&gt;

&lt;p&gt;다음은 &lt;em&gt;color gamut&lt;/em&gt; 혹은 &lt;em&gt;gamut&lt;/em&gt; 이 무엇인지, 어떤 것들이 있는지에 대해서 써보겠다. 위키의 정의에 따르면, &lt;em&gt;gamut&lt;/em&gt; 은 &lt;em&gt;color space&lt;/em&gt; 의 &lt;em&gt;complete subset&lt;/em&gt; 이라고 한마디로 쓰여있다. &lt;em&gt;complete subset&lt;/em&gt; 인 이유는 잘 모르겠으나 아마도 추상적이지 않고 특정한 값을 정의함으로써의 &lt;em&gt;complete subset&lt;/em&gt;, 완벽한 부분집합이라고 말한것으로 생각된다. &lt;em&gt;gamut&lt;/em&gt; 이라는 용어는 이글에서의 의미와도 같고, 거의 대부분 특정한 주어진 환경, 특정한 출력 장치에서 구현될 수 있는 색 공간에서의 부분집합을 뜻하는 말로 쓰이나, 가끔 어떤 이미지, 영상에서 추출된 색의 완벽한 집합을 의미하는 말로도 쓰인다고도 한다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gameworks/hdr/UHDColorForGames.pdf&quot;&gt;UHD Color for Games&lt;/a&gt;에서는 &lt;em&gt;gamut&lt;/em&gt; 이 정의되기 위해서는 색의 기준이되는 여러개의 색 공간의 점들, 복수개의 &lt;em&gt;color primary&lt;/em&gt;(&lt;em&gt;RGB Model&lt;/em&gt; 인 경우 3개), 주로 특정 환경에서의 명시적인 흰색을 나타내기 위해 색 공간에서의 특정한 점으로 정의되는 &lt;em&gt;white point&lt;/em&gt;, 특정 색 공간에서 해당 &lt;em&gt;gamut&lt;/em&gt; 으로 변환 하기 위한 &lt;em&gt;encoding function&lt;/em&gt; 이 필요하다고 쓰여있다. 이 글에서 언급하는 &lt;em&gt;gamut&lt;/em&gt; 들은 전부 디스플레이에서 사용되는 &lt;em&gt;gamut&lt;/em&gt; 들이기 때문에, 적어도 여기서 언급되는 &lt;em&gt;gamut&lt;/em&gt; 들은 &lt;em&gt;RGB&lt;/em&gt; 로 표현이 되기 때문에 &lt;em&gt;r,g,b&lt;/em&gt; 를 나타내는 &lt;em&gt;color primary&lt;/em&gt; 를 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;gamut&lt;/em&gt; 은 디스플레이의 색 표준이기 때문에 사용되는 몇가지의 &lt;em&gt;gamut&lt;/em&gt; 들이 존재한다. 그 중 예전부터 가장 많이 알려지고 사용된 &lt;em&gt;sRGB&lt;/em&gt; 에 대해서 먼저 언급하자면, 이는 CRT 모니터의 &lt;em&gt;gamut&lt;/em&gt; 으로 사용될 정도로 꽤 오래된 &lt;em&gt;gamut&lt;/em&gt; 이다. 현재 사용되는 &lt;em&gt;gamut&lt;/em&gt; 중에 표현할 수 있는 색의 범위가 가장 적다. &lt;em&gt;sRGB&lt;/em&gt; 의 최소한의 필요한 빛의 밝기, &lt;em&gt;minimum luminance&lt;/em&gt; 는 80nit 이다. &lt;em&gt;white point&lt;/em&gt; 는 &lt;em&gt;D65&lt;/em&gt; 로 거의 표준적으로 사용된다. 최근 사용되는 &lt;em&gt;SDR&lt;/em&gt; 모니터들의 최대 &lt;em&gt;luminance&lt;/em&gt; 가 200~300nit 가 되기 때문에 꽤 차이가 난다고 할 수 있다. 아래 그림인 &lt;em&gt;chromaticity diagram&lt;/em&gt; 을 보면 쉽게 알 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;http://www.lamptolaser.com/images/spectrum.jpg&quot; alt=&quot;Color gamut Rec.2020, DCIP3, Rec.709&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://www.lamptolaser.com/fact7.html&quot;&gt;www.lamptolaser.com : The FACTS OF LIGHT, FACT 07
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;sRGB&lt;/em&gt; 의 &lt;em&gt;encoding&lt;/em&gt; 은 아래와 같다. &lt;em&gt;CIE XYZ&lt;/em&gt; 을 변환시키려면 아래와 같이 &lt;em&gt;linear RGB&lt;/em&gt; 값으로 변환시킨 다음에, 해당 값을 꽤나 알려진 &lt;em&gt;gamma correction&lt;/em&gt; 이라는 과정, &lt;em&gt;gamma function&lt;/em&gt; 에 &lt;em&gt;linear RGB&lt;/em&gt; 값을 넣어 &lt;em&gt;sRGB&lt;/em&gt; 값을 얻을 수 있다.&lt;/p&gt;

\[\begin{bmatrix}
\mathit{R}_{linear} \\ \mathit{G}_{linear} \\ \mathit{B}_{linear} \\
\end{bmatrix} =
\begin{bmatrix}
3.2406&amp;amp;-1.5372&amp;amp;-0.4986 \\ -0.9689&amp;amp;1.8758&amp;amp;0.0415 \\ 0.0557&amp;amp;-0.2040&amp;amp;1.0570 \\
\end{bmatrix}
\begin{bmatrix}
\mathit{X}_{D65} \\ \mathit{Y}_{D65}\\ \mathit{Z}_{D65}\\
\end{bmatrix}\]

\[\gamma(\mathit{u}_{rgb}) = \begin{cases} 12.92\mathit{u}_{rgb}&amp;amp;\mathit{u}_{rgb} \leq 0.0031308\\ (1.055\mathit{u}_{rgb}^{1/2.4}-0.055&amp;amp;otherwise \end{cases}\\\]

&lt;p&gt;역변환과 여러 정보에 대해서는 &lt;a href=&quot;https://en.wikipedia.org/wiki/SRGB&quot;&gt;Wikipedia : sRGB&lt;/a&gt;에서 확인할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;sRGB&lt;/em&gt; 와 거의 비슷하게 쓰이는 &lt;em&gt;ITU-R Recommendation BT.709&lt;/em&gt;, 보통 줄여서 &lt;em&gt;Rec.709&lt;/em&gt;, &lt;em&gt;BT.709&lt;/em&gt; 라고 불리는 &lt;em&gt;gamut&lt;/em&gt; 은 HDTV 의 기준으로 많이 쓰이는 &lt;em&gt;gamut&lt;/em&gt; 이다. &lt;em&gt;sRGB&lt;/em&gt; 와 확실하게 다른점은 &lt;em&gt;encoding function&lt;/em&gt; 이 다르다는 점이다. 이는 &lt;em&gt;viewing environtment&lt;/em&gt;, 디스플레이가 사용되는 환경이 다르기 때문이라고 한다.&lt;/p&gt;

&lt;p&gt;위의 &lt;em&gt;chromaticity diagram&lt;/em&gt; 에서 두번째로 넓은 영역을 차지하는 &lt;em&gt;DCI-P3&lt;/em&gt; 은 &lt;em&gt;Digital Cinema Initiative&lt;/em&gt; 라는 조직에서 만들고, &lt;em&gt;Society of Motion Picutre &amp;amp; Telelvision Engineers&lt;/em&gt; 라는 조직에서 &lt;em&gt;publishing&lt;/em&gt; 한 &lt;em&gt;gamut&lt;/em&gt; 으로, 꽤 많은 디스플레이들이 지원하는 비교적 넓은, &lt;em&gt;HDR&lt;/em&gt; 과 같이 응용될 수 있는 &lt;em&gt;gamut&lt;/em&gt; 이다. 가장 넓은 영역을 차지하는 &lt;em&gt;Rec. 2020&lt;/em&gt;, &lt;em&gt;ITU-R Recommendation BT.2020&lt;/em&gt; 은 비교적 최근에 고안된 &lt;em&gt;gamut&lt;/em&gt; 으로, 적어도 &lt;em&gt;HDMI 2.1&lt;/em&gt;, &lt;em&gt;HDR&lt;/em&gt; 이 가능한 환경에서 사용될 수 있기 때문에 가장 한정적으로 사용될 수 밖에 없는 &lt;em&gt;gamut&lt;/em&gt; 이다.&lt;/p&gt;

&lt;p&gt;주로 사용되는 &lt;em&gt;gamut&lt;/em&gt; 에 대해 알아보았으니 나머지 연산에 대해서 한번 알아보자. &lt;em&gt;gamut&lt;/em&gt; 은 색을 연산하기 위해서는 반드시 고정되어야 한다. 아래 그림을 보면 같은 색이라도 어떤 &lt;em&gt;color space&lt;/em&gt;, &lt;em&gt;gamut&lt;/em&gt; 이냐에 따라서 같은 연산의 결과라도 &lt;em&gt;gamut&lt;/em&gt; 에 따라서 달라진다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/color_op_in_gamuts.PNG&quot; alt=&quot;color operation in gamut&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.nvidia.com/hdr-gdc-2018&quot;&gt;HDR Ecosystem for Games, Evan Hart, 2018
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그래서 &lt;em&gt;sRGB&lt;/em&gt; 같은 작은 &lt;em&gt;gamut&lt;/em&gt; 을 사용하는 경우에 &lt;em&gt;HDR&lt;/em&gt; 을 활용하기 위해 &lt;em&gt;gamut&lt;/em&gt; 을 강제로 늘리고 싶은 경우가 있는데 &lt;em&gt;gamut mapping&lt;/em&gt; 이라고 불리고 그다지 추천되는 방법은 아니다. 디지털 상에서라면 이미 &lt;em&gt;quantization&lt;/em&gt; 이 되어있기도 하고, 색의 범위가 줄어들어 단순히 &lt;em&gt;color gamut&lt;/em&gt; 을 &lt;em&gt;clipping&lt;/em&gt; 하게 되면 &lt;em&gt;chromaticity&lt;/em&gt; 가 급격하게 변경되고, 마찬가지고 색의 범위가 늘어나서 단순히 &lt;em&gt;stretching&lt;/em&gt; 하는 경우에도 전의 경우와 같다. 이는 아트팀에서 노발대발할 부분이므로 최대한 하지 않는 것을 추천하는 경우가 많다. 여러 자료에서는 그래서 그냥 &lt;em&gt;sRGB&lt;/em&gt; 를 쓰라고 언급한다.&lt;/p&gt;

&lt;!--
$$ \gamma^{-1}(\mathit{u}_{rgb}) = \begin{cases} \mathit{u}_{rgb}/12.92&amp;\mathit{u}_{rgb} \leq 0.04045\\ (\frac{\mathit{u}_{rgb}+0.055}{1.055})^{2.4}&amp;otherwise \end{cases}\\ $$
$$
\begin{bmatrix}
\mathit{X}_{D65} \\ \mathit{Y}_{D65}\\ \mathit{Z}_{D65}\\
\end{bmatrix} =
\begin{bmatrix}
0.4124&amp;0.3576&amp;0.1805 \\ 0.2126&amp;0.7152&amp;0.0722 \\ 0.0193&amp;0.1192&amp;0.9504 \\
\end{bmatrix}
\begin{bmatrix}
\mathit{R}_{linear} \\ \mathit{G}_{linear} \\ \mathit{B}_{linear} \\
\end{bmatrix}
$$
--&gt;

&lt;!-- ITP(ICtCp) : Hdr, 부록 정도로 --&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Color_space&quot;&gt;Wikipedia : Color space&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Gamut&quot;&gt;Wikipedia : Gamut&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/SRGB&quot;&gt;Wikipedia : sRGB&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Real-Time Rendering 4th, Tomas Akenine-Möller et all, 2018&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://webzine.kps.or.kr/contents/data/webzine/webzine/15124615671.pdf&quot;&gt;특집 예술세계에서의 물리학 : 색채과학이란 - 디지털 색채를 중심으로, 곽영신.우정원, 2000&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/sites/default/files/akamai/gameworks/hdr/UHDColorForGames.pdf&quot;&gt;UHD Color for Games, Evan Hart, 2016&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/hdr-gdc-2018&quot;&gt;HDR Ecosystem for Games, Evan Hart, 2018&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="color" />
      
        <category term="colorimetry" />
      

      

      
        <summary type="html">HDR 에 대한 내용들을 찾다보면 color space 에 대한 개념을 기본적으로 알고 있어야 수학적인 내용을 배울 때 단계적으로 학습해야 하는 것처럼 대부분의 내용들을 쉽게 이해할 수 있다. 필자의 경우 이에 대한 학습이 전혀 없었고, 직접 자료를 찾아보기 전까지 무슨 소리인지 전혀 몰랐던 상태였다. 다행히 여러 분야에 걸쳐 꽤 많이 알려진 지식들이고 받아들이기에 어려운 개념은 아니라서 이에 대해 글을 쓰면서 정리해보려 한다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">What Is Srp Batcher In Unity</title>
      
      <link href="https://suhyeokkim.github.io/2019/07/02/what-is-srp-batcher-in-unity" rel="alternate" type="text/html" title="What Is Srp Batcher In Unity" />
      <published>2019-07-02T00:00:00+00:00</published>
      <updated>2019-07-02T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2019/07/02/what-is-srp-batcher-in-unity</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2019/07/02/what-is-srp-batcher-in-unity">&lt;p&gt;Unity의 SRP 의 개발과 같이 여러 기능들이 생겨나는 것 같다. 아마도 기존의 Unity 의 렌더링 모듈들을 최대한 개선하려는 시도로 보인다. 이번 년초에 공개된 &lt;em&gt;SRP Batcher&lt;/em&gt; 또한 효율을 개선하기 위한 것으로 보인다.&lt;/p&gt;

&lt;p&gt;종종 보이는 용어 &lt;em&gt;batch&lt;/em&gt; 라는 용어는 “한꺼번에 처리한다.” 라는 뜻으로 보통 쓰인다. 일반적인 렌더링 시스템에서의 &lt;em&gt;batch&lt;/em&gt; 는 최소한의 drawcall-driver overhead- 을 위해 렌더링할 것들의 데이터들을 최대한 묶어주는 시스템의 기능을 말하기 위해 사용되는 것 같다. 그리고 Unity 또한 기존의 &lt;em&gt;built-in batcher&lt;/em&gt; 시스템이 존재한다. 근데 이에 성능을 향상시키기 위해 &lt;em&gt;SRP batcher&lt;/em&gt; 라는게 만들어 졌다고 한다. 이는 곧 기존의 &lt;em&gt;built-in batcher&lt;/em&gt; 시스템에 비효율적인 부분이 존재한다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;Unity를 사용을 하다보면 알 수 있지만, MeshRenderer 컴포넌트의 같은 쉐이더에 다른 파라미터를 가진 Material 을 추가하거나 바꾸게 되면 DrawCall 이 바꾼 Material 의 갯수에 비례해서 올라가는 것을 알 수 있다. 문제는 이게 &lt;em&gt;static batch&lt;/em&gt; 든 &lt;em&gt;dynamic batch&lt;/em&gt; 든 무조건 일어난다는 것에 문제가 있다. directX 에 직접 맞닿아본 적은 없지만 Unity로 Shader Model 5.0 부터 접한 필자로써는 이해가 잘 되지 않는 상황이였다.&lt;/p&gt;

&lt;p&gt;문제는 Unity Blog의 해당 포스팅을 보면 알 수 있지만(&lt;a href=&quot;https://blogs.unity3d.com/2019/02/28/srp-batcher-speed-up-your-rendering/&quot;&gt;링크&lt;/a&gt;), Unity 자체가 dx9 레벨을 지원하면서 만들어졌으며, 여러 API(dx11)를 지원하려 하다보니 해당 API의 특징을 잘 사용하지 못한채 &lt;em&gt;built-in batcher&lt;/em&gt; 가 만들어진 듯 했다. 아래에는 &lt;em&gt;built-in batcher&lt;/em&gt; 시스템을 나타낸 그림이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://blogs.unity3d.com/wp-content/uploads/2019/02/SRP-Batcher-OFF.png&quot; alt=&quot;built-in batcher&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://solitaryroad.com/c1003.html&quot;&gt;Unity Blog : SRP Batcher: Speed up your rendering!
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위와 같은 시스템이라면, 무조건 메터리얼이 바뀌면 이들의 정보를 갱신하기 위해 전체를 다 처리하는 코드로 되어있는 듯 하다. 하지만 여기서 조금 더 생각해보면, &lt;em&gt;Material&lt;/em&gt; 과 각 오브젝트들의 &lt;em&gt;Transformation&lt;/em&gt; 정보들은 다른 정보라고 할 수 있다. 그렇다면 이들을 한꺼번에 처리하는게 아니라, &lt;em&gt;Material&lt;/em&gt;, &lt;em&gt;Transformation&lt;/em&gt; 정보를 나누어서 갱신하면 &lt;em&gt;Material&lt;/em&gt; 을 바꿀 때, 쉐이더 코드가 바뀌지 않는다면, &lt;em&gt;DrawCall&lt;/em&gt; 이 늘어나지 않도록 할 수 있겠다. 문서에는 다른 &lt;em&gt;Material&lt;/em&gt; 이지만 &lt;em&gt;Shader&lt;/em&gt; 의 갯수가 많지 않은 경우를 타겟으로 했다고 쓰여져 있다. 아래 그림은 &lt;em&gt;SRP Batcher&lt;/em&gt; 시스템을 나타내었다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://blogs.unity3d.com/wp-content/uploads/2019/02/image5-3.png&quot; alt=&quot;SRP batcher&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://solitaryroad.com/c1003.html&quot;&gt;Unity Blog : SRP Batcher: Speed up your rendering!
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위에서 언급한 데이터를 나눈 것과 동시에 중요한 것이 하나 더 있는데, 기존의 &lt;em&gt;Material&lt;/em&gt; 데이터를 계속 갱신해 주어야 했는데, &lt;em&gt;SRP Batcher&lt;/em&gt; 시스템은 데이터의 영속성을 보장한다고 한다. &lt;em&gt;Material&lt;/em&gt; 의 데이터를 나누어서 관리하기 때문에 각 오브젝트 당으로 &lt;em&gt;cbuffer&lt;/em&gt; 를 데이터를 가질 수 있다고 한다. &lt;em&gt;built-in batcher&lt;/em&gt; 시스템에서는 이와 같은 처리를 하기위해 쉐이더 레벨에서 인스턴싱이라는 것을 지원했었는데 SRP 에서는 몇 안되는 Uber 쉐이더를 사용한다고 가정하고, 이를 자동으로 처리해주는 듯 싶다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;https://blogs.unity3d.com/wp-content/uploads/2019/02/image3-5.png&quot; alt=&quot;SRP batcher&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://solitaryroad.com/c1003.html&quot;&gt;Unity Blog : SRP Batcher: Speed up your rendering!
&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 &lt;em&gt;batch&lt;/em&gt; 처리시 어떤 기준에 따라서 한꺼번에 처리하는지에 대해 알 수 있는 다이어그램이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://blogs.unity3d.com/2019/02/28/srp-batcher-speed-up-your-rendering/&quot;&gt;Unity Blog : SRP Batcher: Speed up your rendering!&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="srp_batcher" />
      

      

      
        <summary type="html">Unity의 SRP 의 개발과 같이 여러 기능들이 생겨나는 것 같다. 아마도 기존의 Unity 의 렌더링 모듈들을 최대한 개선하려는 시도로 보인다. 이번 년초에 공개된 SRP Batcher 또한 효율을 개선하기 위한 것으로 보인다. 종종 보이는 용어 batch 라는 용어는 “한꺼번에 처리한다.” 라는 뜻으로 보통 쓰인다. 일반적인 렌더링 시스템에서의 batch 는 최소한의 drawcall-driver overhead- 을 위해 렌더링할 것들의 데이터들을 최대한 묶어주는 시스템의 기능을 말하기 위해 사용되는 것 같다. 그리고 Unity 또한 기존의 built-in batcher 시스템이 존재한다. 근데 이에 성능을 향상시키기 위해 SRP batcher 라는게 만들어 졌다고 한다. 이는 곧 기존의 built-in batcher 시스템에 비효율적인 부분이 존재한다는 것을 알 수 있다. Unity를 사용을 하다보면 알 수 있지만, MeshRenderer 컴포넌트의 같은 쉐이더에 다른 파라미터를 가진 Material 을 추가하거나 바꾸게 되면 DrawCall 이 바꾼 Material 의 갯수에 비례해서 올라가는 것을 알 수 있다. 문제는 이게 static batch 든 dynamic batch 든 무조건 일어난다는 것에 문제가 있다. directX 에 직접 맞닿아본 적은 없지만 Unity로 Shader Model 5.0 부터 접한 필자로써는 이해가 잘 되지 않는 상황이였다. 문제는 Unity Blog의 해당 포스팅을 보면 알 수 있지만(링크), Unity 자체가 dx9 레벨을 지원하면서 만들어졌으며, 여러 API(dx11)를 지원하려 하다보니 해당 API의 특징을 잘 사용하지 못한채 built-in batcher 가 만들어진 듯 했다. 아래에는 built-in batcher 시스템을 나타낸 그림이다. 출처 : Unity Blog : SRP Batcher: Speed up your rendering! 위와 같은 시스템이라면, 무조건 메터리얼이 바뀌면 이들의 정보를 갱신하기 위해 전체를 다 처리하는 코드로 되어있는 듯 하다. 하지만 여기서 조금 더 생각해보면, Material 과 각 오브젝트들의 Transformation 정보들은 다른 정보라고 할 수 있다. 그렇다면 이들을 한꺼번에 처리하는게 아니라, Material, Transformation 정보를 나누어서 갱신하면 Material 을 바꿀 때, 쉐이더 코드가 바뀌지 않는다면, DrawCall 이 늘어나지 않도록 할 수 있겠다. 문서에는 다른 Material 이지만 Shader 의 갯수가 많지 않은 경우를 타겟으로 했다고 쓰여져 있다. 아래 그림은 SRP Batcher 시스템을 나타내었다. 출처 : Unity Blog : SRP Batcher: Speed up your rendering! 위에서 언급한 데이터를 나눈 것과 동시에 중요한 것이 하나 더 있는데, 기존의 Material 데이터를 계속 갱신해 주어야 했는데, SRP Batcher 시스템은 데이터의 영속성을 보장한다고 한다. Material 의 데이터를 나누어서 관리하기 때문에 각 오브젝트 당으로 cbuffer 를 데이터를 가질 수 있다고 한다. built-in batcher 시스템에서는 이와 같은 처리를 하기위해 쉐이더 레벨에서 인스턴싱이라는 것을 지원했었는데 SRP 에서는 몇 안되는 Uber 쉐이더를 사용한다고 가정하고, 이를 자동으로 처리해주는 듯 싶다. 출처 : Unity Blog : SRP Batcher: Speed up your rendering! 위 그림은 batch 처리시 어떤 기준에 따라서 한꺼번에 처리하는지에 대해 알 수 있는 다이어그램이다. 참조 Unity Blog : SRP Batcher: Speed up your rendering!</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Steradian And Solid Angle</title>
      
      <link href="https://suhyeokkim.github.io/2019/03/08/steradian-and-solid-angle" rel="alternate" type="text/html" title="Steradian And Solid Angle" />
      <published>2019-03-08T00:00:00+00:00</published>
      <updated>2019-03-08T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2019/03/08/steradian-and-solid-angle</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2019/03/08/steradian-and-solid-angle">&lt;p&gt;solid angle 은 우리가 일반적으로 알고있는 angle 과는 다르게 생소할 가능성이 높다. 이의 단위는 steradian(sr) 으로 교과과정에서 많이 보이는 radian 과 이름이 비슷하다.&lt;/p&gt;

&lt;p&gt;먼저 이름이 비슷한 radian 의 정의를 잘 보여주는 아래 이미지를 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/300px-Circle_radians.gif&quot; alt=&quot;radian_animation&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/Radian&quot;&gt;Wikipedia : Radian&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;주목할 것은 초반에 나오는 1rad 의 호의 길이가 반지름과 같은 것이라 정의한 부분이다. steradian 의 정의도 언급한 radian 의 정의와 비슷하다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/Steradian.svg&quot; alt=&quot;steradian&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/Steradian&quot;&gt;Wikipedia : Steradian&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;solid angle 은 해당 표면의 면적이 반지름의 제곱인 값과 같으면 1 sr 으로 정의된다. 모든 구의 면적을 다 차지할 경우 4π sr 이라고 할 수 있겠다. 또한 아래 그림처럼 표면의 크기에 상관있기 때문에 표면의 모양이 어찌 되었든 상관없다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/ole.gif&quot; alt=&quot;steradian&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://solitaryroad.com/c1003.html&quot;&gt;SolitaryRoad.com : Photometry, Steradian, Intensity of a light source, Candlepower, Lumen, Illumination, Photometer&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그리고 면적이 넓은것에 solid angle 이 비례하는 것이 아니라 전체 면적의 비율을 얼마나 차지하느냐에 따라서 solid angle 이 결정된다. 즉 반지름의 크기와는 상관이 없다. 그래서 solid angle 은 다음과 같이 나타낼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

\[\Omega = A / r^2\]

&lt;p align=&quot;center&quot;&gt;definition of steradian&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;!--
  spherical cone 에 대한것도 써야함
--&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Steradian&quot;&gt;Wikipedia : Steradian&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Solid_angle&quot;&gt;Wikipediad : Solid angle&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="terminology" />
      

      

      
        <summary type="html">solid angle 은 우리가 일반적으로 알고있는 angle 과는 다르게 생소할 가능성이 높다. 이의 단위는 steradian(sr) 으로 교과과정에서 많이 보이는 radian 과 이름이 비슷하다. 먼저 이름이 비슷한 radian 의 정의를 잘 보여주는 아래 이미지를 보자. 출처 : Wikipedia : Radian 주목할 것은 초반에 나오는 1rad 의 호의 길이가 반지름과 같은 것이라 정의한 부분이다. steradian 의 정의도 언급한 radian 의 정의와 비슷하다. 출처 : Wikipedia : Steradian solid angle 은 해당 표면의 면적이 반지름의 제곱인 값과 같으면 1 sr 으로 정의된다. 모든 구의 면적을 다 차지할 경우 4π sr 이라고 할 수 있겠다. 또한 아래 그림처럼 표면의 크기에 상관있기 때문에 표면의 모양이 어찌 되었든 상관없다. 출처 : SolitaryRoad.com : Photometry, Steradian, Intensity of a light source, Candlepower, Lumen, Illumination, Photometer 그리고 면적이 넓은것에 solid angle 이 비례하는 것이 아니라 전체 면적의 비율을 얼마나 차지하느냐에 따라서 solid angle 이 결정된다. 즉 반지름의 크기와는 상관이 없다. 그래서 solid angle 은 다음과 같이 나타낼 수 있다. \[\Omega = A / r^2\] definition of steradian 참조 Wikipedia : Steradian Wikipediad : Solid angle</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Unit Of Light Radiation</title>
      
      <link href="https://suhyeokkim.github.io/2019/02/10/unit-of-light-radiation" rel="alternate" type="text/html" title="Unit Of Light Radiation" />
      <published>2019-02-10T00:00:00+00:00</published>
      <updated>2019-02-10T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2019/02/10/unit-of-light-radiation</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2019/02/10/unit-of-light-radiation">&lt;p&gt;real-time rendering 분야에서 PBR 이 정착하게 되면서, 빛에 대한 측정 기준을 알아야 되게 되었다. 단순하지만 확실하게 정의해놓지 않으면 헷갈리는 개념이기 때문에 정리 해보려 한다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;측정에 대한 이야기를 하기 전에, 알기쉽게 빛이 어떻게 행동하는지 설명하자면, 빛은 에너지가 없어질때까지 튕겨다닌다. 빛은 어떤 매체에 부딫힐 때, 해당 매체에 흡수될 수도 있고, 매체 안에 들어가서 들어간 곳과는 다른 위치에서 나올 수도 있고, 매체를 투과할 수도 있고, 매체에 닿았을 때 튕겨나올 수도 있다. 그렇게 에너지가 없어질 떄 까지 튕겨다닌다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/light_properties.png&quot; alt=&quot;light properties&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://www.google.com/url?sa=i&amp;amp;source=images&amp;amp;cd=&amp;amp;cad=rja&amp;amp;uact=8&amp;amp;ved=2ahUKEwj-_K3V6PHgAhXHxbwKHQEuD7QQjhx6BAgBEAM&amp;amp;url=https%3A%2F%2Fwww.renishaw.com%2Fen%2Fa-basic-overview-of-raman-spectroscopy--25805&amp;amp;psig=AOvVaw138lccVwHl19r0jVfWMOpu&amp;amp;ust=1552109516453916&quot;&gt;renishaw : A basic overview of Raman spectroscopy&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;빛의 세기를 정량적으로 이야기 할 때, 이를 빛의 복사량(radiation)이라고 한다. 이를 이야기 할때, 보통 두가지의 분류를 나누어 구분한다. 하나는 우리가 볼 수 있는 가시광선(대략 400nm ~ 700nm 사이의 파장(wavelength)을 가진 전자기파)과 파장에 관련없이 모든 전자기파를 기준으로 하는 것으로 나뉜다. 모든 전자기파의 세기를 측정하는 것을 &lt;em&gt;Radiometry&lt;/em&gt;, 가시광선의 세기만 측정하는 것을 &lt;em&gt;Photometry&lt;/em&gt; 라고 한다. 일반적으로 눈에 보이는 것들을 신경써야 할때는 &lt;em&gt;Photometry&lt;/em&gt; 를 사용한다. 빛의 파장에 관계없이 계산된 복사량은 및의 커브와 같이 곱하여 적분하여 계산하면 photometric unit 으로 변환될 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

\[\int_{380}^{720} r(\lambda)c_p(\lambda) d\lambda\]

&lt;p align=&quot;center&quot;&gt;radiometric unit to photometric unit formula&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/CIE_photometric_curve.png&quot; alt=&quot;light properties&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://www.researchgate.net/figure/CIE-photometric-curve_fig1_2711215&quot;&gt;ResearchGate : CIE photometric curve&lt;/a&gt;
&lt;br /&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위의 식은 파장에 따른 빛의 복사량의 distribution function : r(λ), 위의 그림의 커브를 나타낸 함수 c_p(λ) 로 빛의 복사량을 photometric unit 으로 변환하는 식을 나타낸 것이다. 범위는 대략적인 것이다.&lt;/p&gt;

&lt;p&gt;아래 표는 radiometry, photometry 의 단위들을 비교한 표다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;symbol&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;name in radiometry&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;unit of radiometry&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;name in photometry&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;unit of photometry&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;energy&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Q&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;radiant energy&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;joule(J)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;luminous energy&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;talbot(T)=lumen second(lm⋅s)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;e/time&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;φ&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;radiant flux&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;watt(W)=(J/sec)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;luminous flux&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lumen(lm)=(T/s)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;e/t/area&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;E&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;irradiance&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;watt/area(W/m^2)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;illuminance&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lumen/area(lm/m^2)=lux(lux)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;e/t/steradian&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;L&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;radiance intensity&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;watt/steradian(W/sr)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;luminous intensity&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;lumen/steradian(lm/sr)=candela(cd)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;e/t/a/sr&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;I&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;radiance&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;watt/area/sr(W/m^2/sr)&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;luminance&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;candela/area(cd/m^2)=nit(nit)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Radiometry, Photometry 비교 표(area 의 단위는 m^2 을 사용)&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 표를 잘 살펴보면 총 4종류의 기준이 나온다. 첫번째로는 순수하게 에너지의 수량이다. 표의 첫번째 행에 나온다. 두번째는 시간인데, 일반적으로는 초를 단위로 사용하며 속도를 나타내기 위해 사용된다. 이 에너지의 속도로 대부분의 중요한 개념들이 표현된다. 세번째로는 단위 면적이다. 이는 빛 에너지를 받는 표면을 기준으로 한다. Area 의 앞글자를 따서 수식에서는 A 로 표현한다. 마지막으로 입체각(solid angle)이 존재한다. 수식에서는 Ω 로 표현한다. (보통 radian 은 학생때 부터 많이 보지만 solid angle 은 생소할 가능성이 높다. 이 블로그에도 &lt;a href=&quot;/2019/03/08/steradian-and-solid-angle&quot;&gt;solid angle 에 대해 설명한 글&lt;/a&gt;이 있다.)&lt;/p&gt;

&lt;p&gt;첫번째 행과 두번째 행의 개념은 표만 보기만 해도 쉽게 알 수 있다. 에너지의 수량과, 에너지의 속도다. radiant flux 의 정의는 다음과 같이 나타낼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

\[φ = \frac{\partial Q}{\partial t}\]

&lt;p align=&quot;center&quot;&gt;definition of radiant flux&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이제 radiant flux 는 남은 세가지 정의에서도 계속 등장한다. 남은 factor 는 area 와 solid angle 인데, 먼저 area 가 들어간 세번째 행의 e/t/area 부터 보자. 여기서 area 는 어떤 표면의 넓이를 뜻하는데, 일반적으로 빛을 받는 표면의 넓이를 뜻한다. 정의는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

\[E = \frac{\partial φ}{\partial A}\]

&lt;p align=&quot;center&quot;&gt;definition of irradiance&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이 시점에서 처음에 언급한 빛이 엄청나게 튕긴다는 사실을 다시한번 생각해보자. 그렇다면 거의 모든 방향에서 빛이 들어온다고해도 무방하다. 아래 그림을 보면서 생각해보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/irradiance2.png&quot; alt=&quot;irradiance&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Siggraph 2011 : &quot;Physically-based Lighting in Call Of Duty : Black Ops&quot;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;빨간 점은 빛을 받는 표면의 위치인데 표면의 넓이가 거의 0에 가까우니 점으로 표현되었다.(∂A) 그리고 주황색으로 표시된 화살표는 모든 방향에서 빛이 들어온다는 것을 표현하기 위한 것이다. 저 화살표가 빛을 나타내는 것이라면 화살표들이 반구를 따라서 무한히 많다고 생각할 수도 있다.&lt;/p&gt;

&lt;p&gt;사실 위의 그림은 irradiance 와 radiance 가 같이 그림으로 나와있는 그림이다. 원래 슬라이드는 다음과 같다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/irradiance_and_radiance.png&quot; alt=&quot;irradiance and radiance&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;Siggraph 2011 : &quot;Physically-based Lighting in Call Of Duty : Black Ops&quot;&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;irradiance 는 반구를 따라 무한히 많은 화살표들이 해당 위치로 들어오는 빛의 복사량을 나타내고, radiance 는 그 중 하나의 화살표를 하나 집은것과 같다. 위에서 입체각에 대해서 언급했는데, radiance 의 유도된 식은 irradiance 의 식에서 입체각에 대해서 미분한것과 같다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

\[L = \frac{\partial^2 φ}{\partial A \partial Ω}\]

&lt;p align=&quot;center&quot;&gt;definition of radiance&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;radiance 는 순수하게 ray 하나의 개념이기 때문에 꽤 많은곳에서 단위로 사용할 수 있다. 가장 대표적인 일례는 &lt;em&gt;pixel shader&lt;/em&gt; 에서 빛과 재질에 따른 컬러값을 계산한 결과가 &lt;em&gt;radiance&lt;/em&gt; 다.
&lt;!-- radiance 에 대한 설명? --&gt;&lt;/p&gt;

&lt;p&gt;마지막으로 radiance intensity 라는 개념이 있는데, 이는 radiant flux 를 입체각에 대해서 미분한 값이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

\[I = \frac{\partial φ}{\partial Ω}\]

&lt;p align=&quot;center&quot;&gt;definition of radiant intensity&lt;/p&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이는 입체각에만 신경쓰기 때문에 면적이 존재하지 않는 spot light 나 point light 의 세기를 나타내는데 쓰일 수 있다.&lt;/p&gt;

&lt;p&gt;단순하게 각 단위와 개념들에 대해서 적어보았다. PBR 에서 응용되는 빛의 단위에 대한 자세한 설명은 Siggraph 2014 : “MovingFrostbite to Physically Based Rendering 2.0” 코스 노트에서 볼 수 있다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Light Measurement Handbook, Alex Ryer, 1997&lt;/li&gt;
  &lt;li&gt;Real-Time Rendering 4th, Tomas Akenine-Möller et all, 2018&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Radiometry&quot;&gt;Wikipedia : Radiometry&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Photometry&quot;&gt;Wikipedia : Photometry&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Siggraph 2014 : “MovingFrostbite to Physically Based Rendering 2.0”&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="terminology" />
      

      

      
        <summary type="html">real-time rendering 분야에서 PBR 이 정착하게 되면서, 빛에 대한 측정 기준을 알아야 되게 되었다. 단순하지만 확실하게 정의해놓지 않으면 헷갈리는 개념이기 때문에 정리 해보려 한다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">How To Represent Transparency Object</title>
      
      <link href="https://suhyeokkim.github.io/2018/05/27/how-to-represent-transparency-object" rel="alternate" type="text/html" title="How To Represent Transparency Object" />
      <published>2018-05-27T00:00:00+00:00</published>
      <updated>2018-05-27T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/05/27/how-to-represent-transparency-object</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/05/27/how-to-represent-transparency-object">&lt;p&gt;오래전부터 게임같은 실시간으로 안정적인 성능을 뽑아내야하는 컴퓨터 그래픽에서의 투명한 물체는 항상 골칫거리였다. “투명” 하다보니 일반적으로 사용되는 최적화 방법도 사용할 수 없기 때문에 퍼포먼스의 문제가 있으며, 일반적으로 지원하는 &lt;em&gt;Alpha Blending&lt;/em&gt; 을 사용할시에는 물체의 순서를 직접 소팅해주어야 했다. 투명한 물체를 그리는 일반적인 방법의 문제에 대해서 알아보고, 문제를 부분적으로 해결할 수 있는 몇가지 방법들을 적어보겠다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;일반적으로 아무런 방법없이 투명한 그리는 방법은 뒤에있는 물체부터 순서대로 그리는 것이다. 이를 형상화 시키면 아래 그림과 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/over_operator_draw_order.png&quot; alt=&quot;over operator&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림에서는 아래부터 위쪽에 있는 문체를 순서대로 그린다. 파란색, 빨간색, 연두색 기준으로 그리게 된다. 그렇게 되면 이전에 그려진 결과와 오브젝트의 결과가 합쳐져서 표현되게 된다. 이는 다음과 같은 식으로 표현된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/over-operator_polynomial.png&quot; alt=&quot;over-operator polynomial&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/supplement/oitContinuum/2016_HPG_ExpandingOITContinuum.pdf&quot;&gt;&quot;Exploring and Expanding the Continuum of OIT Algorithms,&quot; HPG 2016.&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;a0,c0&lt;/em&gt; 는 픽셀에서 출력될 &lt;em&gt;Alpha&lt;/em&gt; 와 &lt;em&gt;Color&lt;/em&gt; 를 의미한다. 그 뒤의 항에서 &lt;em&gt;a1,c1&lt;/em&gt; 은 이전에 그려진 결과를 뜻한다. 이런 방식을 &lt;em&gt;“over”&lt;/em&gt; 연산이라고 말한다. 이런 방식은 나중에 그려진 색이 조금 더 강조되고, 이전에 그려지는 색의 존재가 조금씩 흐려지는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;이 방법의 문제는 그려지는 순서를 직접 맞춰줘야 하는 것이다. 이는 굉장히 짜증나는 문제로, 단순한 정렬만으로는 세세한 부분의 문제를 해결할 수 없다. 아래 그림은 해당 문제를 잘 나타내어 준다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/shared-OIT-example-animation_lumberyard.gif&quot; alt=&quot;Lumberyard : OIT example animation&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://docs.aws.amazon.com/ko_kr/lumberyard/latest/userguide/graphics-rendering-order-independent-transparency.html&quot;&gt;lumberyard : OIT(Order Independent Transparency)&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;상단 두개의 그림이 일반적인 &lt;em&gt;“over”&lt;/em&gt; 연산을 한 방법이다. 정렬되지 않아 미리 정해진 순서대로 출력되며 물체가 회전하면 공간상의 순서가 바뀌므로 상단 두개의 그림같이 출력된다. 그래서 이런 &lt;em&gt;Depth&lt;/em&gt; 의 정렬 문제 때문에 만들어진 용어가 있다.&lt;/p&gt;

&lt;h2&gt;Order Independent Transparency(OIT)&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;OIT&lt;/em&gt;, 순서에 구애받지 않는 투명물체를 그리는 방법을 통칭하는 용어다. 대부분의 게임에서는 &lt;em&gt;OIT&lt;/em&gt; 를 사용하여 투명물체를 그린다. 많이 알려진 방식은 두가지가 있다. &lt;em&gt;Depth Peeling&lt;/em&gt; 과 &lt;em&gt;Weighted Blended OIT&lt;/em&gt; 다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Depth Peeling&lt;/em&gt; 은 &lt;em&gt;Detph&lt;/em&gt; 를 사용하여 카메라로부터 가장 가까운(&lt;em&gt;Depth&lt;/em&gt; 값이 가장 작은) 표면의 색을 누적시키는 &lt;em&gt;OIT&lt;/em&gt; 기법이다. 직역하자면 “&lt;em&gt;Depth&lt;/em&gt; 껍질 벗기기” 인데, 조금 더 자세히 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/OIT_Lab_DepthPeeling.gif&quot; alt=&quot;OIT-Lab DepthPeeling&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://github.com/candycat1992/OIT_Lab&quot;&gt;Github : candycat1992 / OIT_Lab&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Depth Peeling&lt;/em&gt; 은 총 3단계로 이루어진다. 맨 처음에는 &lt;em&gt;Alpha&lt;/em&gt; 값에 관계없이 &lt;em&gt;Depth Test&lt;/em&gt; 를 작거나 같은값에서 되게 해두고, &lt;em&gt;Depth Write&lt;/em&gt; 가 가능하게 해준다. 그리고 그려준다. 그렇게 되면 카메라에서 가장 가까운 표면들이 처음에 그려지게 되고, 해당 상태에서 그려진 표면의 &lt;em&gt;Depth&lt;/em&gt; 값들이 &lt;em&gt;Depth Buffer&lt;/em&gt; 에 저장된다. 즉 처음에 그려진 결과를 가진 색들의 집합과 &lt;em&gt;Detph&lt;/em&gt; 의 집합을 가지고 시작한다.&lt;/p&gt;

&lt;p&gt;이제 비슷한 그리기를 계속 반복한다. 어떻게 반복하냐면, 두가지의 &lt;em&gt;Depth Test&lt;/em&gt; 를 사용해야 한다. 일단 처음과 같은 작거나 같은(&lt;em&gt;LessEqual&lt;/em&gt;) &lt;em&gt;Depth Test&lt;/em&gt; 를 계속 해주고, 여기서 추가적으로 이전에 했던 &lt;em&gt;Depth Buffer&lt;/em&gt; 의 값을 가져와 출력되는 &lt;em&gt;Depth&lt;/em&gt; 값이 작거나 같을 때 픽셀의 결과를 누락시킨다.(&lt;em&gt;Discard&lt;/em&gt;) 즉 이전에 출력한 표면을 &lt;em&gt;Depth Test&lt;/em&gt; 로 누락시키고 그 뒤에서 가장 &lt;em&gt;Depth&lt;/em&gt; 값이 작은 것들을 출력한다. 이때 &lt;em&gt;Depth&lt;/em&gt; 값은 계속 기록해야한다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/depthpeeling-crosssection.png&quot; alt=&quot;Depth Peeling Cross-Section&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://developer.download.nvidia.com/assets/gamedev/docs/OrderIndependentTransparency.pdf&quot;&gt;NVidia : Order-Independent Transparency&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;맨 처음에 했던 결과가 &lt;em&gt;Layer 0&lt;/em&gt; 의 결과이고, 두번째 과정을 반복하면 뒷부분을 계속 출력하게 된다. 그래서 임의의 횟수만큼 이와 같은 과정을 계속 반복해준다. 그러면 두번쨰 과정, &lt;em&gt;Depth Peeling&lt;/em&gt; 은 끝이다.&lt;/p&gt;

&lt;p&gt;다음은 임의의 횟수만큼 &lt;em&gt;Depth Peeling&lt;/em&gt; 을 해서 출력된 색의 결과와 &lt;em&gt;Depth Buffer&lt;/em&gt; 를 가지고 위에서 언급한 일반적인 &lt;em&gt;Alpha Blending&lt;/em&gt; 의 과정인 &lt;em&gt;“over”&lt;/em&gt; 연산을 해주면 된다. 순서는 가장 뒤에있는 결과, 마지막에 출력한 결과부터 처음 출력한 결과, 카메라에서 가장 가까운 결과까지 순서대로 &lt;em&gt;Layer&lt;/em&gt; 를 &lt;em&gt;“over”&lt;/em&gt; 연산을 통해 결합시켜주면 된다. 아래에는 &lt;em&gt;Layer&lt;/em&gt; 의 크기를 점점 증가시킨 결과를 애니메이션으로 보여주는 그림이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/depthpeeling.gif&quot; alt=&quot;OIT-Lab DepthPeeling Anim&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://github.com/candycat1992/OIT_Lab&quot;&gt;Github : candycat1992 / OIT_Lab&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;다른 방법에 비해 &lt;em&gt;Depth Peeling&lt;/em&gt; 은 그다지 좋은 방법은 아니다. 들어가는 비용이 너무 크다. &lt;em&gt;Depth Peeling&lt;/em&gt; 은 &lt;em&gt;Layer&lt;/em&gt; 가 크면 클수록 더 많은 것들을 표현할 수가 있다. 하지만 &lt;em&gt;Layer&lt;/em&gt; 의 갯수에 맞춰서 들어가는 메모리가 굉장히 크다. 우선 화면 해상도를 기준으로 색과 &lt;em&gt;Depth&lt;/em&gt; 를 저장하는 버퍼를 여러개 만들어야 한다. 그리고 &lt;em&gt;Layer&lt;/em&gt; 의 갯수만큼 &lt;em&gt;Geometry Pass&lt;/em&gt;(&lt;em&gt;Vertex Shader&lt;/em&gt;, &lt;em&gt;Tesselation&lt;/em&gt;, &lt;em&gt;Geometry Shader&lt;/em&gt;)를 반복한다. 이는 정점 데이터가 많으면 많을수록 크리티컬하다. 이런 여러가지의 단점이 있기 때문에 &lt;em&gt;Depth Peeling&lt;/em&gt; 은 잘 쓰이지 않는것으로 보인다. 또한 &lt;em&gt;Shader&lt;/em&gt; 코드내에서 &lt;em&gt;Depth Test&lt;/em&gt; 를 해주게 되면 GPU 의 &lt;em&gt;Early-Z Test&lt;/em&gt; 가 비활성화가 되기 때문에 퍼포먼스 손실도 있을 것이라고 예측된다.&lt;/p&gt;

&lt;p&gt;그래서 &lt;em&gt;Depth Peeling&lt;/em&gt; 보다는 나은 성능을 가진 &lt;em&gt;Weighted Blended OIT&lt;/em&gt; 라는 방법이 어느정도 쓰이는 것으로 보인다. &lt;em&gt;Weighted Blended OIT&lt;/em&gt; 는 2013년에 논문을 발표하였으며, 요즘에도 쓰이는 방법이다. GDC2018 에서 Agent of Mayhem 의 제작사가 &lt;em&gt;Weighted Blended OIT&lt;/em&gt; 에 대한 내용을 발표했다.(&lt;a href=&quot;https://www.dsvolition.com/publications/rendering-technology-in-agents-of-mayhem/&quot;&gt;링크&lt;/a&gt;) &lt;em&gt;Weighted Blended OIT&lt;/em&gt; 는 2013년에 고안된 기법으로 &lt;em&gt;Depth Peeling&lt;/em&gt; 보다는 덜 오래된 방법이다. &lt;em&gt;Weighted Blended OIT&lt;/em&gt; 는 물체의 색을 표현할 떄, 특정한 가중치(&lt;em&gt;weight&lt;/em&gt;)를 구해 곱해서 표현한다. 그리고 이전에 출력된 결과에 그대로 색값을 더해준다. 이제 자세한 방법에 대해서 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/weightedblendedOIT_formula_.png&quot; alt=&quot;wboit formula&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://jcgt.org/published/0002/02/09/&quot;&gt;jcgt : Weighted Blended Order-Independent Transparency&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 최종으로 나온 픽셀이 가지고 있는 색을 보여준다. &lt;em&gt;n&lt;/em&gt; 은 해당 픽셀에 그려지는 갯수이고, &lt;em&gt;α&lt;/em&gt; 는 &lt;em&gt;Alpha&lt;/em&gt;, &lt;em&gt;C&lt;/em&gt; 는 &lt;em&gt;Color&lt;/em&gt;, &lt;em&gt;Z&lt;/em&gt; 는 &lt;em&gt;Depth&lt;/em&gt;, &lt;em&gt;C0&lt;/em&gt; 는 투명 오브젝트를 그리기 전에 그려진 불투명한 표면의 색이다. 식만 봐서는 자세히는 모르기 때문에 아래 그림을 보면서 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/weightedblendedOIT_formula_explain_.png&quot; alt=&quot;wboit formula&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://jcgt.org/published/0002/02/09/&quot;&gt;jcgt : Weighted Blended Order-Independent Transparency&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;일단 총 3가지 단계로 나뉜다. &lt;em&gt;RGB * Weight&lt;/em&gt;, &lt;em&gt;Alpha * Weight&lt;/em&gt; 를 &lt;em&gt;RGBA&lt;/em&gt; 로 저장해주는 누적값(&lt;em&gt;accumulate&lt;/em&gt;)을 하나의 렌더 타겟에 저장하고, 얼마나 픽셀의 색이 덮는지에 대한 여부가 아닌, 반대로 이전의 색이 얼마만큼 노출이 될 수 있는지에 대한 노출값(&lt;em&gt;revealage&lt;/em&gt;)을 다른 하나의 렌더 타겟에 저장한다. 그 다음 그 결과를 가지고 위의 식의 값을 계산한 결과가 &lt;em&gt;Weighted, Blended OIT&lt;/em&gt; 의 끝이다. 다만 &lt;em&gt;accumulate&lt;/em&gt; 와 &lt;em&gt;revealage&lt;/em&gt; 값들은 &lt;em&gt;MRT&lt;/em&gt; 를 통해서 &lt;em&gt;DrawCall&lt;/em&gt; 을 단축시킬 수 있을 것 같다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Weight&lt;/em&gt; 값을 계산하는 방법은 여러가지가 있다. 가장 중요한 것은 &lt;em&gt;Weight&lt;/em&gt; 를 계산할 떄, &lt;em&gt;Depth&lt;/em&gt;, &lt;em&gt;Alpha&lt;/em&gt; 이 두가지를 사용하여 계산하는 것이 가장 중요한 점이다. &lt;em&gt;Depth&lt;/em&gt; 는 카메라를 기준으로 앞 뒤를 판별하는 중요한 기준이며, &lt;em&gt;Alpha&lt;/em&gt; 값은 투명한 정도를 나타내는 중요한 값이다. &lt;em&gt;weight&lt;/em&gt; 를 구하는 공식은 아래 그림을 참고하자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/weightedblendedOIT_weight_formula_.png&quot; alt=&quot;wboit formula&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://jcgt.org/published/0002/02/09/&quot;&gt;jcgt : Weighted Blended Order-Independent Transparency&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;_0.1 ≤&lt;/td&gt;
      &lt;td&gt;z&lt;/td&gt;
      &lt;td&gt;≤ 500_ 를 가정하고 만든 식이다. 이중에 &lt;em&gt;d(z)&lt;/em&gt; 라는 식이 있는데 이는 아래를 보면된다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/weightedblendedOIT_weight_formula_additional_.png&quot; alt=&quot;wboit formula&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://jcgt.org/published/0002/02/09/&quot;&gt;jcgt : Weighted Blended Order-Independent Transparency&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이는 &lt;em&gt;GLSL&lt;/em&gt; 기준으로, &lt;em&gt;HLSL&lt;/em&gt; 에서 취급하는 &lt;em&gt;Depth&lt;/em&gt; 의 범위가 달라지면 바뀔수도 있다. 식을 선택할 떄 중요한 점은 커브가 어떤식으로 생성되는지 보아야 한다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/weightedblendedOIT_weight_curve_.png&quot; alt=&quot;wboit formula&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://jcgt.org/published/0002/02/09/&quot;&gt;jcgt : Weighted Blended Order-Independent Transparency&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;논문에 실려있던 그림이며, 각 식에 따른 &lt;em&gt;weight&lt;/em&gt; 의 커브를 잘 보여준다. 어느 정도 지식이 있다면 보여주고 싶은 컨텐츠의 특성에 따라서 식을 변형을 할 수도 있겠다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;WBOIT&lt;/em&gt; 의 장점은 굉장히 전통적인 방법으로 구현이 가능하기 때문에 어떠한 기계에도 사용할 수 있다는 장점이 있다. &lt;em&gt;Depth Peeling&lt;/em&gt; 은 &lt;em&gt;MRT&lt;/em&gt; 를 사용해서 해야하므로 &lt;em&gt;DX10+&lt;/em&gt; 를 지원하는 디바이스부터 가능한 것에 비하면 굉장한 장점이다. &lt;em&gt;Occlusion Culling&lt;/em&gt; 은 안되지만 거의 &lt;em&gt;O(n)&lt;/em&gt; 의 속도와 많아봐야 2개의 해상도에 비례하는(&lt;em&gt;RGBA&lt;/em&gt;, &lt;em&gt;R&lt;/em&gt;) 메모리만 있으면 되기 때문에 투명 물체를 엄청나게 많이 출력하지 않는다면 일반적으로 쓸 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;WBOIT&lt;/em&gt; 또한 단점이 몇가지 존재한다. 첫번째로 불투명한 물체와 함께 &lt;em&gt;“over”&lt;/em&gt; 연산을 한다면 앞의 물체에 의해 가려지게 된다. 하지만 &lt;em&gt;WBOIT&lt;/em&gt; 는 물체가 다른색을 표현할 경우에는 불투명한 물체를 표현하지 못한다. 그리고 &lt;em&gt;Depth&lt;/em&gt; 값의 정밀도에 따라서 표현할 수 있는 투명한 물체의 사이의 거리가 달라진다. 아무리 식을 변형시킨다고 하더라도 부동소수점 정밀도의 문제가 생길수가 있다. 마지막으로 모든 오브젝트가 카메라의 &lt;em&gt;Z&lt;/em&gt; 축을 따라서 움직인다면 출력값은 달라질 것이다. 이는 &lt;em&gt;weight&lt;/em&gt; 계산에 &lt;em&gt;Depth&lt;/em&gt; 값이 들어가서 이러한 결과를 보여주는데, 해당 논문에는 그다지 신경쓰지 않았다고 적혀있다.&lt;/p&gt;

&lt;p&gt;하지만 위의 단점은 충분히 안고갈만한 단점이기 때문에 투명한 물체를 그릴 때는 &lt;em&gt;Weighted Blended OIT&lt;/em&gt; 가 가장 나은 방법이라고 본다. 아래 &lt;em&gt;Alpha Blend, Detph Peeling, _Weighted Blended OIT&lt;/em&gt; 이 세가지 방법에 대한 비교 영상이 있다.&lt;/p&gt;

&lt;style&gt;.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }&lt;/style&gt;
&lt;div class=&quot;embed-container&quot;&gt;    &lt;iframe title=&quot;YouTube video player&quot; width=&quot;640&quot; height=&quot;390&quot; src=&quot;//www.youtube.com/embed/JVa9xXddgbM&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;p&gt;위에서 언급한 &lt;a href=&quot;https://www.dsvolition.com/publications/rendering-technology-in-agents-of-mayhem/&quot;&gt;Rendering Technology in ‘Agents of Mayhem’&lt;/a&gt; PT 에서는 기존의 &lt;em&gt;WBOIT&lt;/em&gt; 에서 &lt;em&gt;Emmisive&lt;/em&gt; 한 물체를 위해 추가적인 화면 해상도에 비례하는 버퍼를 사용하여 빛나는 투명 물체를 표현하는 방법을 서술해놓았다. 또한 해당 논문의 저자가 1년전에 고안한 &lt;a href=&quot;https://www.youtube.com/watch?v=jWe5Ae22Ffs&amp;amp;t=555s&quot;&gt;&lt;em&gt;Phenomenological Transparency&lt;/em&gt;&lt;/a&gt; 라는 방법도 있다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://cwyman.org/papers.html&quot;&gt;cwyman.org : “Exploring and Expanding the Continuum of OIT Algorithms,” HPG 2016.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://developer.download.nvidia.com/assets/gamedev/docs/OrderIndependentTransparency.pdf&quot;&gt;NVidia : Order-Independent Transparency&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://developer.download.nvidia.com/SDK/10.5/opengl/src/dual_depth_peeling/doc/DualDepthPeeling.pdf&quot;&gt;NVidia : Order Independent Transparency with Dual Depth Peeling&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://jcgt.org/published/0002/02/09/&quot;&gt;jcgt : Weighted Blended Order-Independent Transparency&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://casual-effects.blogspot.com/2015/03/implemented-weighted-blended-order.html&quot;&gt;Implementing Weighted, Blended Order-Independent Transparency&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/candycat1992/OIT_Lab&quot;&gt;Github : candycat1992 / OIT_Lab&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.dsvolition.com/publications/rendering-technology-in-agents-of-mayhem/&quot;&gt;GDC2018 : Rendering Technology in ‘Agents of Mayhem’&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=jWe5Ae22Ffs&amp;amp;t=555s&quot;&gt;Youtube : Phenomenological Transparency&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="rendering" />
      
        <category term="transparency" />
      

      

      
        <summary type="html">오래전부터 게임같은 실시간으로 안정적인 성능을 뽑아내야하는 컴퓨터 그래픽에서의 투명한 물체는 항상 골칫거리였다. “투명” 하다보니 일반적으로 사용되는 최적화 방법도 사용할 수 없기 때문에 퍼포먼스의 문제가 있으며, 일반적으로 지원하는 Alpha Blending 을 사용할시에는 물체의 순서를 직접 소팅해주어야 했다. 투명한 물체를 그리는 일반적인 방법의 문제에 대해서 알아보고, 문제를 부분적으로 해결할 수 있는 몇가지 방법들을 적어보겠다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Opaque As Alpha Test</title>
      
      <link href="https://suhyeokkim.github.io/2018/05/22/opaque-as-alpha-test" rel="alternate" type="text/html" title="Opaque As Alpha Test" />
      <published>2018-05-22T00:00:00+00:00</published>
      <updated>2018-05-22T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/05/22/opaque-as-alpha-test</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/05/22/opaque-as-alpha-test">&lt;p&gt;&lt;em&gt;Shader&lt;/em&gt; 에서 샘플링하는 &lt;em&gt;Texutre&lt;/em&gt; 에서 &lt;em&gt;Alpha&lt;/em&gt; 값을 가지고 있어, &lt;em&gt;Alpha&lt;/em&gt; 을 참조해서 실제 픽셀에 출력을 하는지 안하는지를 결정하는 것을 &lt;em&gt;Alpha Test&lt;/em&gt; 라고 한다. 이런 &lt;em&gt;Material&lt;/em&gt; 이나 &lt;em&gt;Texture&lt;/em&gt; 를  &lt;em&gt;Cutout&lt;/em&gt; 이라고 통칭하는 경우가 많다.&lt;/p&gt;

&lt;p&gt;보통 게임에서의 &lt;em&gt;Alpha Test&lt;/em&gt; 를 사용하는 것들은 나무, 풀 같은 식생들(&lt;em&gt;Vegetation&lt;/em&gt;)이 있고, 중간에 구멍이 뚫린 펜스같은 것들도 존재한다. 자연을 배경으로하는 게임의 경우에는 식생들이 굉장히 많기 때문에 &lt;em&gt;Alpha Test&lt;/em&gt; 를 사용하는 &lt;em&gt;Shader&lt;/em&gt; 가 굉장히 많이 사용될 것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/1_8EKqWSOOPXaTrDHVFTACJg.png&quot; alt=&quot;Wikipedia : Single-precision floating-point format&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://medium.com/@bgolus/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f&quot;&gt;Anti-aliased Alpha Test: The Esoteric Alpha To Coverage&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;하지만 &lt;em&gt;Alpha Test&lt;/em&gt; 는 굉장히 큰 단점이 있다. 고정된 화면 해상도에서 물체가 작게 표현되면 물체를 표현할 수 있는 픽셀의 숫자가 많이 작아진다. 물체를 표현하는 픽셀의 수가 작아지게 되면 일반적으로 해당 넓이에 맞게 생성된 &lt;em&gt;Texture&lt;/em&gt; 의 &lt;em&gt;Mip-level&lt;/em&gt; 에 접근한다. 중간의 &lt;em&gt;Alpha Test&lt;/em&gt; 그림을 보면된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/1_zNbZFiJXjcqqyTkM9eEt7w.gif&quot; alt=&quot;Wikipedia : Single-precision floating-point format&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://medium.com/@bgolus/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f&quot;&gt;Anti-aliased Alpha Test: The Esoteric Alpha To Coverage&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;실제로는 양 옆의 물체들처럼 자연스럽게 표현이 되야하지만 일반적인 &lt;em&gt;Alpha Test&lt;/em&gt; 를 사용하게 되면 위와 같은 현상에 마주치게 된다. 이는 굉장히 끔찍한 현상이다. 실제 게임을 해보거나, 만들어본 사람이라면 안다. 대부분의 픽셀에 나무가 표현되고, 잎사귀들이 저런식으로 자글자글 거린다면 약간의 불쾌함이 느껴진다. VR 이라면 더욱..&lt;/p&gt;

&lt;p&gt;그래서 급하게 대처방안으로 나온 것이 위 그림의 오른쪽에 나오는 &lt;em&gt;Alpha to Coverage&lt;/em&gt; 라는 방법이다. 이는 하드웨어 &lt;em&gt;MSAA&lt;/em&gt; 를 픽셀 쉐이더의 결과를 통해 자동으로 해주는것으로, &lt;em&gt;MSAA&lt;/em&gt; 의 퍼포먼스와 비례한다. &lt;em&gt;MSAA&lt;/em&gt; 는 성능이 영 좋지않아 안쓰는 경우가 꽤 많이 존재하기 때문에 &lt;em&gt;Alpha to Coverage&lt;/em&gt; 는 절대적으로 사용할 수 있는 방법은 아니다. 게다가 엄청나게 많은 나무를 &lt;em&gt;Alpha to Coverage&lt;/em&gt; 를 쓴다면.. 성능은 안봐도 뻔하다.&lt;/p&gt;

&lt;p&gt;앞서 말한 &lt;em&gt;Alpha Test&lt;/em&gt; 은 &lt;em&gt;Material&lt;/em&gt;, &lt;em&gt;Shader&lt;/em&gt; 별로 고정된 &lt;em&gt;Alpha&lt;/em&gt; 값을 설정해 그 이하가 되면 &lt;em&gt;Pixel Shader&lt;/em&gt; 에서 결과를 내놓지 않게 하는(&lt;em&gt;Discard&lt;/em&gt;) 방법이였다. &lt;em&gt;Alpha Test&lt;/em&gt; 의 문제는 샘플링한 &lt;em&gt;Alpha&lt;/em&gt; 값이 가끔 극단적으로 낮아서 &lt;em&gt;Discard&lt;/em&gt; 되는 것인데, 이를 간단하게 해결하기 위해 요상한 방법이 등장했다.&lt;/p&gt;

&lt;p&gt;바로 &lt;em&gt;Stochastic test&lt;/em&gt; 라는 방법이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/stochastic_sampling.png&quot; alt=&quot;NVidia deverloper : Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://developer.download.nvidia.com/assets/gameworks/downloads/regular/GDC17/RealTimeRenderingAdvances_HashedAlphaTesting_GDC2017_FINAL.pdf?pUIX8DXxfad7mL4zB3GOthX3r5IgGao9UWxYuYb3q9h10RXrQeYko-dEuJXJxt1hhsI9J_9KJDcCYGeWWksxlaHTrXSE825D_3izja7LUFOtzhaeBUqpn7qbwXaaGlLdbipjE3PeI3e2IMn45mQAA3OV2PD-kG2y9cecTaWE2uum2uwdHgyn0nhYiLOvlOsrUzewbK5REH7vAm3-lNWzxehw_5Tphg&quot;&gt;NVidia developer : Hashed Alpha Testing&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 그림에서 위쪽에 있는 것이 일반적인 &lt;em&gt;Alpha Test&lt;/em&gt; 인데, &lt;em&gt;color.a&lt;/em&gt; 는 텍스쳐에서 샘플링한 &lt;em&gt;Alpha&lt;/em&gt; 값, &lt;em&gt;ατ&lt;/em&gt; 는 &lt;em&gt;Alpha Test&lt;/em&gt; 를 위한 고정된 &lt;em&gt;Alpha Threshold&lt;/em&gt;(&lt;em&gt;알파한계&lt;/em&gt;)다. 밑의 코드에서 &lt;em&gt;drand48&lt;/em&gt; 이 나타내는 것은 단순한 0 ~ 1 사이의 랜덤값이다. 즉 랜덤하게 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 설정해주어 물체가 멀어져서 평균 &lt;em&gt;Alpha&lt;/em&gt; 값이 낮아질 때도 픽셀이 &lt;em&gt;Discard&lt;/em&gt; 되지 않도록 하는 것이다. 하지만 이는 굉장한 눈아픔? 반짝거림? 을 유발한다. 범위를 지정해주지 않았기 때문에 이전 프레임에서 출력된 픽셀이 다음 프레임에서는 출력되지 않을 수도 있다. 이렇게 각 프레임마다 상황이 달라서 생기는 현상앞에 &lt;em&gt;Temporal&lt;/em&gt; 을 붙인다. &lt;em&gt;Stochastic Alpha Test&lt;/em&gt; 의 문제는 &lt;em&gt;Temporal Flickering&lt;/em&gt; 이라고 할 수 있겠다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Temporal Flickering&lt;/em&gt; 이 없는, &lt;em&gt;Temporal Stability&lt;/em&gt;(임시적 안정성) 을 확보하기 위해서는 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 이러저리 튀지 않게해야 했고, 이를 위해 특정 값에 따라서 &lt;em&gt;Hash&lt;/em&gt; 값을 생성하는 방법이 고안되었다. 이 방법은 &lt;em&gt;Hashed Alpha Test&lt;/em&gt; 라는 이름으로 작년에 공개되었다.&lt;/p&gt;

&lt;h2&gt;Hashed Alpha Testing&lt;/h2&gt;

&lt;p&gt;기본적으로 랜덤 값(난수) 생성은 제대로된 난수생성이 아닌, 특수한 식을 사용해서 의사 난수 생성 방법을 이용하는데, &lt;em&gt;Hash&lt;/em&gt; 를 이용한 난수생성은 일반적으로 많이 쓰인다고 한다. &lt;em&gt;Hashed Alpha Testing&lt;/em&gt; 은 &lt;em&gt;Hash&lt;/em&gt; 를 생성하기 위한 &lt;em&gt;Key&lt;/em&gt; 값을 선정하는데 조심스러웠다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Key&lt;/em&gt; 로 선정될 수 있는 후보는 &lt;em&gt;Texture Coordinate&lt;/em&gt;, &lt;em&gt;World-Space Coordinate&lt;/em&gt;, &lt;em&gt;Ojbect-Space Coordinate&lt;/em&gt; 이 세가지 였다고 한다. &lt;em&gt;Texture Coordinate&lt;/em&gt; 는 가끔 없는 경우가 있어 제외하였고, &lt;em&gt;World-Space Coordinate&lt;/em&gt; 는 정적 물체에는 원하는대로 동작하지만, 동적 물체의 경우에는 문제가 있었다고 한다. 결국 남은건 &lt;em&gt;Ojbect-Space Coordinate&lt;/em&gt; 가 남게 되었다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ojbect-Space Coordinate&lt;/em&gt; 의 &lt;em&gt;X,Y,Z&lt;/em&gt; 세 좌표를 모두 이용하게 되는데, 이는 &lt;em&gt;X,Y&lt;/em&gt; 두개만 이용하게 되면 &lt;em&gt;Hash&lt;/em&gt; 값이 &lt;em&gt;Screen-Space&lt;/em&gt; 에서 생성되어 다른 물체와 겹치게 되면 &lt;em&gt;Alpha to Coverge&lt;/em&gt; 같은 효과를 내게되어 3가지 좌표 모두 &lt;em&gt;Hash&lt;/em&gt; 생성에 사용된다고 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 중요한 포인트는 &lt;em&gt;Temporal Stability&lt;/em&gt; 를 확보하는 것이다. 이해하기 쉽게 설명하자면, 아래와 같은 각 픽셀을 나타내는 그리드안에 점이 있다고 가정해보자. 이 점들이 조금씩 움직여서 계속 픽셀안에 있다면, 같은 &lt;em&gt;Hash&lt;/em&gt; 값을 사용하여 같은 &lt;em&gt;Alpha Threshold&lt;/em&gt; 값을 만들어줘야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/subpixel_0.png&quot; alt=&quot;Subpixel 0&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;아래 두 그림의 빨간 점의 위치처럼 원래의 픽셀위치를 벗어나게 된다면 새로운 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 생성해야 하겠지만, 위치가 많이 바뀌지 않는다면 같은 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 사용해 &lt;em&gt;Flickering&lt;/em&gt; 을 최대한 줄여야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/subpixel_2.png&quot; alt=&quot;Subpixel 2&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이러한 맥락으로 &lt;em&gt;Hashed ALpha Testing&lt;/em&gt; 은 &lt;em&gt;Temporal Stability&lt;/em&gt; 를 조금 확보하게 된다. 물론 위의 그림은 이해를 돕기위한 용도로, 실제 코드상에서는 다른 방법을 통해 계산된다. 아래 코드를 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hat_codesnippet_screenxy.png&quot; alt=&quot;Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;Cwyman.org : Hashed Alpha Test(Extended)&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 코드는 픽셀이 가지고 있는 &lt;em&gt;Object-Space Coordinate&lt;/em&gt; 의 옆 픽셀과의 차이, 세로에 있는 픽셀과의 차이를 통한 값으로 계산한다. (dFdX, dFdY 의 자세한 내용은 찾아보거나 &lt;a href=&quot;/2018/03/04/what-is-ddx-and-ddy&quot;&gt;What is ddx and ddy&lt;/a&gt; 에서 볼 수 있다.) 픽셀별로 값의 차이, 즉 근접한 픽셀의 위치 차이값에 따른값(미분값)과 그 값을 이용해 &lt;em&gt;Object-Space Coordinate&lt;/em&gt; 값에 곱한 값을 &lt;em&gt;Key&lt;/em&gt; 로 두어서 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 계산한다.&lt;/p&gt;

&lt;p&gt;마지막에 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 구하는 코드를 보면, &lt;em&gt;Floor&lt;/em&gt; 하는, 올림을 해주어 &lt;em&gt;discrete value&lt;/em&gt; 로 &lt;em&gt;Key&lt;/em&gt; 값을 넣어준다. &lt;em&gt;Floor&lt;/em&gt; 가 의미하는 것은, 선형적인 데이터가 아닌 뚝뚝 끊기는 데이터로 만들어 특정한 값을 넘어야 &lt;em&gt;Key&lt;/em&gt; 값이 바뀌게 하여 &lt;em&gt;Hash&lt;/em&gt; 를 유지해 &lt;em&gt;Flickering&lt;/em&gt; 을 방지하는 것이다. 아래 그림은 &lt;em&gt;floor(x)&lt;/em&gt; 의 그래프다. 즉 코드의 &lt;em&gt;pixScale&lt;/em&gt; 이 크면 클수록 &lt;em&gt;Hash&lt;/em&gt; 의 값은 픽셀의 변화에 따라서 빠르게 바뀌고, 작으면 작을수록(0에 가까워질수록) 픽셀의 변화에 따라서 &lt;em&gt;Hash&lt;/em&gt; 값이 느리게 바뀔 것이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/wolframalpha_floor.gif&quot; alt=&quot;Woflram Alpha : Floor Graph&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://www.wolframalpha.com/input/?i=floor&quot;&gt;Wolframalpha&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이러한 방법은 &lt;em&gt;View-Space&lt;/em&gt; 를 기준으로 &lt;em&gt;X,Y&lt;/em&gt; 좌표가 조금씩 바뀔때는 픽셀끼리의 차이를 계산하기 때문에 안정적이다. 하지만 &lt;em&gt;Z(Depth)&lt;/em&gt; 값이 바뀔때는 많은 &lt;em&gt;Flickering&lt;/em&gt; 을 일으킬 것이다. 이를 해결하기 위해 아래 코드를 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hat_codesnippet_screenz0.png&quot; alt=&quot;Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;Cwyman.org : Hashed Alpha Test(Extended)&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위치의 픽셀별 차이 벡터의 크기를 &lt;em&gt;discrete&lt;/em&gt; 시키는 방법도 좋은 아이디어중 하나다. 하지만 이는 빌보드처럼 큰 크기의 판이 다가오게 된다면 끝부분의 &lt;em&gt;discontinuity&lt;/em&gt; 를 유발하게 된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hat_codesnippet_screenz1.png&quot; alt=&quot;Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;
&lt;img src=&quot;/images/hat_codesnippet_lerpscale.png&quot; alt=&quot;Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;Cwyman.org : Hashed Alpha Test(Extended)&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그래서 위 코드와 같 &lt;em&gt;discretize&lt;/em&gt; 시킨 올림처리한 값과, 내림처리한 값을 사용한 두 &lt;em&gt;Hash&lt;/em&gt; 값 사이의 보간을 통해서 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 구해준다. 하지만 이 코드는 아직 문제점이 존재한다. 만약 &lt;em&gt;maxDeriv&lt;/em&gt; 의 값이 0 ~ 1 사이라면 내림값이 반드시 0이 되기 때문에 보간할 값 중 한개의 값이 고정되게 된다. 그래서 아래와 같은 코드를 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hat_codesnippet_exp2.png&quot; alt=&quot;Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;Cwyman.org : Hashed Alpha Test(Extended)&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;pixScale&lt;/em&gt; 을 그냥 계산하는 대신, &lt;em&gt;discretize&lt;/em&gt; 된 두개의 스케일값을 2의 지수로 표현하여 값이 0으로 되는 것을 막는다. 이렇게 보간된 값을 사용하여 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 정해주면 약간의 문제가 생긴다. 보간을 함으로써 균일하지 않게 랜덤값이 분포되었기 때문이다. 그래서 아래와 같은 식을 사용하여 다시 값을 분포시켜준다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hat_codesnippet_cdf.png&quot; alt=&quot;Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;Cwyman.org : Hashed Alpha Test(Extended)&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위의 식을 적용하면 모든 값들이 균일하게 분포되어 진정한 랜덤값의 &lt;em&gt;Alpha Threshold&lt;/em&gt; 가 생성된다고 한다. 아래는 전체 코드다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/hat_codesnippet_whole.png&quot; alt=&quot;Hashed Alpha Testing&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;Cwyman.org : Hashed Alpha Test(Extended)&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;자세한 사항은 논문에서 확인할 수 있다(&lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;[Cwyman17]&lt;/a&gt;). 결과는 아래 유튜브 영상에서 확인할 수 있다.&lt;/p&gt;

&lt;style&gt;.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }&lt;/style&gt;
&lt;div class=&quot;embed-container&quot;&gt;    &lt;iframe title=&quot;YouTube video player&quot; width=&quot;640&quot; height=&quot;390&quot; src=&quot;//www.youtube.com/embed/p4TYf5DDpbQ&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;p&gt;이를 통해 전보다 훨씬 나은 &lt;em&gt;Alpha Test&lt;/em&gt; 품질을 얻을 수 있게 되었다. 하지만 &lt;em&gt;Hashed Alpha Testing&lt;/em&gt; 의 결과는 &lt;em&gt;Stochastic Test&lt;/em&gt; 처럼 픽셀이 흩뿌려진 느낌을 지울 수 없다. 어느정도의 랜덤값에서 생성이되니 이는 어쩔 수 없는 결과다.&lt;/p&gt;

&lt;h2&gt;Alpha Distribution&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Alpha Test&lt;/em&gt; 의 구린 품질을 좀 더 개선할 수 있는 방법이 또 있다. 이번년도 &lt;em&gt;I3D&lt;/em&gt; 에 제출된 &lt;em&gt;Alpha Distribution&lt;/em&gt; 이라는 논문이 있는데, 이는 &lt;em&gt;Hashed Alpha Testing&lt;/em&gt; 처럼 런타임에 계산을 하지않고 각 &lt;em&gt;Mip-level&lt;/em&gt; 의 텍스쳐를 미리 처리해놓는 방법 중에 하나다. 미리 계산된 &lt;em&gt;Texture&lt;/em&gt; 들을 사용하여 일반적인 &lt;em&gt;Alpha Test&lt;/em&gt; 를 그대로 사용하기만 하면 된다. 아직 직접 사용한 예시는 없어 검증되지는 않았지만, 이 방법이 그대로 사용될 수 있다면 &lt;em&gt;Alpha Test&lt;/em&gt; 부분에서는 거의 끝판왕이 될 것 같다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Alpha Distribution&lt;/em&gt; 일반적인 &lt;em&gt;Alpha Test&lt;/em&gt; 를 기준으로 &lt;em&gt;Alpha Threshold&lt;/em&gt; 가 고정되어 있다는 것을 가정한다. 그렇게 되면 &lt;em&gt;Alpha Threshold&lt;/em&gt; 에 따라서 픽셀에 출력이 되냐, 안되냐로  따질 수가 있다.(&lt;em&gt;Binary Visibility&lt;/em&gt;) &lt;em&gt;Binary Visibility&lt;/em&gt; 를 각 &lt;em&gt;Mip-level&lt;/em&gt; 에 맞춰서 고르게 분산(&lt;em&gt;Distribution&lt;/em&gt;)시키는게 &lt;em&gt;Alpha Distribution&lt;/em&gt; 의 목적이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Alpha Distribution&lt;/em&gt; 은 두가지 분산방법을 사용한다. &lt;em&gt;Error Diffusion&lt;/em&gt; 과 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 이라는 방법을 사용한다. 하나씩 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Error Diffusion&lt;/em&gt; 은 하나하나의 픽셀을 순회하면서, 각 픽셀의 &lt;em&gt;Binary Visibility&lt;/em&gt; 에 해당하는 값(0 아니면 1)과 이미지가 가지고 있는 &lt;em&gt;Alpha&lt;/em&gt; 값을 비교해 그 오차(&lt;em&gt;Quantization Error&lt;/em&gt;)를 다른 픽셀에 나누어준다. &lt;em&gt;Binary Visibility&lt;/em&gt; 는 다음과 같이 정해진다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;αˆi = αi &amp;gt;= ατ : 1, αi &amp;lt; ατ : 0&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;αi 는 이미지가 가지고 있는 이산화된 &lt;em&gt;Alpha&lt;/em&gt; 값이고, ατ 는 &lt;em&gt;Alpha Threshold&lt;/em&gt;, 한계값을 뜻한다. αˆi 는 해당 픽셀의 &lt;em&gt;Binary Visibility&lt;/em&gt; 를 뜻한다. 이것을 가지고 &lt;em&gt;Quantization Error&lt;/em&gt; 를 계산한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;ϵi = αi − αˆi&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;ϵi 는 &lt;em&gt;Quantization Error&lt;/em&gt; 를 뜻하고 픽셀이 보이게 된다면 &lt;em&gt;~1 &amp;lt;= ϵi &amp;lt; 0&lt;/em&gt; 의 값을 가지게 되고 픽셀이 보이지 않는다면 &lt;em&gt;0 &amp;lt; ϵi &amp;lt;= 1&lt;/em&gt; 의 값을 가지게 된다. 이런 &lt;em&gt;Quantization Error&lt;/em&gt; 는 인근 픽셀로 분포된다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/ad_error_diffusion.png&quot; alt=&quot;Error Diffusion&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림에서 ϵi 가 들어가 있는 부분이 현재 처리중인 픽셀이며, ϵi 의 값은 인근 픽셀로 고정된 비율로 &lt;em&gt;Alpha&lt;/em&gt; 값에 더해진다. (x+1,y) 는 7/16, (x-1,y+1) 은 3/16, (x,y+1) 은 5/16, (x+1,y+1) 은 1/16 비율로 분포된다. 이런 방법으로 각 픽셀을 순회하면서 처리하면 &lt;em&gt;Error Diffusion&lt;/em&gt; 은 간단하게 끝난다. 오차 확산이라는 이름이 굉장히 직관적이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Error Diffusion&lt;/em&gt; 은 픽셀과 픽셀사이의 &lt;em&gt;Alpha&lt;/em&gt; 값을 고르게 분포시킨다. 하지만 약간의 문제가 존재한다. 보이게 되던, 안보이게 되던 &lt;em&gt;Alpha&lt;/em&gt; 값이 0.3 ~ 0.7 정도로 중간값을 가지고 있다면, 한 픽셀은 강조되고, 옆의 픽셀은 보이지 않게 된다. 이러한 방법은 아래 이미지와 비슷한 결과를 만든다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
![Michelangelo’s_David_-&lt;em&gt;Floyd-Steinberg](/images/Michelangelo’s_David&lt;/em&gt;-_Floyd-Steinberg.png){: .center-image}&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/Dither&quot;&gt;Wikipedia : Dither&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Error Diffusion&lt;/em&gt; 의 문제는 위 그림처럼 비슷한 색 영역에 있어도 분산된 영향을 받아서 각 픽셀이 부드럽게 보이지 않는 현상이 발생한다. 이러한 특징을 &lt;em&gt;Dithering&lt;/em&gt; 이라고 부른다. 그래서 &lt;em&gt;Alpha Distribution&lt;/em&gt; 논문에서는 이보다 나은 품질을 위해 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 라는 다른 방법이 소개된다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/alpha_pyramid.png&quot; alt=&quot;Cemyuksel : Alpha Distribution&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://www.cemyuksel.com/research/alphadistribution/&quot;&gt;Cemyuksel : Alpha Distribution&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Alpha Pyramid&lt;/em&gt; 은 &lt;em&gt;Error Diffusion&lt;/em&gt; 보다는 좀 더 복잡한 방식이다. &lt;em&gt;Alpha Pyramid&lt;/em&gt; 라는 밉맵같은 개념의 텍스쳐들을 생성하고, 그 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 를 사용해서 &lt;em&gt;Alpha&lt;/em&gt; 값들을 분산시키는 방법이다. &lt;em&gt;Alpha Pyramid&lt;/em&gt; 를 만들고 값을 다루는 방법에 대해서 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Alpha Pyramid&lt;/em&gt; 은 각각의 &lt;em&gt;mip-level&lt;/em&gt; 마다 하나씩 생성된다. 즉 이미지 한개씩만 처리한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Alpha Pyramid&lt;/em&gt; 를 만들떄 맨 처음에 &lt;em&gt;Mip-Map&lt;/em&gt; 과 비슷한 방식으로 &lt;em&gt;Sub-level&lt;/em&gt; 들을 만든다. 맨 처음에 생성되는 &lt;em&gt;level&lt;/em&gt; 의 해상도는 이미지 해상도의 1/4(1/2*1/2) 을 곱한 해상도로, 2의 지수가 아니여도 된다. 이렇게 생성된 &lt;em&gt;level 1&lt;/em&gt; 은 약 원본 이미지의 해상도가 1/4이 되는데, &lt;em&gt;level 0&lt;/em&gt; 의 각 픽셀들에 적어도 원본 이미지의 픽셀 4개의 알파값들을 더해서 저장한다. 원본 이미지의 해상도가 2의 지수가 아니라면 &lt;em&gt;level 0&lt;/em&gt; 세로와 가로 끝부분의 픽셀들은 픽셀 6개의 알파값들을 더해서 저장하고, 가장 모서리의 픽셀 하나는 픽셀 9개의 알파값을 더해서 저장한다. 위의 이미지는 그리드로 원본의 해상도를 표시하고, 색으로 해당 레벨의 실질적인 픽셀들을 표시한다.&lt;/p&gt;

&lt;p&gt;원본 이미지와 &lt;em&gt;level 1&lt;/em&gt; 의 관계는 &lt;em&gt;level 1&lt;/em&gt; 생성한 후 다음 &lt;em&gt;Level 2&lt;/em&gt; 을 생성할 때 &lt;em&gt;level 1&lt;/em&gt; 과 &lt;em&gt;level 2&lt;/em&gt; 의 관계와 같다. 즉 같은 방법을 2x2 해상도가 될떄까지 계속 반복한다. 이렇게 생성된 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 의 각 레벨의 텍셀은 하위 레벨의 연관된 &lt;em&gt;Alpha&lt;/em&gt; 값들의 합을 가지고 있는다. 이를 누적된 알파값(&lt;em&gt;Accumulated Alpha&lt;/em&gt;)라고 부르겠다.&lt;/p&gt;

&lt;p&gt;다음은 각각의 &lt;em&gt;Accumulated Alpha&lt;/em&gt; 을 가지고 각각의 픽셀의 보여주는 여부를 결정하는 &lt;em&gt;Visibility Value&lt;/em&gt; 를 구해야 한다. 처음에는 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 의 최상위 레벨의 각각의 &lt;em&gt;Accumulated Alpha&lt;/em&gt; 값들의 합을 구하여 올림을 해준 값을 가지고 있는다. (이 값은 입력으로 들어온 이미지의 보여지는 픽셀을 정하는 값으로, 이 값이 하위 층으로 한층한층 분산되면서 결국 이미지의 보여지는 픽셀을 결정하게 된다. 논문에서는 텍스쳐 전체의 &lt;em&gt;Visibility Value&lt;/em&gt; 라고도 한다.) &lt;em&gt;Alpha Pyramid&lt;/em&gt; 의 최상위 레벨의 각각의 &lt;em&gt;Accumulated Alpha&lt;/em&gt; 의 정수부의 값만(일반적으로 &lt;em&gt;Alpha&lt;/em&gt; 값은 0 ~ 1 사이의 소수.) &lt;em&gt;Visibility Value&lt;/em&gt; 에 저장한다. 그리고 각 &lt;em&gt;Accumulated Alpha&lt;/em&gt; 의 소수부 값들 중 큰 값들만 &lt;em&gt;Visibility Value&lt;/em&gt; 를 1씩 나누어준다. 이러면 모든 &lt;em&gt;Visibility Value&lt;/em&gt; 가 분산된다. 이렇게 최상위 층의 처리가 끝난다.&lt;/p&gt;

&lt;p&gt;그 다음 각각의 층들이 처리가 되야한다. 최상위 층은 각 &lt;em&gt;Accumulated Alpha&lt;/em&gt; 을 가지고 있는 윗층이 없어 직접 구했지만, 아랫층부터는 상위 층들이 &lt;em&gt;Accumulated Alpha&lt;/em&gt; 합을 구해서 가지고 있다. 이 값을 가지고 위에서 언급한 &lt;em&gt;Visibility Value&lt;/em&gt; 를 계산하여 계속 구한다. &lt;em&gt;level 1&lt;/em&gt; 까지 이 과정을 반복하면 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 내부에서 처리하는 과정은 끝난다.&lt;/p&gt;

&lt;p&gt;다음은 마지막으로 계산된 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 의 최하층 &lt;em&gt;level 1&lt;/em&gt; 의 &lt;em&gt;Visibility Value&lt;/em&gt; 들과 맨 처음 입력으로 들어온 이미지를 처리한다. (위에서 &lt;em&gt;Binary Visibility&lt;/em&gt; 에 대한 언급을 했었다. &lt;em&gt;Alpha Test&lt;/em&gt; 의 이미지는 결국 보이냐, 안보이냐의 차이이기 때문에 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 도 &lt;em&gt;level 1&lt;/em&gt; 의 &lt;em&gt;Visibility Value&lt;/em&gt; 를 통해 이미지의 &lt;em&gt;Binary Visibility&lt;/em&gt; 를 처리해준다.) &lt;em&gt;level 1&lt;/em&gt; 에 관련된 2x2,2x3,3x2,3x3 픽셀의 &lt;em&gt;Binary Visibility&lt;/em&gt; 를 처리한다. &lt;em&gt;level 1&lt;/em&gt; 의  &lt;em&gt;Visibility Value&lt;/em&gt; 의 값을 기존 이미지가 가지고 있는 &lt;em&gt;Alpha&lt;/em&gt; 값이 큰 순서대로 1씩 나누어준다.(보이게 처리한다.) 그렇게 &lt;em&gt;Visibility Value&lt;/em&gt; 를 다 쓰게되고 남아있는 픽셀들은 안보이게 처리한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Alpha Pyramid&lt;/em&gt; 는 순서대로 텍스쳐의 층을 쌓은 후 최상층에서 다시 차례대로 내려오면서 &lt;em&gt;Visibility Value&lt;/em&gt; 를 분산시키고, 마지막으로 이미지의 각 픽셀의 &lt;em&gt;Binary Visibility&lt;/em&gt; 를 정해주는 방법이다.&lt;/p&gt;

&lt;p&gt;이 글에서의 &lt;em&gt;Alpha Distribution&lt;/em&gt; 에 대한 내용은 논문 뿐만 아니라 논문의 저자가 제공한 코드까지 참조하여 썼다. 근데 논문의 내용중 여기서 언급하지 않은 내용이 있다. 저자가 &lt;a href=&quot;https://github.com/cemyuksel/cyCodeBase/blob/master/cyAlphaDistribution.h&quot;&gt;제공한 코드&lt;/a&gt;에서는 &lt;em&gt;Visibility Value&lt;/em&gt; 를 분산시킬 떄 소수부의 값이 큰 기준으로 분산시킨다. 하지만 논문에서는 이를 랜덤하게 처리한다고 한다. 왜냐하면 균일한 패턴의 생성을 막기 위해서라고 한다. 하지만 제공되는 코드에서는 랜덤하게 설정하는 부분은 없었다. 또한 코드에서는 &lt;em&gt;Alpha Threshold&lt;/em&gt; 를 0.5 로 가정하여 코드를 짜놓아서&lt;/p&gt;

&lt;p&gt;방법만 봐도 여러가지 이유로 &lt;em&gt;Alpha Pyramid&lt;/em&gt; 이 &lt;em&gt;Error Diffusion&lt;/em&gt; 보다는 더 나은 &lt;em&gt;Alpha Test&lt;/em&gt; 를 제공할 것 같다는 생각이 든다. 논문에서도 실제로 더 나은 품질을 보여준다고 한다.&lt;/p&gt;

&lt;style&gt;.embed-container { position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 100%; } .embed-container iframe, .embed-container object, .embed-container embed { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }&lt;/style&gt;
&lt;div class=&quot;embed-container&quot;&gt;    &lt;iframe title=&quot;YouTube video player&quot; width=&quot;640&quot; height=&quot;390&quot; src=&quot;//www.youtube.com/embed/cjHfPi9lQik&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;&lt;/div&gt;

&lt;p&gt;절대적으로 좋은 결과를 내게하는 방법은 없다. &lt;em&gt;Alpha Distribution&lt;/em&gt; 역시 단점을 가지고 있다. 미리 처리를 하기 때문에 이미지가 고정되어 타일링처럼 보일 수가 있다. 또한 확대시 아무것도 처리하지 않고, &lt;em&gt;Bilinear Filtering&lt;/em&gt; 만 걸은 것보다 안좋은 결과를 보여줄 수도 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/ad_cons.png&quot; alt=&quot;Cemyuksel : Alpha Distribution&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://www.cemyuksel.com/research/alphadistribution/&quot;&gt;Cemyuksel : Alpha Distribution&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;또 &lt;em&gt;Alpha Threshold&lt;/em&gt; 가 고정되어 있다고 가정하기 때문에 값이 바뀌면 다시 계산해야한다. 직접 구현해서 붙이는 경우에는 계산하는 코드를 넣어주어야 하는데, 만약 &lt;em&gt;Texture Compression&lt;/em&gt; 이 적용되어 있으면 굉장히 귀찮을 것이다. 거기에 상용엔진에 &lt;em&gt;Intergration&lt;/em&gt; 할려면 더욱더 심할것이다.&lt;/p&gt;

&lt;p&gt;그에 비해 &lt;em&gt;Hashed Alpha Testing&lt;/em&gt; 은 구현하기엔 쉬운편이다. 코드는 &lt;em&gt;Shader&lt;/em&gt; 에 붙여넣기만 하면 된다. 하지만 약간의 퍼포먼스를 잡아먹고, 뭉개진 가루처럼 보이는 현상이 존재하기 때문에 무조건 좋다고하기에는 무리가 있다.&lt;/p&gt;

&lt;p&gt;조금더 시간을 가지고 지켜봐야 될것 같다는 생각이 든다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://medium.com/@bgolus/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f&quot;&gt;Anti-aliased Alpha Test: The Esoteric Alpha To Coverage&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.download.nvidia.com/assets/gameworks/downloads/regular/GDC17/RealTimeRenderingAdvances_HashedAlphaTesting_GDC2017_FINAL.pdf?pUIX8DXxfad7mL4zB3GOthX3r5IgGao9UWxYuYb3q9h10RXrQeYko-dEuJXJxt1hhsI9J_9KJDcCYGeWWksxlaHTrXSE825D_3izja7LUFOtzhaeBUqpn7qbwXaaGlLdbipjE3PeI3e2IMn45mQAA3OV2PD-kG2y9cecTaWE2uum2uwdHgyn0nhYiLOvlOsrUzewbK5REH7vAm3-lNWzxehw_5Tphg&quot;&gt;NVidia developer : Hashed Alpha Testing&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cwyman.org/papers/tvcg17_hashedAlphaExtended.pdf&quot;&gt;Cwyman.org : Hashed Alpha Test(Extended)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.cemyuksel.com/research/alphadistribution/&quot;&gt;Cemyuksel : Alpha Distribution&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/cemyuksel/cyCodeBase/blob/master/cyAlphaDistribution.h&quot;&gt;Github : cyAlphaDistribution.h&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="rendering" />
      
        <category term="alphatest" />
      
        <category term="shader" />
      

      

      
        <summary type="html">Shader 에서 샘플링하는 Texutre 에서 Alpha 값을 가지고 있어, Alpha 을 참조해서 실제 픽셀에 출력을 하는지 안하는지를 결정하는 것을 Alpha Test 라고 한다. 이런 Material 이나 Texture 를 Cutout 이라고 통칭하는 경우가 많다. 보통 게임에서의 Alpha Test 를 사용하는 것들은 나무, 풀 같은 식생들(Vegetation)이 있고, 중간에 구멍이 뚫린 펜스같은 것들도 존재한다. 자연을 배경으로하는 게임의 경우에는 식생들이 굉장히 많기 때문에 Alpha Test 를 사용하는 Shader 가 굉장히 많이 사용될 것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Ieee 754 Floaing Number</title>
      
      <link href="https://suhyeokkim.github.io/2018/05/18/IEEE-754-floaing-number" rel="alternate" type="text/html" title="Ieee 754 Floaing Number" />
      <published>2018-05-18T00:00:00+00:00</published>
      <updated>2018-05-18T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/05/18/IEEE-754-floaing-number</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/05/18/IEEE-754-floaing-number">&lt;p&gt;코딩을 하던 도중, 비트로 나타내어진 2 byte floating number(half-precision) 데이터를 일반적인 4byte floating number(single-precision) 으로 나타내야 할 일이 있었다. 그래서 귀찮아서 알아보지 않았던 컴퓨터의 소수를 표현하는 방법에 대해서 알아보았다. 이 글에서는 간략하게 어떤식으로 표현되는지에 대해서만 적어보기로 하겠다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;134.75
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이와 같은 소수가 있다. 이는 10진법으로 나타낸 소숫점으로, 2진법으로 나타내면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;134.75(demical) = 10000110.11(binary)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이를 소수부와 정수부를 나누면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;134(demical) = 10000110(binary)
0.75(demical) = 0.11(binary)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;정수부는 오른쪽부터 2^0 인 1부터 나란히 2^¹, 2^², 2^³, 2^⁴, … 2^ⁿ 로 구성되고(n은 자리의 끝), 소수부는 점 이하인 숫자부터 2^-1, 2^-2, … 2^-n 으로 구성된다. 0.75 는 2^-1 * 1 + 2^-2 * 2 가 되니 위의 경우처럼 굉장히 쉽게 표현이 가능하다. 하지만 다음과 같은 숫자는 어떻게 표현할까?&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;0.9999... = 0.1111...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이런식으로 표기는 가능할 것이다. 하지만 컴퓨터는 유한한 데이터만을 다루기 때문에 한계가 있다.&lt;/p&gt;

&lt;h2&gt;IEEE 754&lt;/h2&gt;

&lt;p&gt;컴퓨터에서는 숫자를 다루기 위해 여러가지 기준이 정해져 있다. 그 중에서도 소수를 나타내기 위한 기준은 IEEE 754 로 알려져 있다. 대부분의 언어에서 사용하는 &lt;em&gt;float&lt;/em&gt; 은 IEEE 754 single-precision 을 사용하여 계산된다.(&lt;em&gt;double&lt;/em&gt; 또한 마찬가지.) 데이터를 어떻게 저장하는지, 그 데이터의 표현방식은 어떻게 되는지에 대하여 간략하게 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/General_floating_point_ko.png&quot; alt=&quot;위키백과 : IEEE 754&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://ko.wikipedia.org/wiki/IEEE_754&quot;&gt;위키백과 : IEEE 754
&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;데이터의 저장 방식은 다음과 같다. 일반적으로 들어가는 부호를 위한 1bit, 그리고 우리가 아직 살펴보지 않은 지수(&lt;em&gt;exponent&lt;/em&gt;), 가수(&lt;em&gt;fraction&lt;/em&gt;) 부분으로 나뉘어져 있다. single-precision 을 예시로 보며 설명해보겠다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/single-precision_example.png&quot; alt=&quot;Wikipedia : Single-precision floating-point format&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/Single-precision_floating-point_format&quot;&gt;Wikipedia : Single-precision floating-point format&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;각각의 부분이 어떠한 숫자를 저장하는지만 알면 된다. &lt;em&gt;fraction&lt;/em&gt; 은 말 그대로 소숫점 아래의 숫자만 나타내는 부분이다. 가장 왼쪽의 비트(22번쨰 비트)는 2^-1 을 저장하고 오른쪽으로 2^-2, 2^-3 이런식의 숫자에 대한 정보를 기록한다. 이렇게 실질적인 소수부와 나머지인 &lt;em&gt;exponent&lt;/em&gt; 부분이 남아 있다. &lt;em&gt;exponent&lt;/em&gt; 는 &lt;em&gt;fraction&lt;/em&gt; 숫자를 얼마나 곱하는지 나타내는 숫자다. 아래의 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/single-precision_formatted.svg&quot; alt=&quot;Wikipedia : Single-precision floating-point format&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://en.wikipedia.org/wiki/Single-precision_floating-point_format&quot;&gt;Wikipedia : Single-precision floating-point format&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;여기서 이해가 안되는 부분이 많을 것이다. 첫번째로 맨 오른쪽의 식은 2의 지수가 음수가 되는 부분의 데이터를 나타내는 식인데, 전부다 더한 이후에 1을 더한다. 소수점을 표현하는 &lt;em&gt;fraction&lt;/em&gt; 이 0일 경우에 예외처리를 위해 1을 더한다. &lt;em&gt;fraction&lt;/em&gt; 이 단순히 소수를 표현한다면 왼쪽의 &lt;em&gt;exponent&lt;/em&gt; 부분은 &lt;em&gt;fraciton&lt;/em&gt; 에 값에 2진수의 자릿수 올림을 해주는 값이다. &lt;em&gt;exponent&lt;/em&gt; 는 가변적으로 2진수의 자릿수를 크게하거나 0에 가깝게 작게하여 가변적으로 숫자를 표현할 수 있게 해주는 매우 중요한 부분이다. 하지만 이 방식은 10^1023 + 10^-2353 * 1 같은 큰 숫자와 매우 작은 숫자의 표현은 불가능하다. 일반적으로는 작은 부분에 신경을 쓰지 않기 때문에 큰 부분을 정확하게 맞추고 작은 부분은 오차를 나게 한다. 그래서 가끔 2.999999 이런 숫자가 나오는 것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/IEEE_754&quot;&gt;위키피디아(한글) : IEEE 754&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Single-precision_floating-point_format&quot;&gt;Wikipedia : Single-precision floating-point format&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Half-precision_floating-point_format&quot;&gt;Wikipedia : Half-precision floating-point format&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="math" />
      
        <category term="floating_point" />
      

      

      
        <summary type="html">코딩을 하던 도중, 비트로 나타내어진 2 byte floating number(half-precision) 데이터를 일반적인 4byte floating number(single-precision) 으로 나타내야 할 일이 있었다. 그래서 귀찮아서 알아보지 않았던 컴퓨터의 소수를 표현하는 방법에 대해서 알아보았다. 이 글에서는 간략하게 어떤식으로 표현되는지에 대해서만 적어보기로 하겠다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Anisotropic Filtering</title>
      
      <link href="https://suhyeokkim.github.io/2018/05/13/anisotropic-filtering" rel="alternate" type="text/html" title="Anisotropic Filtering" />
      <published>2018-05-13T00:00:00+00:00</published>
      <updated>2018-05-13T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/05/13/anisotropic-filtering</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/05/13/anisotropic-filtering">&lt;p&gt;보통 사용되는 &lt;em&gt;Texture Fltering&lt;/em&gt; 들은 &lt;em&gt;Axis Align&lt;/em&gt; 된 방향을 기준으로 추가적인 샘플링을 하는 방법들이 대부분이다.(bilinear, bicubic, etc..) 하지만 특이한 것이 하나 있다. 바로 &lt;em&gt;Anisotropic Filtering&lt;/em&gt; 이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;em&gt;Anisotropic Filtering&lt;/em&gt; 은 원거리에 있는 물체들을 선명하게 보이게 하기위해서 쓰여지는 &lt;em&gt;Fiterling&lt;/em&gt; 으로, 말보다는 아래 그림을 보는게 훨씬 직관적으로 이해할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/aniso_pixel_to_texel.png&quot; alt=&quot;Real-time Rendering 3rd&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : Real-time Rendering 3rd&amp;lt;/a&amp;gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림과 같이 &lt;em&gt;Texture-Space&lt;/em&gt; 에서 픽셀안에 있는 텍스쳐를 여러번 샘플링하여 평균을 구하는 방식인듯하다. 그런데 아주 중요한 것이 하나 남아있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/img034.gif&quot; alt=&quot;Unsolved Problems and Opportunities for High-quality, High-perfornmance 3D Graphics on a PC Platform : Anisotropic Filtering&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://www.graphicshardware.org/previous/www_1998/presentations/kirk/sld030.htm&quot;&gt;Unsolved Problems and Opportunities for High-quality, High-perfornmance 3D Graphics on a PC Platform : Anisotropic Filtering&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위의 그림을 보면 알겠지만 &lt;em&gt;bilinear filtering&lt;/em&gt; 과 함께 쓸 경우 픽셀에 해당하는 만큼의 샘플링을 하는걸 알 수 있다. 이렇게 된다면 텍스쳐의 해상도가 클수록, &lt;em&gt;Anisotropic Level&lt;/em&gt; 이 높아지면 높아질수록 텍스쳐 샘플링 부하가 생긴다는 것을 알 수 있다. 거기에 &lt;em&gt;Trilinear filtering&lt;/em&gt; 까지 함께한다면 엄청난 시간을 잡아먹을 것으로 예상된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Anisotropic Filtering&lt;/em&gt; 을 처음 접했을 떄, 가장 이해가 가지 않았던 것은 결국 내부에서 샘플링을 해야할 텐데 어떤 방식으로 방향을 구할지 가장 이해가 안됬었다. 지금 다시 생각해보면, &lt;em&gt;ddx&lt;/em&gt; 키워드를 &lt;em&gt;uv&lt;/em&gt; 좌표에 쓰듯이 &lt;em&gt;Texutre-Space&lt;/em&gt; 의 차이 벡터를 쉽게 구할 수 있을 듯 하다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Real-Time Rendering 3rd&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.graphicshardware.org/previous/www_1998/presentations/kirk/sld030.htm&quot;&gt;Unsolved Problems and Opportunities for High-quality, High-perfornmance 3D Graphics on a PC Platform : Anisotropic Filtering&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="anisotropic" />
      
        <category term="filtering" />
      

      

      
        <summary type="html">보통 사용되는 Texture Fltering 들은 Axis Align 된 방향을 기준으로 추가적인 샘플링을 하는 방법들이 대부분이다.(bilinear, bicubic, etc..) 하지만 특이한 것이 하나 있다. 바로 Anisotropic Filtering 이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Recommandation Of Gpu Skinning In Github</title>
      
      <link href="https://suhyeokkim.github.io/2018/03/13/recommandation-of-gpu-skinning-in-github" rel="alternate" type="text/html" title="Recommandation Of Gpu Skinning In Github" />
      <published>2018-03-13T00:00:00+00:00</published>
      <updated>2018-03-13T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/03/13/recommandation-of-gpu-skinning-in-github</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/03/13/recommandation-of-gpu-skinning-in-github">&lt;p&gt;최근 급하게 어떤 프로젝트에 투입되서 작업을 하고 있다. 다른 회사와 같이 일을 하고 있는데, 다른 회사에서 해놓은 것들이 너무 느려서 최적화를 해야했다. 결국 일반적인 잔머리로는 도저히 해결할 수 없는 상황에 봉착했다. 1년 전의 필자였다면 포기하고 안된다고 했었겠지만 다행히 약간의 노하우를 통해 해결할 수 있었다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h2&gt;상황과 문제?&lt;/h2&gt;

&lt;p&gt;요즘 한국에서는 VR 게임/컨텐츠들이 굉장히 많이 개발되고 있다. 필자도 그 와중에 떨어진 프로젝트를 하나 받아진행하게 되었다. 개발은 주변 3D 환경을 다른 회사에서 해주고, 게임이 돌아가는 코어 시스템을 필자의 회사에서 작업하기로 되어 있었다. 게임에서의 코어 시스템은 개발을 하였으나 &lt;em&gt;Unity&lt;/em&gt; 에 의존적인 코딩은 거의 진행되지 않은 상태에서 한달전 프로젝트에 투입되었다.&lt;/p&gt;

&lt;p&gt;그렇게 하나하나 작업을 하면서 코어 시스템과 3D 환경을 결합하는 도중, 터무니 없는 경우를 만났다. 바로 &lt;strong&gt;SkinnedMeshRenderer&lt;/strong&gt; 와 &lt;em&gt;Animator&lt;/em&gt; 가 약 800 개 정도되는 상황에 부딫쳤다. 여기서는 두가지의 큰 부하가 있었다. 절대적인 &lt;em&gt;Vertex Skinning&lt;/em&gt; 부하와 &lt;em&gt;Animator&lt;/em&gt; 가 800개가 한꺼번에 계산되는 부하였다. &lt;em&gt;Vertex&lt;/em&gt; 숫자는 &lt;em&gt;LOD&lt;/em&gt; 베이커를 구해서 어떻게든 해결이 되었으나, 800개의 &lt;em&gt;Animator&lt;/em&gt; 부하는 우회방법이 없었다. 즉 이는 &lt;em&gt;Vertex Shader&lt;/em&gt; 나 &lt;em&gt;Compute Shader&lt;/em&gt; 안에서 &lt;em&gt;AnimationClip&lt;/em&gt; 의 정보들을 처리하는 정공법이 필요했다.&lt;/p&gt;

&lt;p&gt;하지만 기한도 얼마 남지않아 급한 와중에 저것들을 직접 코딩할 여유는 없었다. 게다가 처음 건드려보는 부분이라서 헤멜 코스트까지 합하면 굉장히 암울했다. 혹시 오픈소스가 있나 싶어서 생각을 해보았는데 예전에 &lt;em&gt;SkinRenderer&lt;/em&gt; 를 직접 구현하면서 찾아본 오픈소스 레포지토리가 하나 있었다.&lt;/p&gt;

&lt;h2&gt;Github : &lt;a href=&quot;https://github.com/chengkehan/GPUSkinning&quot;&gt;GPUSkinning&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;한 중국인이 개발한 스키닝 툴이다. 이는 두가지의 큰 기능을 담고있다. 하나는 &lt;em&gt;Vertex Shader&lt;/em&gt; 에서 &lt;em&gt;Skinning&lt;/em&gt; 처리를 해주는 기능과, 하나는 &lt;em&gt;AnimationClip&lt;/em&gt; 들을 직접 샘플링해 바이너리 파일로 저장해 GPU 메모리에 텍스쳐의 형태로 올려두어 사용하는 기능이 있다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Compute Shader&lt;/em&gt; 나 &lt;em&gt;Vetex Shader&lt;/em&gt; 를 사용해 &lt;em&gt;Skinning&lt;/em&gt; 을 구현하는 것은 크게 어려운 것은 아니다. &lt;em&gt;Deformation&lt;/em&gt;  하지만 제일 시간이 오래걸리는 부분은 &lt;em&gt;AnimationClip&lt;/em&gt; 을 가공하는 부분이 제일 오래 걸리는 부분 중 하나다. 해당 레포지토리에는 그 오래걸리는 부분을 만들어 놓았다. 사실 이 부분으로만으로 꽤 큰 가치가 있다. 부가적으로 원하는 &lt;em&gt;bone&lt;/em&gt; 의 위치와 회전값을 &lt;strong&gt;Transform&lt;/strong&gt; 으로 만들어 &lt;em&gt;Hierarchy&lt;/em&gt; 상에서 컨트롤이 가능하다.&lt;/p&gt;

&lt;p&gt;조금 불편한 점도 몇가지 있다. 한번에 여러개의 샘플링이 안되고, 에디터에서 필수적으로 지원해야할 멀티 에디팅이 안된다. 후자는 간단히 코드를 수정하면 되지만 전자는 샘플링 과정에서 플레이를 해야되기 때문에 직접 수정하기엔 조금 부담스럽다. &lt;em&gt;Vertex Shader&lt;/em&gt; 에 스키닝이 물려있기 때문에 &lt;em&gt;Skinning&lt;/em&gt; 을 수정하려면 &lt;em&gt;Shader&lt;/em&gt; 부분도 바꿔야하고, &lt;em&gt;LOD&lt;/em&gt; 기능도 어설프게 들어있어 조금 애매하다.&lt;/p&gt;

&lt;p&gt;더 기능을 생각하자면 IK 나 특정 본을 타겟으로 회전을 시키는 기능이 없다. 이는 &lt;em&gt;mecanim&lt;/em&gt; 에서 &lt;em&gt;Humanoid&lt;/em&gt; 를 타겟으로 지원하는 기능으로 이 기능까지 만들어 놓았으면 엄청 유용 했을것 같다. 다만 구현이 &lt;em&gt;Vertex Shader&lt;/em&gt; 에서 되어서 다른 기능을 끼워넣기는 조금 부담스러운 것으로 생각된다.&lt;/p&gt;

&lt;p&gt;굳이 단점을 생각하지 않아도 샘플링 코드와 구현만으로도 충분히 가치있는 레포지토리로 생각된다. &lt;em&gt;ComputeShader&lt;/em&gt; 를 사용해서 구현했으면 더 좋았을 것 같다는 생각이 문득든다.&lt;/p&gt;

&lt;p&gt;써보면서 이게 본격적으로 쓰려고 만들어진 코드는 아닌 것 같다는 생각이 들었다. 기본적인 캐싱도 안되있어서 약간의 삽질을 했었다.&lt;/p&gt;

&lt;p&gt;가장 큰 문제는 &lt;em&gt;AnimationClip&lt;/em&gt; 이 많으면 많을수록 에디터, 런타임 로드시에 엄청나게 로딩이 걸린다. 아마 ScriptableObject 에 Serialization 으로 저장한 정보들이 많아서 그런듯 하다. 이는 따로 텍스쳐든 뭐든 Unity 에서 직접 관리하는 리소스로 바꾸어야 겠다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/chengkehan/GPUSkinning&quot;&gt;Github : GPUSkining&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      
        <category term="gpu-skinning" />
      

      

      
        <summary type="html">최근 급하게 어떤 프로젝트에 투입되서 작업을 하고 있다. 다른 회사와 같이 일을 하고 있는데, 다른 회사에서 해놓은 것들이 너무 느려서 최적화를 해야했다. 결국 일반적인 잔머리로는 도저히 해결할 수 없는 상황에 봉착했다. 1년 전의 필자였다면 포기하고 안된다고 했었겠지만 다행히 약간의 노하우를 통해 해결할 수 있었다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Dualized Asset Management Of Unity</title>
      
      <link href="https://suhyeokkim.github.io/2018/03/06/dualized-asset-management-of-unity" rel="alternate" type="text/html" title="Dualized Asset Management Of Unity" />
      <published>2018-03-06T00:00:00+00:00</published>
      <updated>2018-03-06T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/03/06/dualized-asset-management-of-unity</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/03/06/dualized-asset-management-of-unity">&lt;p&gt;&lt;em&gt;Unity&lt;/em&gt; 에서는 모든 사용자의 작업물을 &lt;em&gt;Assets&lt;/em&gt; 폴더에 저장한다. 그리고 &lt;em&gt;Assets&lt;/em&gt; 폴더안의 파일의 변경이 발생할 시 안의 파일들을 재가공하여 다시 로드한다. 보통 파일의 변경은 &lt;em&gt;assetDatabaseX&lt;/em&gt; 바이너리 파일로 들어가게 되며, 스크립트, 바이너리의 변경은 다시 컴파일을 함으로써 현재 변경사항을 프로젝트에 적용시킨다.&lt;/p&gt;

&lt;p&gt;이러한 시스템을 위해 &lt;em&gt;Unity&lt;/em&gt; 에서는 모든 파일, 디렉토리에 &lt;em&gt;meta&lt;/em&gt; 파일을 생성한다. 파일별 &lt;em&gt;meta&lt;/em&gt; 파일에는 해당 파일의 순수한 정보가 아닌 메타 정보가 들어간다. 중요한 정보는 두개로 나뉜다.&lt;/p&gt;

&lt;p&gt;하나는 &lt;em&gt;Unity&lt;/em&gt; 프로젝트상에서 파일을 처음 감지했을 때, 파일의 &lt;em&gt;GUID&lt;/em&gt; 를 생성한다. &lt;em&gt;GUID&lt;/em&gt; 란 고유의 16진수 32글자로 이루어지는 총 512비트로 이루어지는 &lt;em&gt;ID&lt;/em&gt; 로써 자동으로 생성되는 알고리즘을 가지고 있으며 겹칠 염려는 거의 없는 &lt;em&gt;ID&lt;/em&gt; 알고리즘이다. 그래서 생성된 &lt;em&gt;GUID&lt;/em&gt; 는 다른 곳에서 해당 파일을 참조할떄 쓰인다. 즉 파일이 삭제되서 같은 것으로 다시 생성한다고 해도 &lt;em&gt;GUID&lt;/em&gt; 가 랜덤으로 결정되기 때문에 다시 연결을 해주어야 한다. 이는 &lt;em&gt;Unity&lt;/em&gt; 내부에서 파일 링크를 &lt;em&gt;GUID&lt;/em&gt; 로 한다는 추측을 할 수 있게 해준다. 또한 &lt;em&gt;Edit -&amp;gt; Project Setting -&amp;gt; Editor&lt;/em&gt; 에서 &lt;em&gt;Asset Serialization&lt;/em&gt; 모드가 &lt;em&gt;Force Text&lt;/em&gt; 로 되어있을 시에는 &lt;em&gt;meta&lt;/em&gt; 파일들을 직접 텍스트 에디터로 확인이 가능하다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;fileFormatVersion: 2
guid: 5d44a238286f6904198ab78e914c229d
MonoImporter:
  serializedVersion: 2
  defaultReferences: []
  executionOrder: 0
  icon: {instanceID: 0}
  userData:
  assetBundleName:
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;어떤 스크립트에 딸린 &lt;em&gt;meta&lt;/em&gt; 파일의 내용이다. 두번째 줄에 생성된 &lt;em&gt;guid&lt;/em&gt; 가 존재한다. 이는 &lt;em&gt;Library/metadata&lt;/em&gt; 디렉토리에 쓰여진 이름들과 매칭된다.&lt;/p&gt;

&lt;p&gt;두번째는 바로 해당 파일의 &lt;em&gt;Importer&lt;/em&gt; 정보가 들어있다. 위의 &lt;em&gt;meta&lt;/em&gt; 파일은 스크립트이기 때문에 3번째 줄에 &lt;em&gt;MonoImporter&lt;/em&gt; 라고 쓰여져 있으며, 파일의 성질에 따라서 &lt;em&gt;built-in importer&lt;/em&gt; 가 달라진다. 바이너리 파일들은 &lt;em&gt;NativeImporter&lt;/em&gt;, 텍스쳐 파일들은 &lt;em&gt;TextureImporter&lt;/em&gt;, 3D 모델 파일들은 &lt;em&gt;ModelImporter&lt;/em&gt; 로 자동으로 매칭된다.&lt;/p&gt;

&lt;p&gt;이러한 &lt;em&gt;Importer&lt;/em&gt; 정보들은 보통 해당 &lt;em&gt;Asset&lt;/em&gt; 의 옵션을 세팅할 떄 쓰인다. 또한 &lt;em&gt;2017&lt;/em&gt; 버젼에서는 파일의 확장자를 사용자가 직접 지정해 &lt;em&gt;Importer&lt;/em&gt; 를 사용할 수도 있게 해두었다.(&lt;a href=&quot;/2018/01/11/unity-scripted-importer&quot;&gt;링크&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;즉 &lt;em&gt;Unity&lt;/em&gt; 에서는 새로운 파일을 감지했을 때, &lt;em&gt;GUID&lt;/em&gt; 를 생성하고 파일의 확장자에 따라 &lt;em&gt;Importer&lt;/em&gt; 정보를 갱신한 후, 정보를 &lt;em&gt;Library/metadata&lt;/em&gt; 에 갱신하는 것으로 볼 수 있다. &lt;em&gt;Library/metadata&lt;/em&gt; 에서는 &lt;em&gt;GUID&lt;/em&gt; 로 된 파일과 (해당 &lt;em&gt;GUID&lt;/em&gt;).info 로 파일이 구성되어 있다. 각각의 파일은 파일의 유형별로 다른 것으로 보인다.&lt;/p&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      

      

      
        <summary type="html">Unity 에서는 모든 사용자의 작업물을 Assets 폴더에 저장한다. 그리고 Assets 폴더안의 파일의 변경이 발생할 시 안의 파일들을 재가공하여 다시 로드한다. 보통 파일의 변경은 assetDatabaseX 바이너리 파일로 들어가게 되며, 스크립트, 바이너리의 변경은 다시 컴파일을 함으로써 현재 변경사항을 프로젝트에 적용시킨다. 이러한 시스템을 위해 Unity 에서는 모든 파일, 디렉토리에 meta 파일을 생성한다. 파일별 meta 파일에는 해당 파일의 순수한 정보가 아닌 메타 정보가 들어간다. 중요한 정보는 두개로 나뉜다. 하나는 Unity 프로젝트상에서 파일을 처음 감지했을 때, 파일의 GUID 를 생성한다. GUID 란 고유의 16진수 32글자로 이루어지는 총 512비트로 이루어지는 ID 로써 자동으로 생성되는 알고리즘을 가지고 있으며 겹칠 염려는 거의 없는 ID 알고리즘이다. 그래서 생성된 GUID 는 다른 곳에서 해당 파일을 참조할떄 쓰인다. 즉 파일이 삭제되서 같은 것으로 다시 생성한다고 해도 GUID 가 랜덤으로 결정되기 때문에 다시 연결을 해주어야 한다. 이는 Unity 내부에서 파일 링크를 GUID 로 한다는 추측을 할 수 있게 해준다. 또한 Edit -&amp;gt; Project Setting -&amp;gt; Editor 에서 Asset Serialization 모드가 Force Text 로 되어있을 시에는 meta 파일들을 직접 텍스트 에디터로 확인이 가능하다. fileFormatVersion: 2 guid: 5d44a238286f6904198ab78e914c229d MonoImporter: serializedVersion: 2 defaultReferences: [] executionOrder: 0 icon: {instanceID: 0} userData: assetBundleName: 어떤 스크립트에 딸린 meta 파일의 내용이다. 두번째 줄에 생성된 guid 가 존재한다. 이는 Library/metadata 디렉토리에 쓰여진 이름들과 매칭된다. 두번째는 바로 해당 파일의 Importer 정보가 들어있다. 위의 meta 파일은 스크립트이기 때문에 3번째 줄에 MonoImporter 라고 쓰여져 있으며, 파일의 성질에 따라서 built-in importer 가 달라진다. 바이너리 파일들은 NativeImporter, 텍스쳐 파일들은 TextureImporter, 3D 모델 파일들은 ModelImporter 로 자동으로 매칭된다. 이러한 Importer 정보들은 보통 해당 Asset 의 옵션을 세팅할 떄 쓰인다. 또한 2017 버젼에서는 파일의 확장자를 사용자가 직접 지정해 Importer 를 사용할 수도 있게 해두었다.(링크) 즉 Unity 에서는 새로운 파일을 감지했을 때, GUID 를 생성하고 파일의 확장자에 따라 Importer 정보를 갱신한 후, 정보를 Library/metadata 에 갱신하는 것으로 볼 수 있다. Library/metadata 에서는 GUID 로 된 파일과 (해당 GUID).info 로 파일이 구성되어 있다. 각각의 파일은 파일의 유형별로 다른 것으로 보인다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">What Is Ddx And Ddy</title>
      
      <link href="https://suhyeokkim.github.io/2018/03/04/what-is-ddx-and-ddy" rel="alternate" type="text/html" title="What Is Ddx And Ddy" />
      <published>2018-03-04T00:00:00+00:00</published>
      <updated>2018-03-04T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/03/04/what-is-ddx-and-ddy</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/03/04/what-is-ddx-and-ddy">&lt;p&gt;&lt;em&gt;HLSL&lt;/em&gt; 에는 &lt;em&gt;ddx&lt;/em&gt; 와 &lt;em&gt;ddy&lt;/em&gt; &lt;em&gt;intrisic&lt;/em&gt; 이 &lt;em&gt;Shader Model 2.0&lt;/em&gt; 부터 존재했다. 필자는 이를 이해하기 위해 자료를 찾아보았지만 쉽게 이해되는 것들은 거의 없었다. 이해한 것을 정리하기 위해 이글을 쓴다.&lt;/p&gt;

&lt;p&gt;예전부터 &lt;em&gt;Pixel Shader&lt;/em&gt; 를 처리할 때 픽셀 단위로 하나하나 처리하는게 아닌 적어도 2x2 개의 픽셀들을 한꺼번에 처리했다고 한다. 그래서 이러한 아키텍쳐를 이용한 키워드가 &lt;em&gt;ddx&lt;/em&gt; 와 &lt;em&gt;ddy&lt;/em&gt; 다. 기본적으로 쉐이더는 병렬로 처리되기 때문에, 4개의 &lt;em&gt;Pixel Shader&lt;/em&gt; 가 한꺼번에 실행되는 것으로 생각할 수 있다. 아래 코드를 보면서 생각해보자.&lt;/p&gt;

&lt;div class=&quot;language-hlsl highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;    &lt;span class=&quot;kt&quot;&gt;half3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dpdx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ddx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;kt&quot;&gt;half3&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dpdy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;ddy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;4개의 픽셀 쉐이더가 첫번째 라인을 실행할 때 ddx 는 들어온 파라미터의 x축, 가로의 픽셀들의 파라미터의 차이를 구해 반환한다. 이는 &lt;em&gt;δ/δx&lt;/em&gt; 의 의미와 같다. 즉 x 를 기준으로 편미분을 한것이라고 한다. 마찬가지로 ddy 는 y축을 기준으로 차이를 계산해 반환하는 키워드로 생각하면 된다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Shader Model 5.0&lt;/em&gt; 부터는 &lt;em&gt;ddx_coarse/ddy_coarse&lt;/em&gt; 와 &lt;em&gt;ddx_fine/ddy_fine&lt;/em&gt; 으로 키워드가 나뉜다. 기존의 &lt;em&gt;ddx/ddy&lt;/em&gt; 는 &lt;em&gt;ddx_coarse/ddy_coarse&lt;/em&gt; 와 같다고 한다. &lt;em&gt;fine&lt;/em&gt; 과 &lt;em&gt;coarse&lt;/em&gt; 의 차이는 간단하다. 4개의 픽셀을 기준으로 각각의 차이를 전부 구하는게 &lt;em&gt;fine&lt;/em&gt;, 한쪽의 차이만 구하는게 &lt;em&gt;coarse&lt;/em&gt; 라고 한다. 자세한 것은 아래 참조에서 보는 것을 추천한다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/bb509588.aspx&quot;&gt;MSDN HLSL Intrisic : ddx&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://gamedev.stackexchange.com/questions/62648/what-does-ddx-hlsl-actually-do&quot;&gt;gamedev.stackexchange.net : What does ddx (hlsl) actually do?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://fgiesen.wordpress.com/2011/07/10/a-trip-through-the-graphics-pipeline-2011-part-8/#comment-1990&quot;&gt;The ryg blog : A trip through the Graphics Pipeline 2011, part 8&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/hh446950.aspx&quot;&gt;MSDN Shader Model Assembly 5.0 : deriv_rtx_fine&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://msdn.microsoft.com/en-us/library/windows/desktop/hh446948.aspx&quot;&gt;MSDN Shader Model Assembly 5.0 : deriv_rtx_coarse &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="shader" />
      
        <category term="hlsl" />
      

      

      
        <summary type="html">HLSL 에는 ddx 와 ddy intrisic 이 Shader Model 2.0 부터 존재했다. 필자는 이를 이해하기 위해 자료를 찾아보았지만 쉽게 이해되는 것들은 거의 없었다. 이해한 것을 정리하기 위해 이글을 쓴다. 예전부터 Pixel Shader 를 처리할 때 픽셀 단위로 하나하나 처리하는게 아닌 적어도 2x2 개의 픽셀들을 한꺼번에 처리했다고 한다. 그래서 이러한 아키텍쳐를 이용한 키워드가 ddx 와 ddy 다. 기본적으로 쉐이더는 병렬로 처리되기 때문에, 4개의 Pixel Shader 가 한꺼번에 실행되는 것으로 생각할 수 있다. 아래 코드를 보면서 생각해보자. half3 dpdx = ddx(position); half3 dpdy = ddy(position); 4개의 픽셀 쉐이더가 첫번째 라인을 실행할 때 ddx 는 들어온 파라미터의 x축, 가로의 픽셀들의 파라미터의 차이를 구해 반환한다. 이는 δ/δx 의 의미와 같다. 즉 x 를 기준으로 편미분을 한것이라고 한다. 마찬가지로 ddy 는 y축을 기준으로 차이를 계산해 반환하는 키워드로 생각하면 된다. Shader Model 5.0 부터는 ddx_coarse/ddy_coarse 와 ddx_fine/ddy_fine 으로 키워드가 나뉜다. 기존의 ddx/ddy 는 ddx_coarse/ddy_coarse 와 같다고 한다. fine 과 coarse 의 차이는 간단하다. 4개의 픽셀을 기준으로 각각의 차이를 전부 구하는게 fine, 한쪽의 차이만 구하는게 coarse 라고 한다. 자세한 것은 아래 참조에서 보는 것을 추천한다. 참조 MSDN HLSL Intrisic : ddx gamedev.stackexchange.net : What does ddx (hlsl) actually do? The ryg blog : A trip through the Graphics Pipeline 2011, part 8 MSDN Shader Model Assembly 5.0 : deriv_rtx_fine MSDN Shader Model Assembly 5.0 : deriv_rtx_coarse</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Gpu Branching And Divergence</title>
      
      <link href="https://suhyeokkim.github.io/2018/02/19/gpu-branching-and-divergence" rel="alternate" type="text/html" title="Gpu Branching And Divergence" />
      <published>2018-02-19T00:00:00+00:00</published>
      <updated>2018-02-19T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/02/19/gpu-branching-and-divergence</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/02/19/gpu-branching-and-divergence">&lt;p&gt;요즘은 꽤나 많은 것들을 GPU 로 처리할 수 있다. GPGPU 기술이 나온지 10년이 넘어가는 이 시점에서 꽤나 많은 것들이 GPU 로 처리되고 있다. 그 중에서도 GPGPU 를 다뤄볼 사람이라면 필수적인 상식하나가 있다. 아래 그림을 보자.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/prior_simt.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://composter.com.ua/documents/Volta-Architecture-Whitepaper.pdf&quot;&gt;NVidia : GV100 Whitepaper&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;위 그림은 분기가 나뉘어져 있는 코드를 여러개의 스레드가 실행하는 것을 보여준다. 즉 GPU 에서의 코드 실행 모습이다. 왼쪽은 스레드의 번호로 나뉘는 간단한 분기 코드다. 이는 CPU 에서는 크게 문제가 없다. 하지만 분기가 있던 말던 모든 명령어들을(분기안의 코드들) 전부 실행시키는 것이다. 오른쪽의 그림에서 설명하는 것은 이를 실행하는 쓰레드의 모습을 나타낸다. 딱 봐도 이 그림은 처리가 비효율적일 것처럼 보인다.&lt;/p&gt;

&lt;p&gt;CPU 는 한 쓰레드에서 하나의 &lt;em&gt;Program Conter&lt;/em&gt; 를 가지기 때문에 분기가 나오면 조건에 맞게 단순히 포인터를 증가시키기만 한다. 하지만 &lt;em&gt;SIMT&lt;/em&gt;(&lt;em&gt;Single Instruction Multiple Threads&lt;/em&gt;) 의 구조를 가진 GPU 에서의 분기는 조금 다르다. 여태까지는 여러개의 쓰레드를 가진 그룹 하나당 &lt;em&gt;Program Counter&lt;/em&gt; 를 가지는게 일반적이였다. 그래서 위와같이 동시에 활성화된 쓰레드들 끼리만 실행하게 되는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Volta&lt;/em&gt; 아키텍쳐에서는 이를 개선시켜 한 &lt;em&gt;Thread&lt;/em&gt; 당 하나의 &lt;em&gt;Program Counter&lt;/em&gt; 와 &lt;em&gt;Call-Stack&lt;/em&gt; 을 두므로써 각 &lt;em&gt;Thread&lt;/em&gt; 를 독립적으로 실행시키게 해준다고 한다. &lt;em&gt;SIMT&lt;/em&gt; 의 &lt;em&gt;Concurrency&lt;/em&gt; 를 고려하여 전부 한꺼번에 실행시키지는 못하지만 각각의 &lt;em&gt;Thread&lt;/em&gt; 를 같은 명령별로 그룹지어 실행시키거나, 한번에 실행시키는게 아니라 각 그룹의 실행을 클럭이나 시분할로 쪼개어 실행하는 것들을 지원한다고 한다. 아래 그림을 보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/interleaved_execution.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://composter.com.ua/documents/Volta-Architecture-Whitepaper.pdf&quot;&gt;NVidia : GV100 Whitepaper&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;하지만 이는 그림에서 나와 있다시피 그다지 효율적인 실행은 아니다. 결국 아직은 분기의 사용은 최소화해야될 것으로 보인다. 다만 이 기능들은 &lt;em&gt;Graphic Processing Unit&lt;/em&gt; 들이 &lt;em&gt;Accelerator&lt;/em&gt; 로 바뀌는 하나의 과정으로 볼 수 있을듯 하다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://composter.com.ua/documents/Volta-Architecture-Whitepaper.pdf&quot;&gt;NVidia : GV100 Whitepaper&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="gpu" />
      
        <category term="gpgpu" />
      

      

      
        <summary type="html">요즘은 꽤나 많은 것들을 GPU 로 처리할 수 있다. GPGPU 기술이 나온지 10년이 넘어가는 이 시점에서 꽤나 많은 것들이 GPU 로 처리되고 있다. 그 중에서도 GPGPU 를 다뤄볼 사람이라면 필수적인 상식하나가 있다. 아래 그림을 보자.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Frustum Traced Shadow With Irrelgular Z Buffer 2</title>
      
      <link href="https://suhyeokkim.github.io/2018/01/14/frustum-traced-shadow-with-irrelgular-z-buffer-2" rel="alternate" type="text/html" title="Frustum Traced Shadow With Irrelgular Z Buffer 2" />
      <published>2018-01-14T00:00:00+00:00</published>
      <updated>2018-01-14T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/01/14/frustum-traced-shadow-with-irrelgular-z-buffer-2</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/01/14/frustum-traced-shadow-with-irrelgular-z-buffer-2">&lt;p&gt;&lt;a href=&quot;/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-1&quot;&gt;frustum Traced Shadow with Irregular Z-Buffer 1&lt;/a&gt; 에서 포괄적인 전체 시스템과 복잡도에 대하여 알아보았다. 이번 글에서는 시스템 구현에 관한 디테일한 사항들을 알아볼 것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;첫번째로는 &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 와 &lt;em&gt;Sampling Rate&lt;/em&gt; 간의 최적화다. 논문의 저자는 기본적으로 &lt;em&gt;32spp&lt;/em&gt; (&lt;em&gt;sampling per pixel&lt;/em&gt;) 를 제안했다. 정확히 짚자면, &lt;em&gt;Light-Space&lt;/em&gt; 에서 &lt;em&gt;Occluder Geometry&lt;/em&gt; 를 &lt;em&gt;Conservative Rasterization&lt;/em&gt; 을 하면 &lt;em&gt;Visibility Test&lt;/em&gt; 를 계산하는 것이, 한번 &lt;em&gt;Visibility Test&lt;/em&gt; 를 할때 32번을 하는게 가장 신경쓰이는 부분이다. 이의 결과를 저장하기 위해 두가지 방법이 있다고 한다. 하나는 &lt;em&gt;μQuad&lt;/em&gt; 를 &lt;em&gt;Light-Space&lt;/em&gt; 에서 &lt;em&gt;IZB&lt;/em&gt; 를 만들 떄 &lt;em&gt;Rasterize&lt;/em&gt; 하는 것, 다른 방법은 32 번의 &lt;em&gt;Visibility Test&lt;/em&gt; 샘플링 결과를 &lt;em&gt;IZB&lt;/em&gt; 에 저장하는 것이다. 전자는 비용이 크기 때문에 안쓰고, 후자를 선택했다고 한다. 이를 &lt;em&gt;Sample-based insertion&lt;/em&gt; 이라고 명명했다. 그래서 이 방식으로 &lt;em&gt;Prototype&lt;/em&gt; 을 만들어 보니, &lt;em&gt;IZB&lt;/em&gt; 의 중복을 위한 최적화를 했음에도 불구하고 한 픽셀당 8개 이상의 &lt;em&gt;IZB Node&lt;/em&gt; 가 생성되었다고 한다.&lt;/p&gt;

&lt;p&gt;그래서 고안해낸 간단한 근사(&lt;em&gt;approximate&lt;/em&gt;)하는 방법을 언급한다. &lt;em&gt;μQuad&lt;/em&gt; 의 &lt;em&gt;Normal&lt;/em&gt; 벡터와 &lt;em&gt;View Ray&lt;/em&gt;(&lt;em&gt;Eye Direction&lt;/em&gt;) 벡터의 내적 값이 0에 가까워질수록(90도에 가까워질수록) &lt;em&gt;μQuad&lt;/em&gt; 를 늘리는 것이다. 아래 그림의 왼쪽 그림을 보면 쉽게 이해할 수 있다.
그래서 고안해낸 간단한 근사(&lt;em&gt;approximate&lt;/em&gt;)하는 방법을 언급한다. &lt;em&gt;μQuad&lt;/em&gt; 의 &lt;em&gt;Normal&lt;/em&gt; 벡터와 &lt;em&gt;View Ray&lt;/em&gt;(&lt;em&gt;Eye Direction&lt;/em&gt;) 벡터의 내적 값이 0에 가까워질수록(90도에 가까워질수록) &lt;em&gt;μQuad&lt;/em&gt; 를 늘리는 것이다. 아래 그림의 왼쪽 그림을 보면 쉽게 이해할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_microquad_elongate.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;보다 정확하게 계산 방법을 설명하자면, &lt;em&gt;μQuad&lt;/em&gt; 의 넓이는 표면의 방향과 상관없이 상수로 정해주고 &lt;em&gt;View Ray&lt;/em&gt; 의 앞뒤 방향으로 &lt;em&gt;μQuad&lt;/em&gt; 의 길이가 늘어나고, 그 방향을 따라서 1줄로 샘플링을 한다. 1차원이라고도 할 수 있겠다. 1 ~ 8 개의 샘플링을 해준다고한다. 위 그림의 오른쪽 그림을 보면 쉽게 이해할 수 있다.&lt;/p&gt;

&lt;p&gt;다만 이는 단지 &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 를 &lt;em&gt;Approximate&lt;/em&gt;(근사) 하는 것이기 때문에 오차가 생길 수 있다. &lt;em&gt;μQuad&lt;/em&gt; 가 커질수록 &lt;em&gt;IZB Node&lt;/em&gt; 를 넣는 것을 놓치고, &lt;em&gt;Light Leak&lt;/em&gt; 을 발생시킬 수 있다. 보통 가리는 물체가 작거나, 멀리있는 경우에 해당된다. &lt;em&gt;Light Leak&lt;/em&gt; 을 없에는 방법은 몇가지가 존재하는데, 가장 쉬운 방법은 &lt;em&gt;IZB&lt;/em&gt; 의 기본적인 모토인 1:1 샘플링을 맞춰주는 것이다. 하지만 이는 정확히 해주기에 어려운 경우가 있다고 한다. 그래서 다른 방법을 제시한다. &lt;em&gt;Conservative Rasterization&lt;/em&gt; 은 보통 결과에서 0.5 픽셀을 늘려준다. 하지만 1 픽셀 팽창(&lt;em&gt;dilation&lt;/em&gt;)을 해주는 &lt;em&gt;Conservative Rasterization&lt;/em&gt; 을 사용하면 &lt;em&gt;Light Leak&lt;/em&gt; 을 막을 수 있다. 원래 &lt;em&gt;μQuad&lt;/em&gt; 2차원으로 샘플링을 했었으나 기준을 1차원으로 줄이면서 각각의 폴리곤의 넓이을 늘리는 방식으로 보완한 것이라고 생각하면 되겠다. 아래 그림에 적용을 한 사례가 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_approx-insert_vs_over-conserv-raster.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이전 글에서 언급한 복잡도는 O(&lt;em&gt;La&lt;/em&gt; * &lt;em&gt;F&lt;/em&gt;) 이다. 우선 평균적인 리스트의 길이는 줄어든다고 한다. 샘플링을 하는 횟수가 최소 1/4 정도 줄었기 때문이다.(8 / 32) 그리고 더 넓은 &lt;em&gt;Conservative Rasterization&lt;/em&gt; 의 결과로 &lt;em&gt;Fragment&lt;/em&gt; 의 갯수는 최대 60% 증가했다고 한다. 이는 성능상 엄청난 이득을 가져온다.&lt;/p&gt;

&lt;p&gt;하지만 이 방법은 &lt;em&gt;Approximate&lt;/em&gt; 하는 방법이란 것을 알아야 한다. 아주 극성맞은 경우와 안좋은 파라미터 설정에는 &lt;em&gt;Light Leak&lt;/em&gt; 이 발생할 수 있다고 한다. 아래 그림에서 그 경우를 볼 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_lightleaks.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽의 그림은 정상적으로 그림자가 보일 때, 두번째는 정말 안좋은 경우들이 겹친 &lt;em&gt;Light Leak&lt;/em&gt; 이 발생하는 경우, 세번째 경우는 세팅값을 맞춰주어 &lt;em&gt;Light Leak&lt;/em&gt; 을 없엔 장면이다. 하지만 결과를 잘 모르는 경우에는 이 결과들이 맞는지 아닌지 쉽게 구별할 수 있는 정도는 아니다. 즉 아주 정확한 결과를 원하는게 아니라면 그냥 써도 된다는 말이다.&lt;/p&gt;

&lt;p&gt;두번째는 데이터 구조와 메모리 레이아웃 최적화다. 가장 맨처음 이를 구현할 때는 링크드 리스트의 2D 그리드의 형태로 만들었다고 한다. 각각의 리스트의 노드는 다음노드를 가리키는 포인터와 &lt;em&gt;G-Buffer&lt;/em&gt; 를 참조하기 위한 명시적인&lt;sup id=&quot;fnref:C2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C2&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 인덱스로 구성되었다고 한다. 하지만 이 구조는 &lt;em&gt;GPU&lt;/em&gt; 에서의 두가지 쓰레드 동기화를 필요로 했다. 하나는 &lt;em&gt;Global Node Pool&lt;/em&gt; 에서 비어있는 노드를 찾기위한 &lt;em&gt;Global&lt;/em&gt; 동기화&lt;sup id=&quot;fnref:C1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C1&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, 나머지는 헤드 포인터(&lt;em&gt;Light-Space Data&lt;/em&gt;)를 업데이트하기 위한 &lt;em&gt;Per-Texel&lt;/em&gt; 동기화&lt;sup id=&quot;fnref:C1:1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C1&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;였다. 동기화를 많이 걸면 걸수록 성능상으로는 그다지 좋지않다. 그렇기 때문에 데이터 구조를 바꾸었다고 한다.&lt;/p&gt;

&lt;p&gt;여러 시도 끝에 가장 성공적인 결과는 리스트의 각 노드의 크기를 줄이는 것이였다. 이를 위한 준비는 노드를 저장하기 위한 &lt;em&gt;Screen-Space Grid&lt;/em&gt; 버퍼를 미리 할당한다. 그리고 각 노드들은 자신을 기준으로한 다음 노드의 오프셋을 저장한다. 이는 &lt;em&gt;Linked-List&lt;/em&gt; 의 기준으로 보자면 &lt;em&gt;Next Pointer&lt;/em&gt; 가 된다. 이를 논문에서는 간접적인(&lt;em&gt;Implcit&lt;/em&gt;) &lt;em&gt;G-Buffer&lt;/em&gt; 인덱스라고 부른다. 이렇게 계속 픽셀의 노드 정보를 참조하면서 픽셀의 위치를 &lt;em&gt;Linked-List&lt;/em&gt; 의 형태로 나타낼 수 있는 것이다. 아래 중간의 그림의 노란색 화살표는 이를 간단하게 나타냈다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_SimpleLayout.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이는 &lt;em&gt;IZB Node&lt;/em&gt; 의 크기도 반으로 줄이고, 위에서 언급한 두가지의 동기화 중 &lt;em&gt;Global&lt;/em&gt; 동기화를 안할 수 있게 되었다. 32spp 그림자를 보여주기 위해서는 적어도 픽셀별로 8개의 노드가 필요했다. 이렇게 반으로 노드의 크기를 줄임으로써 큰 퍼포먼스 향상을 얻게 되었다.&lt;/p&gt;

&lt;p&gt;세번째는 헤드 포인터를 가지고 있는 &lt;em&gt;Light-Space Buffer&lt;/em&gt; 의 해상도다. 일반적인 &lt;em&gt;Shadow Mapping&lt;/em&gt; 기법의 &lt;em&gt;Shadow Map&lt;/em&gt; 의 해상도는 보여지는 정도를 결정하지만, 여기서의 해상도는 퍼포먼스를 결정한다.(&lt;em&gt;La&lt;/em&gt;) 1920 x 1080 을 기준으로 추천하는 해상도는 1400 ~ 2500 사이라고 한다.&lt;/p&gt;

&lt;p&gt;네번째로는 기존의 &lt;em&gt;Shadow Mapping&lt;/em&gt; 의 잘 알려진 기법인 &lt;em&gt;Cascaded Shadow Mapping&lt;/em&gt;&lt;sup id=&quot;fnref:P1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:P1&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; 을 이 기법에 적용시키는 것이다. 이 기법의 원리는 &lt;em&gt;View frustum&lt;/em&gt; 을 원하는 갯수대로 쪼갠 후, 쪼개진 &lt;em&gt;frustum&lt;/em&gt; 안의 오브젝트들의 &lt;em&gt;Shadow&lt;/em&gt; 를 계산한다. 논문에서 쪼개는 방법은 &lt;em&gt;Sample Distribution Shadow Map&lt;/em&gt; 과 &lt;em&gt;Logarithm Partitioning&lt;/em&gt; 을 언급했다. 여기서는 쪼개진 &lt;em&gt;frustum&lt;/em&gt; 마다 전부 &lt;em&gt;IZB&lt;/em&gt; 를 생성한다. 이때 각각의 쪼개진 &lt;em&gt;frustum&lt;/em&gt; 의 끝부분이 잘 맞도록 신경써야줘야 한다고 언급했다. 논문의 저자는 구현할때 &lt;em&gt;2D Texture Array&lt;/em&gt; 를 사용하여 &lt;em&gt;IZB&lt;/em&gt; 를 저장하고, 병렬로 각각의 &lt;em&gt;Detph Texture&lt;/em&gt; 마다 &lt;em&gt;Light-Space Culling Prepass&lt;/em&gt; 를 넣어줬다고 한다. 일반적으로 각각의 &lt;em&gt;Cascade&lt;/em&gt; 를 계산할때는 한개당 하나의 &lt;em&gt;Pass&lt;/em&gt; 를 사용하여 계산하는데, 여기서는 1 Pass 로 적절히 프리미티브를 나누어 성능 향상을 고려했다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Cascade&lt;/em&gt; 의 적용은 &lt;em&gt;Occluder Geometry&lt;/em&gt; 의 &lt;em&gt;Rasterize&lt;/em&gt; 퍼포먼스를 안고 가면서 &lt;em&gt;Thread Divergence&lt;/em&gt; 의 시간을 줄여준다. 이는 사용시 적절한 타협점을 찾아야 한다는 뜻으로, 보통은 두개의 &lt;em&gt;Cascade&lt;/em&gt; 를 사용하고, 복잡한 게임에서는 3개나 4개의 &lt;em&gt;Cascade&lt;/em&gt; 를 사용하여 상황에 따라 뜀뛰는 시간을 최소화 시킨다. 아래 그림은 &lt;em&gt;Cascade&lt;/em&gt; 의 효과를 증명해준다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_cascaded-izb.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;다섯번째로는 &lt;em&gt;N dot L Culling&lt;/em&gt; 이다. 일반적으로 &lt;em&gt;N dot L&lt;/em&gt; 의 값이 음수가 되는 경우에는 0으로 클램핑하여 사용한다. 이 말은 값이 음수나 0 인 경우에는 무조건 &lt;em&gt;Shadow&lt;/em&gt; 가 비춘다는 말이다. 이때는 &lt;em&gt;La&lt;/em&gt; : 평균적인 &lt;em&gt;IZB&lt;/em&gt; 리스트의 길이를 줄여 성능 향상을 해줄 수 있다고 한다. 보통은 10 ~ 15% 의 성능향상을 해준다고 한다.&lt;/p&gt;

&lt;p&gt;여섯번째로는 &lt;em&gt;Early-Z&lt;/em&gt; 의 개념을 응용한 &lt;em&gt;Early-Out&lt;/em&gt; 이다. &lt;em&gt;Visibility Test&lt;/em&gt; 에서 한 픽셀을 완전하게 그림자를 드리우는 경우, 다음 후속으로 같은 픽셀에 &lt;em&gt;Node&lt;/em&gt; 가 추가될 필요가 없다. 그러므로 완전히 그림자 처리가 되는 부분은 &lt;em&gt;Node&lt;/em&gt; 를 지워준다. 이때 &lt;em&gt;atomic&lt;/em&gt; 연산을 사용하지 않는데, 최악에 경우에는 &lt;em&gt;Visibility Test&lt;/em&gt; 를 다시할 수도 있다. &lt;em&gt;Early-Out&lt;/em&gt; 은 추가적인 시간과 메모리를 요구함에도 불구하고 10 ~ 15% 의 성능향상을 보인다.&lt;/p&gt;

&lt;p&gt;일곱번째로는 &lt;em&gt;Unchanged Mask&lt;/em&gt; 를 이용한 메모리 동기화다. &lt;em&gt;Visibility Test&lt;/em&gt; 는 메모리 대역폭, 처리량, 동기화로 인하여 병목이 일어난다. 픽셀 각각의 &lt;em&gt;Visibility Mask&lt;/em&gt; 를 사용해 동기화를 한다. 정확히 말하면 각각의 폴리곤들이 픽셀의 가시성을 테스트 할때 &lt;em&gt;Race Condition&lt;/em&gt; 을 피하기 위하여 동기화를 하여 &lt;em&gt;Visibility&lt;/em&gt; 를 기록한다. 그러므로 &lt;em&gt;Visibility Mask&lt;/em&gt; 는 반드시 폴리곤이 기존의 &lt;em&gt;Visibility&lt;/em&gt; 를 바꿀 때만 업데이트된다. 바뀌는지 비교를 하기위해 이전에 사용한 마스크를 써야하지만, 이는 최고 14% 의 성능 향상을 보여준다고 한다.&lt;/p&gt;

&lt;p&gt;마지막으로는 코드를 통한 &lt;em&gt;Latency Hiding&lt;/em&gt; 이다. 단계가 복잡하여 &lt;em&gt;Memory Latency&lt;/em&gt; 가 꽤나 긴편인데, GPU 에서는 이 &lt;em&gt;Latency&lt;/em&gt; 를 감출 방법이 없다. 다행히 사전에 루프를 돌면서 &lt;em&gt;G-Buffer&lt;/em&gt; 좌표를 계산하여 &lt;em&gt;Latency Hiding&lt;/em&gt; 이 가능하다고 한다. 이는 5 ~ 15% 성능 향상을 보였다고 한다.&lt;/p&gt;

&lt;p&gt;시스템 구현에 대한 디테일한 사항은 여기까지가 끝이다.&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;em&gt;Transparency Geometry&lt;/em&gt; 를 처리하는 방법에 대해서 써보겠다. 이 기법의 &lt;em&gt;per-pixel&lt;/em&gt; 테스트는 &lt;em&gt;Visibility Mask Buffer&lt;/em&gt; 에 결과가 저장된다. &lt;em&gt;Visibility Mask Buffer&lt;/em&gt; 의 효율적인 사용을 위해 항상 각 픽셀의 여러개의 32bit 데이터를 저장해준다고 한다. 이정도의 크기라면 단지 &lt;em&gt;Visibility&lt;/em&gt; 만을 사용하는게 아니라 &lt;em&gt;Opacity&lt;/em&gt; 또한 저장이 가능하다. 통상적인 가시성을 위한 투명 오브젝트의 처리 방법은 &lt;em&gt;Alpha to Coverage&lt;/em&gt;&lt;sup id=&quot;fnref:C3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C3&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; 를 쓴다고 한다. 그리고 여기에서도 비슷한 방법을 사용할 수 있다고한다.&lt;/p&gt;

&lt;p&gt;처음에는 &lt;em&gt;Coverage&lt;/em&gt; 를 계산하기 위해 &lt;em&gt;Visibility Test&lt;/em&gt; 를 해준다. 그리고 해당 알파가 저장된 텍스쳐를 참조하여 투명도를 가져오고, 해당 투명도를 사용하여 &lt;em&gt;Alpha to Coverage&lt;/em&gt; 를 실행하여 투명도 마스크를 얻는다. 이를 비트 AND 연산으로 합쳐서 &lt;em&gt;Coverage&lt;/em&gt; 를 &lt;em&gt;Visibility Buffer&lt;/em&gt; 에 저장한다.&lt;/p&gt;

&lt;p&gt;이 기법에서 알파 데이터를 처리하는 방법은 두가지로 나뉜다. 적은 비용으로 &lt;em&gt;Aliasing&lt;/em&gt; 을 생기게 하는 방법과 높은 비용으로 완벽하게 구현하는 방법으로 나뉜다. 적은 비용의 방식은 &lt;em&gt;Alpha&lt;/em&gt; 텍스쳐의 값을 &lt;em&gt;IZB Node&lt;/em&gt; 를 순회하기 전에 가져와서 계산하는 방식이다. &lt;em&gt;Light-Space Texel&lt;/em&gt; 을 기준으로 계산하므로 &lt;em&gt;Aliasing&lt;/em&gt; 이 생길 것으롸 예상된다. 하지만 이 논문의 저자는 구현물을 이 방식으로 구현했다고 한다. 나머지 한개의 방식은 &lt;em&gt;IZB Node&lt;/em&gt; 를 하나하나 순회하면서 &lt;em&gt;Alpha&lt;/em&gt; 텍스쳐의 값을 가져와 계산하는 것이다. 이는 일반적으로 생각되는 텍스쳐 샘플링의 부하와 &lt;em&gt;Varing&lt;/em&gt; 부하를 생기게 한다. 이는 꽤나 큰 비용이라고 한다.&lt;/p&gt;

&lt;p&gt;여기까지가 끝이다. 논문에 그 다음 내용들은 전부 퍼포먼스들의 분석밖에 없다. 다음으로 쓸 내용은 &lt;em&gt;HFTS&lt;/em&gt; 에 대한 내용이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/sample-distribution-shadow-maps&quot;&gt;Intel Developer Zone : Sample Distribution Shadow Maps&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:C2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;명시적이란 뜻은 바로 넣어서 계산할 수 있는 절대적인 위치의 텍셀 인덱스를 뜻한다. &lt;a href=&quot;#fnref:C2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:C1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;여기서의 동기화는 &lt;em&gt;atomic&lt;/em&gt; 의 개념을 말한다. 성능상의 단점은 다른 쓰레드에서 선점하는 경우에는 기다리는 것이다. &lt;a href=&quot;#fnref:C1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt; &lt;a href=&quot;#fnref:C1:1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:P1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;이 블로그에서 &lt;em&gt;Cascaded Shadow Mapping&lt;/em&gt; 에 대한 내용을 다루었었다. &lt;a href=&quot;/2017/12/17/cascaded-shadow-mapping&quot;&gt;여기&lt;/a&gt;에서 볼 수 있다. &lt;a href=&quot;#fnref:P1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:C3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://medium.com/@bgolus/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f&quot;&gt;https://medium.com/@bgolus/anti-aliased-alpha-test-the-esoteric-alpha-to-coverage-8b177335ae4f&lt;/a&gt; &lt;a href=&quot;#fnref:C3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="shader" />
      
        <category term="shadow" />
      
        <category term="rendering" />
      
        <category term="fts" />
      

      

      
        <summary type="html">frustum Traced Shadow with Irregular Z-Buffer 1 에서 포괄적인 전체 시스템과 복잡도에 대하여 알아보았다. 이번 글에서는 시스템 구현에 관한 디테일한 사항들을 알아볼 것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Frustum Traced Shadow With Irrelgular Z Buffer 1</title>
      
      <link href="https://suhyeokkim.github.io/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-1" rel="alternate" type="text/html" title="Frustum Traced Shadow With Irrelgular Z Buffer 1" />
      <published>2018-01-13T00:00:00+00:00</published>
      <updated>2018-01-13T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-1</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-1">&lt;p&gt;&lt;a href=&quot;/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-0&quot;&gt;frustum Traced Shadow with Irregular Z-Buffer 0&lt;/a&gt; 에서 기법의 아이디어를 둘러봄으러써 대강 이 알고리즘이 무엇인지 살펴보았다. 이번 글에서는 논문에 수록된 포괄적인 전체 시스템과 복잡도에 대하여 알아볼 것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3&gt;전체 시스템&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-0&quot;&gt;이전 글&lt;/a&gt;에서 두가지 단계에 대해서 자세한 설명을 했었다. &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 를 생성하고 &lt;em&gt;Visibility Test&lt;/em&gt; 를 하는 것이였다. 실제 구현된 단계는 총 6개의 단계로 이루어진다고 한다.&lt;/p&gt;

&lt;p&gt;첫번째로는 &lt;em&gt;Eye-Space Z-Prepass&lt;/em&gt; 를 해준다. 요즘의 엔진들이나 큰 규모가 아닌 게임이더라도 &lt;em&gt;Z-Prepass&lt;/em&gt;&lt;sup id=&quot;fnref:L1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:L1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 는 거의 대부분 해준다. &lt;em&gt;Geometry Pass&lt;/em&gt; 가 두번 걸리기는 하지만 &lt;em&gt;Fill Rate&lt;/em&gt; 의 부하가 &lt;em&gt;Geometry Pass&lt;/em&gt; 의 부하보다 많이 커서 그런 듯하다. 중요한건 단순히 언급한 &lt;em&gt;Eye-Space Z-Prepass&lt;/em&gt; 를 뜻하는게 아니다. 이전에 언급한 &lt;em&gt;μQuad&lt;/em&gt; 의 빠른 계산을 위해 &lt;em&gt;G-Buffer&lt;/em&gt; 에 3개의 실수 값들을 넣는다. 이 3개의 실수는 실제 그려지는 카메라의 위치와 &lt;em&gt;Tangent Plane&lt;/em&gt; 의 4개의 코너중에 3개의 거리를 나타낸다. 이는 &lt;em&gt;μQuad&lt;/em&gt; 를 다시 계산하기에 충분하다고 한다.&lt;/p&gt;

&lt;p&gt;이 방법은 &lt;em&gt;Visibility Test&lt;/em&gt; 의 속도를 빠르게 하는데 도움이 되지만, 당연히 &lt;em&gt;G-Buffer&lt;/em&gt; 의 공간이 부족한 경우에는 쓰지 못한다. AAA 급의 게임들은 &lt;em&gt;G-Buffer&lt;/em&gt; 를 bit 단위로 최대한 아껴쓰기 경우가 많기 때문에 이와 같은 상황이 일어날 수도 있다. 이런 경우에는 명시적으로 &lt;em&gt;Visibility Test&lt;/em&gt; 를 할때 &lt;em&gt;μQuad&lt;/em&gt; 를 계산한다고 한다. 아래 그림은 2009년에 발매된 &lt;em&gt;KillZone 2&lt;/em&gt; 의 &lt;em&gt;G-Buffer&lt;/em&gt; 사용을 나타내는 PT의 한 부분이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/killzone2_g-buffer.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;https://www.slideshare.net/guerrillagames/deferred-rendering-in-killzone-2-9691589&quot;&gt;Deferred Rendering in Killzone 2&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;두번째로는 씬의 경계를 설정해주는 것이다. &lt;em&gt;Shadow Mapping&lt;/em&gt; 에서 &lt;em&gt;Light-Space Projection&lt;/em&gt; 행렬은 씬에 딱 맞게 해주어야 한다.&lt;sup id=&quot;fnref:C1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C1&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 딱 맞지 않는 경우에는 &lt;em&gt;IZB&lt;/em&gt; 에 쓸모없는 텍셀을 생기게 하기 때문이다. 그래서 &lt;em&gt;Light-Space Projection&lt;/em&gt; 행렬을 계산하기 위해 &lt;em&gt;Compute Shader&lt;/em&gt; 와 &lt;em&gt;Z-Buffer&lt;/em&gt; 를 사용하여 &lt;em&gt;Bounding Box&lt;/em&gt; 를 계산한다. 이 계산은 화면의 해상도에 따라서 달라진다. 하지만 논문의 저자는 이 비용이 병목의 큰 원인이 아니기 때문에 특별한 해결 방법을 제시하지는 않는다.&lt;/p&gt;

&lt;p&gt;세번째는 &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 를 만드는 것이다. 이전 글에서 &lt;em&gt;IZB&lt;/em&gt; 에 대한 대략적인 아이디어는 언급했었다. 더 디테일하게 이를 말해보면, 우선 &lt;em&gt;Eye-Space Z Buffer&lt;/em&gt; 를 참조해 &lt;em&gt;Light-Space&lt;/em&gt; 로 변환한 후에 &lt;em&gt;Light-Space A-Buffer&lt;/em&gt; 의 텍셀의 &lt;em&gt;Linked-List&lt;/em&gt; 에 넣는다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;IZB&lt;/em&gt; 의 발상은 &lt;em&gt;Eye-Space&lt;/em&gt; 의 픽셀과 &lt;em&gt;Light-Space&lt;/em&gt; 의 텍셀이 1:1 로 매칭되지 않고 하나의 텍셀이 참조당하는 횟수가 1을 넘을때 &lt;em&gt;allasing&lt;/em&gt; 이 발생하는 것에서 시작되었다. 그래서 여기서 구현된 &lt;em&gt;IZB&lt;/em&gt; 는 텍셀에 &lt;em&gt;Linked-List&lt;/em&gt; 의 개념을 도입하여 보다 정확히 계산할 수 있게 하였다.&lt;/p&gt;

&lt;p&gt;아래 그림은 &lt;em&gt;IZB&lt;/em&gt; 의 데이터를 나타낸다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_depth_length_cull.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;왼쪽의 그림은 일반적인 &lt;em&gt;Shadow Map&lt;/em&gt; 을 나타내고, 중간의 그림은 &lt;em&gt;Linked-List&lt;/em&gt; 의 크기를 나타낸다. 흰색은 &lt;em&gt;Linked-List&lt;/em&gt; 의 크기가 0인 텍셀을 나타내고, 검은색에 가까워질수록 &lt;em&gt;Linked-List&lt;/em&gt; 의 크기가 점점 커지는 것을 나타낸다. 오른쪽의 그림은 필요없는 부분을 0으로 나타내고, 나머지 부분은 0 이상의 숫자를 나타내는 방식이다. 이는 아래에서 언급할 &lt;em&gt;Light-Space Culling Prepass&lt;/em&gt; 에서 쓰인다.&lt;/p&gt;

&lt;p&gt;픽셀별로 여러개의 가시성(가려진 정도)를 나타내는 픽셀은 여러개의 &lt;em&gt;IZB Node&lt;/em&gt; 를 필요로 한다. 일반적인 &lt;em&gt;Shadow Map&lt;/em&gt; 과는 다르게 &lt;em&gt;μQuad&lt;/em&gt; 는 다른 &lt;em&gt;Light-Space Texel&lt;/em&gt; 에 &lt;em&gt;Projection&lt;/em&gt; 이 가능하다.&lt;/p&gt;

&lt;p&gt;대충 생각해보면, &lt;em&gt;N&lt;/em&gt; 개의 픽셀별 쉐도우가 필요하면, &lt;em&gt;N&lt;/em&gt; 개의 &lt;em&gt;IZB Node&lt;/em&gt; 가 필요하다. 하지만 쓸데없는 데이터를(&lt;em&gt;Geometry&lt;/em&gt; 가 없는 경우) 넣지 않을 수 있으므로 &lt;em&gt;M&lt;/em&gt; 개의 &lt;em&gt;Light-Space Texel&lt;/em&gt; 에 &lt;em&gt;μQuad&lt;/em&gt; 를 투영한다면, 우리는 min(&lt;em&gt;N&lt;/em&gt;, &lt;em&gt;M&lt;/em&gt;)개의 &lt;em&gt;IZB Node&lt;/em&gt; 가 필요하다고 알 수 있다.&lt;/p&gt;

&lt;p&gt;아래 그림은 &lt;em&gt;IZB&lt;/em&gt; 를 사용하는 디테일한 구조를 나타낸다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_SimpleLayout.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;IZB&lt;/em&gt; 의 데이터 구조는 &lt;em&gt;Light-Space A-Buffer&lt;/em&gt; : &lt;em&gt;Eye-Space A-Buffer&lt;/em&gt; 의 &lt;em&gt;Node&lt;/em&gt; 를 찾아가기 위한 데이터, &lt;em&gt;Eye-Space A-Buffer&lt;/em&gt; : 리스트의 크기를 나타내는 버퍼와 같다. 출력되는 결과 : &lt;em&gt;Visibility Buffer&lt;/em&gt; 또한 따로 존재한다. 이게 최종적으로 그려질때 사용된다.&lt;/p&gt;

&lt;p&gt;다음은 &lt;em&gt;Light-Space Culling Prepass&lt;/em&gt; 다. &lt;em&gt;Visibility Test&lt;/em&gt; 를 위해 &lt;em&gt;Geometry&lt;/em&gt; 의 &lt;em&gt;Light-Space Conservative Rasterization&lt;/em&gt; 을 하게 되는데, GPU 에서 &lt;em&gt;Early-Z&lt;/em&gt; 기능을 제공한다면 쓸데없는 부분(아무것도 없는 텍셀, 가장 끝)을 컬링할 수 있다.&lt;/p&gt;

&lt;p&gt;하지만 &lt;em&gt;Early-Z&lt;/em&gt; 하드웨어를 사용할때는 &lt;em&gt;Light-Space Z-Buffer&lt;/em&gt; 를 필요로 한다. 이는 조금 당황스러운 상황을 만든다. 그래서 이 단계에서는 반드시 스텐실 버퍼를 만들어야 한다. 위에서 언급한 쓸데없는 부분(아무것도 없는 텍셀, 가장 끝)의 &lt;em&gt;Depth&lt;/em&gt; 를 0으로 세팅한다. 나머지는 0 이상의 숫자로 세팅한다.&lt;/p&gt;

&lt;p&gt;논문의 저자에 따르면, 엄청 큰 씬을 제외하고는 30% ~ 50% 의 성능 향상을 보였다고 한다. 이는 &lt;em&gt;Conservative Rasterization&lt;/em&gt; 으로 생성된 &lt;em&gt;Fragment&lt;/em&gt; 의 절대적인 숫자를 줄이고, 아무것도 없는 리스트를 스킵하면서 길이의 다양성을 없엔 효과다.&lt;/p&gt;

&lt;p&gt;컬링을 된 이후에는 픽셀별로 &lt;em&gt;Visibility Test&lt;/em&gt; 를 해준다. 이때 각각의 폴리곤들은 임의의 텍셀 집합을 가리기 된다. 그리고 각각의 텍셀이 가진 리스트를 순회하면서 &lt;em&gt;Visibility Test&lt;/em&gt; 를 한다. 이때 &lt;em&gt;atomic OR&lt;/em&gt; 을 사용하여 &lt;em&gt;Visibility Buffer&lt;/em&gt; 에 기록한다. 여기서 가장 병목이 되는 구간은 각각의 폴리곤이 임의의 서로다른 길이를 가진 텍셀의 리스트를 커버링하여 각각의 쓰레드별로 실행되는 시간이 제각각이 된다. 문제는 시간이 제각각인 경우, 가장 느린 시간을 소모한 쓰레드를 기준으로 &lt;em&gt;divergence&lt;/em&gt; 하여 각각의 텍셀의 리스트의 길이 중 가장 긴 길이의 시간으로 맞춰진다. 이는 최악의 상황을 유발할 수 있다.&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;em&gt;Visibility Buffer&lt;/em&gt; 를 사용하여 실제 오브젝트들을 렌더링하면 된다.&lt;/p&gt;

&lt;h3&gt;복잡도 계산&lt;/h3&gt;

&lt;p&gt;위에서도 언급햇다시피 이 기법은 &lt;em&gt;N&lt;/em&gt; 번의 &lt;em&gt;Visibility Test&lt;/em&gt; 한다면, 시간 복잡도는 O(&lt;em&gt;N&lt;/em&gt;) 과 같다. 여기서 &lt;em&gt;N&lt;/em&gt; 을 분해하면 다음과 같다. O(&lt;em&gt;La&lt;/em&gt; * &lt;em&gt;F&lt;/em&gt;), &lt;em&gt;F&lt;/em&gt; 는 &lt;em&gt;Light-Space&lt;/em&gt; 의 &lt;em&gt;Fragment&lt;/em&gt; 갯수이고, &lt;em&gt;La&lt;/em&gt; 는 &lt;em&gt;Linked-List&lt;/em&gt; 의 평균 길이다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;La&lt;/em&gt; 또한 다른 요소로 나타낼 수 있다. &lt;em&gt;Visibility Test&lt;/em&gt; 는 &lt;em&gt;Eye-Space&lt;/em&gt; 에서 한다. 그래서 &lt;em&gt;IZB Node&lt;/em&gt; 의 갯수는 &lt;em&gt;Eye-Space&lt;/em&gt; 의 해상도에 비례한다. 그리고 &lt;em&gt;Eye-Space&lt;/em&gt; 의 데이터는 전부 &lt;em&gt;Light-Space&lt;/em&gt; 에 기록되므로 &lt;em&gt;La&lt;/em&gt; ≈ (&lt;em&gt;Eye-Space Resolution&lt;/em&gt;) / (&lt;em&gt;Light-Space Resolution&lt;/em&gt;) 으로 계산될 수 있다.&lt;/p&gt;

&lt;p&gt;하지만 위에서 언급했던 것과 같이 &lt;em&gt;SIMT&lt;/em&gt; 기반의 GPU 에서는 O(&lt;em&gt;La&lt;/em&gt; * &lt;em&gt;F&lt;/em&gt;) 가 아닌 O(&lt;em&gt;Lm&lt;/em&gt; * &lt;em&gt;F&lt;/em&gt;) 이 될 수 밖에 없다. &lt;em&gt;Lm&lt;/em&gt; 은 &lt;em&gt;Linked-List&lt;/em&gt; 의 최대 길이다. 결국 퍼포먼스를 내기 위해선 &lt;em&gt;Lm&lt;/em&gt; 의 길이를 줄이는 것이 가장 중요하다는 것이 된다.&lt;/p&gt;

&lt;p&gt;이번 글에서는 전체 시스템과 복잡도에 대해서 알아보았다. 다음은 더 디테일한 구현 부분의 내용을과 &lt;em&gt;Alpha&lt;/em&gt; 처리에 대한 부분을 알아볼것이다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:L1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;https://ypchoi.gitbooks.io/rendering-techniques/content/z_prepass.html &lt;a href=&quot;#fnref:L1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:C1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;Cascaded Shadow Map 의 Crop Matrix 를 떠올리면 된다. &lt;a href=&quot;#fnref:C1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="shader" />
      
        <category term="shadow" />
      
        <category term="rendering" />
      
        <category term="fts" />
      

      

      
        <summary type="html">frustum Traced Shadow with Irregular Z-Buffer 0 에서 기법의 아이디어를 둘러봄으러써 대강 이 알고리즘이 무엇인지 살펴보았다. 이번 글에서는 논문에 수록된 포괄적인 전체 시스템과 복잡도에 대하여 알아볼 것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Frustum Traced Shadow With Irrelgular Z Buffer 0</title>
      
      <link href="https://suhyeokkim.github.io/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-0" rel="alternate" type="text/html" title="Frustum Traced Shadow With Irrelgular Z Buffer 0" />
      <published>2018-01-13T00:00:00+00:00</published>
      <updated>2018-01-13T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-0</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/01/13/frustum-traced-shadow-with-irrelgular-z-buffer-0">&lt;p&gt;&lt;a href=&quot;/2017/12/27/percentage-closer-soft-shadows&quot;&gt;Percentage-Closer Filtering Shadows&lt;/a&gt; 에서 &lt;em&gt;PCF&lt;/em&gt; 를 응용한 &lt;em&gt;PCSS&lt;/em&gt; 라는 &lt;em&gt;Soft Shadow&lt;/em&gt; 를 나타내는 기법에 대해서 알아보았다. 이번 글에서는 여태까지 알아본 것들에 비해 굉장히 최근에 나온 기법인 &lt;em&gt;frustum-Traced Shadow&lt;/em&gt; 에 대해서 알아볼것이다.&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;해당 기법은 2015년에 &lt;em&gt;Siggraph&lt;/em&gt;, &lt;em&gt;Interactive 3D&lt;/em&gt; 같은 컨퍼런스에서 발표되었으며, 현재 &lt;em&gt;Tom Clansy’s the Division&lt;/em&gt; 에 &lt;em&gt;PCSS&lt;/em&gt; 와 혼합된 형태(&lt;em&gt;Hybrid frustum Traced Shadow&lt;/em&gt;)로 적용되어 있다. &lt;em&gt;Frame Rate&lt;/em&gt; 에 조금 영향을 미쳐 대부분의 게이머들은 아직은 &lt;em&gt;HFTS&lt;/em&gt; 를 사용하지 않는듯 하다.(&lt;a href=&quot;https://www.reddit.com/r/nvidia/comments/49idz3/nvidia_hfts_the_division/&quot;&gt;Reddit : Nvidia HFTS (The Division)&lt;/a&gt;) 하지만 컴퓨팅 파워가 늘어나는 것을 가정한다면 앞으로 하이엔드 게임의 주 옵션이 될수도 있겠다.&lt;/p&gt;

&lt;p&gt;이 기법의 저자는 &lt;em&gt;Shadow Map&lt;/em&gt; 처럼 따로 붙은 기법없이 &lt;em&gt;Aliasing&lt;/em&gt; 이 없어야 했으며, 현세대의 GPU 와 해상도를 &lt;em&gt;Interactive&lt;/em&gt; 하게 지원하는 것이 완벽한 &lt;em&gt;Hard Shadow&lt;/em&gt; 를 목표로 &lt;em&gt;FTS&lt;/em&gt; 를 고안했다. 가장 많이 쓰이는 &lt;em&gt;Shadow Map&lt;/em&gt; 기법은 공간적(&lt;em&gt;Light-Space&lt;/em&gt; 와 &lt;em&gt;Clipping-Space&lt;/em&gt; 의 &lt;em&gt;Discretize&lt;/em&gt; 된 결과의 차이), 일시적인(필터링이 필요한 &lt;em&gt;Aliasing&lt;/em&gt;)인 문제들이 산재한다. 이는 이 기법을 고안한 시발점이였다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;FTS&lt;/em&gt; 의 이론적인 뿌리를 정하기 위해 저자는 여태까지 존재하는 여러 기법을 언급한다. 빛을 하나의 직선단위로 시뮬레이팅 하는 &lt;em&gt;Ray-Tracing&lt;/em&gt;, 볼륨을 통한 각각의 폴리곤들을 테스트 하는 &lt;em&gt;Shadow Volume&lt;/em&gt;, &lt;em&gt;Irregular Z-Buffers&lt;/em&gt; 를 언급했다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Shadow Volume&lt;/em&gt; 은 3차원상으로 &lt;em&gt;Shadow&lt;/em&gt; 가 생기는 부분을 정해 그 부분을 테스트해서 &lt;em&gt;Shadow&lt;/em&gt; 를 정해주는 기법이다. 이는 &lt;em&gt;Shadow Map&lt;/em&gt; 보다 픽셀 단위로 처리할 수 있지만, 여러 단점이 있다고 한다. 한번에 해결되는 깔끔한 방법이 없으며, 보이지 않는 부분도 처리하기 때문에 &lt;em&gt;Fill-Rate&lt;/em&gt; 를 많이 소모한다. 게다가 처리 자체가 간단하지 않기 때문에 개발자들도 많이 쓰는 기법이 아니라고 한다. 필자도 &lt;em&gt;Shadow Map&lt;/em&gt; 에 대한 자료는 굉장히 많이 봤지만 &lt;em&gt;Shadow Volume&lt;/em&gt; 은 거의 본적이 없다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/NVidia_ShadowVolume.jpg&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://developer.download.nvidia.com/books/HTML/gpugems/gpugems_ch09.html&quot;&gt;GPU Gems : Efficient Shadow Volume Rendering&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ray-Tracing&lt;/em&gt; 은 빛을 직선 단위로 시뮬레이팅을 하는 기법으로, 계산 비용 자체가 비싸기 때문에 하드웨어와 구조에 굉장히 의존적이라고 한다. 게임에서도 쓰일 수 있는 기법이 있었지만 다른 후보에 밀려났다. 바로 &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 다. 현대 GPU 의 &lt;em&gt;Geometry&lt;/em&gt; -&amp;gt; &lt;em&gt;Rasterize&lt;/em&gt; 구조에 맞춰 가장 걸맞는 방법이라고 한다. 자세한 설명은 아래에서 보자.&lt;/p&gt;

&lt;h3&gt;Key Idea&lt;/h3&gt;

&lt;p&gt;이 기법의 중요한 아이디어는 앞에서 소개한 &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 와 &lt;em&gt;frustum-Triangle Test&lt;/em&gt; 이 두가지다. &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 는 앞서 &lt;em&gt;Shadow Map&lt;/em&gt; 의 단점중에 공간적 괴리를 해결하는 데이터 구조이고, &lt;em&gt;frustum-Triangle Test&lt;/em&gt; 는 논문에서 한 말을 이용하면 &lt;em&gt;Sub-Pixel Accurate Pixel&lt;/em&gt; 을 구성하기 위한 시뮬레이션 테스트다. 이 두가지를 간단하게 살펴보자.&lt;/p&gt;

&lt;p&gt;첫번째로는 바로 위에서 언급했던 &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 다. 여기서의 &lt;em&gt;IZB&lt;/em&gt; 는 우리가 알던 일반적인 &lt;em&gt;Buffer&lt;/em&gt; 의 쓰임새와는 조금 다르게 쓰인다. 이 기법에서의 &lt;em&gt;IZB&lt;/em&gt; 는 일반적인 &lt;em&gt;Shadow Map&lt;/em&gt; 에서의 &lt;em&gt;Eye-Space&lt;/em&gt; 와 &lt;em&gt;Light-Space&lt;/em&gt; 의 괴리를 없에기 위해 &lt;em&gt;Light-Space&lt;/em&gt; 를 기준으로 &lt;em&gt;Depth&lt;/em&gt; 를 쭉 저장하는게 아닌, &lt;em&gt;Eye-Space&lt;/em&gt; 의 각각 픽셀별로 표현하는 물체에 영향을 미치는 광원을 방향으로 &lt;em&gt;Ray&lt;/em&gt; 를 쏜다. 그리고 &lt;em&gt;Light-Space&lt;/em&gt; 를 기준으로 만든 &lt;em&gt;Grid&lt;/em&gt; 버퍼에 &lt;em&gt;Ray&lt;/em&gt; 가 부딫치고, 부딫친 부분에서 가장 가까운 텍셀에 데이터를 저장한다. 위에서 설명한 &lt;em&gt;IZB&lt;/em&gt; 를 구성하는 방법에 대한 그림이 아래에 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_IZB.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;간단하게 이런식으로 &lt;em&gt;IZB&lt;/em&gt; 가 구성되는 것을 알 수 있다. 이제 &lt;em&gt;Geometry&lt;/em&gt; 와 비교하는 &lt;em&gt;Visibility Test&lt;/em&gt; 가 필요하다. 일반적인 &lt;em&gt;Shadow Mapping&lt;/em&gt; 의 &lt;em&gt;Visibility Test&lt;/em&gt; 와는 조금 다르다. 기존의 &lt;em&gt;Shadow Mapping&lt;/em&gt; 은 정점을 &lt;em&gt;Light-Space&lt;/em&gt; 로 바꾸어 &lt;em&gt;Z&lt;/em&gt; 값을 비교하여 &lt;em&gt;Visibility Test&lt;/em&gt; 를 한다. 하지만 이 기법에서의 &lt;em&gt;Visibility Test&lt;/em&gt; 는 다르다. 위에서 언급한 것과 같이 &lt;em&gt;IZB&lt;/em&gt; 를 만든다. 그 다음 &lt;em&gt;Occlluder Geometry&lt;/em&gt; 들을 &lt;em&gt;Light-Space&lt;/em&gt; 를 기준으로 &lt;em&gt;Conservative Rasterization&lt;/em&gt; 을 해준다.&lt;sup id=&quot;fnref:C1&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; 그렇게 나온 결과를 통해 &lt;em&gt;IZB&lt;/em&gt; 와 함께 &lt;em&gt;Visibility Test&lt;/em&gt; 를 한다. &lt;em&gt;Conservative Rasterization&lt;/em&gt; 의 결과는 거의 &lt;em&gt;Flag&lt;/em&gt; 로 사용될것으로 예측되고, &lt;em&gt;Eye-Space&lt;/em&gt; 픽셀의 그림자 계산은 복잡한 계산을 통해 구한다. 아래는 논문에 있던 &lt;em&gt;IZB&lt;/em&gt; 를 기준으로 쓰여진 수도 코드다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Step 1: Identify pixel locations we need to shadow
G(x, y) ← RenderGBufferFromEye()

// Step 2: Add pixels to our light-space IZB data structure
for pixel p ∈ G(x, y) do
    lsTexelp ← ShadowMapXform[ GetEyeSpacePos( p ) ]
    izbNodep ← CreateIZBNode[ p ]
    AddNodeToLightSpaceList[ lsTexelp, izbNodep ]
end for

// Step 3: Test each triangle with pixels in lists it covers
for tri t ∈ SceneTriangles do
    for frag f ∈ ConservateLightSpaceRaster( t ) do
        lsTexelf ← FragmentLocationInRasterGrid[ f ]
        for node n ∈ IZBNodeList( lsTexelf ) do
            p ← GetEyeSpacePixel( n )
            visMask[p] = visMask[p] | TestVisibility[ p, t ]
        end for
    end for
end for
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;다음은 &lt;em&gt;Visibility Test&lt;/em&gt; 다. 논문에서는 &lt;em&gt;frustum-Triangle Test&lt;/em&gt; 라고 부르는데, 이는 조금 복잡한 과정으로 구성된다. 아래 그림을 보면서 알아보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/fts_VisibilityTest.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;가장 처음에는 &lt;em&gt;μQuad&lt;/em&gt; 라는 것을 생성한다. &lt;em&gt;μQuad&lt;/em&gt; 는 &lt;em&gt;Tangent-Space&lt;/em&gt; 를 기준으로 설정하며 각 픽셀별로 생성한다. 위 그림에서는 중간 그림에 구 위에있는 평면을 뜻한다. 그 다음 가리는 &lt;em&gt;Geometry&lt;/em&gt; 의 폴리곤들의 각각의 &lt;em&gt;Edge&lt;/em&gt; 를 사용하여 &lt;em&gt;Shadow Plane&lt;/em&gt; 을 생성한다. 마지막으로 만들어진 &lt;em&gt;Shadow Plane&lt;/em&gt; 을 &lt;em&gt;μQuad&lt;/em&gt; 에 &lt;em&gt;Projection&lt;/em&gt; 한다. 이때 가지고 있던 &lt;em&gt;LUT&lt;/em&gt; 를 통해 가려짐을 계산한다. 그리고 다른 &lt;em&gt;Edge&lt;/em&gt; 들도 계속해서 누적시킨다.&lt;/p&gt;

&lt;p&gt;간단하게 &lt;em&gt;frustum-Triangle Test&lt;/em&gt; 의 단계에 대해 설명해보았다. 이제 각각의 과정 : &lt;em&gt;μQuad Construction&lt;/em&gt;, &lt;em&gt;Shadow Plane Construction&lt;/em&gt;, &lt;em&gt;Visibility Computation&lt;/em&gt; 에 대해 조금 더 자세히 써보겠다.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;μQuad&lt;/em&gt; 의 생성은 &lt;em&gt;Geometry&lt;/em&gt; 의 &lt;em&gt;Tangent-Space&lt;/em&gt; 를 기준으로 계산되는 것 빼고는 특이한 점이 없다. 하지만 생성되는 시기에 대해선 조금 특별한게 있다. 가시성을 계산할 때 생성할 수도 있지만 &lt;em&gt;G-Buffer&lt;/em&gt; 를 생성할 때 미리 계산하는 것이 더 효율적이라고 한다.&lt;/p&gt;

&lt;p&gt;가시성을 계산할 때 &lt;em&gt;ray-triangle intersection&lt;/em&gt; 을 계산하기 보다는 앖에서 언급한 각각의 폴리곤의 &lt;em&gt;Shadow Volume&lt;/em&gt; 을 각 점마다 계산한다고 한다. &lt;em&gt;Shadow Volume&lt;/em&gt; 은 그림자를 생성하는 &lt;em&gt;Occluder Triangle&lt;/em&gt; 을 기준으로 각각의 &lt;em&gt;Edge&lt;/em&gt; 에서 뻗어나오는 직사각형 면으로 구성된다. 아래 그림을 보면 쉽게 이해할 수 있다. 그리고 &lt;em&gt;μQuad&lt;/em&gt; 에서 샘플링한 각각의 점들을 기준으로 가시성을 계산한다면 한다면, 4번의 내적으로 가시성을 테스트할 수 있다는 것을 의미한다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;img src=&quot;/images/HFTS_frustumTracing.png&quot; alt=&quot;&quot; class=&quot;center-image&quot; /&gt;&lt;/p&gt;
&lt;center&gt;출처 : &lt;a href=&quot;http://developer.download.nvidia.com/gameworks/events/  GDC2016/jstory_hfts.pdf&quot;&gt;NVidia : Advanced Geometrically Correct Shadows for Modern Game Engines&lt;/a&gt;
&lt;/center&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;또한 그림자를 멀티샘플링 하기 위해서는 여기서 언급한 &lt;em&gt;Shadow Volume&lt;/em&gt; 의 &lt;em&gt;Shadow Plane&lt;/em&gt; 들을 이용한다고 한다.&lt;/p&gt;

&lt;p&gt;마지막으로 &lt;em&gt;Visibility Computation&lt;/em&gt; 이 남아있다. 이 부분의 대략적인 것은 위에서 언급했다. 자세한 계산방식을 말해보겠다. 위에서 언급한 &lt;em&gt;μQuad&lt;/em&gt; 와 &lt;em&gt;Shadow Plane&lt;/em&gt; 사용해서 해당 폴리곤들의 데이터 누적을 위해서는 &lt;em&gt;μQuad&lt;/em&gt; 에서 이산화된 &lt;em&gt;binary&lt;/em&gt; 샘플링이 필요하다. 논문의 저자는 32 번의 &lt;em&gt;Halton sampling&lt;/em&gt;&lt;sup id=&quot;fnref:C2&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; 을 사용했다고 한다.&lt;/p&gt;

&lt;p&gt;가시성을 계산하기 위해서는 &lt;em&gt;Shadow Plane&lt;/em&gt; 을 &lt;em&gt;μQuad&lt;/em&gt; 에 &lt;em&gt;Projection&lt;/em&gt; 해줘야 한다. 그러면 &lt;em&gt;μQuad&lt;/em&gt; 는 최대 3개의 &lt;em&gt;line&lt;/em&gt; 을 얻게 된다. 논문에서는 이 &lt;em&gt;line&lt;/em&gt; 을 &lt;em&gt;μQuad&lt;/em&gt; 를 기준으로 극좌표계&lt;sup id=&quot;fnref:C3&quot; role=&quot;doc-noteref&quot;&gt;&lt;a href=&quot;#fn:C3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; 데이터로 저장한다고 한다. 반지름과 각도가 5bit 크기로 저장된다. 해당 10bit 데이터를 사용하여 미리 계산된 테이블에서 32개의 이진 가시성 샘플을 가져온다. 결과와  bit 단위의 and 연산을 통해 &lt;em&gt;μQuad&lt;/em&gt; 의 가시성을 계산할 수 있다고 한다.&lt;/p&gt;

&lt;p&gt;해당 기법을 고안한 사람은 두가지의 아이디어 : &lt;em&gt;Irregular Z-Buffer&lt;/em&gt; 와 &lt;em&gt;frustum-Triangle Test&lt;/em&gt; 를 통해  &lt;em&gt;Sub-pixel Hard Shadow&lt;/em&gt; 의 이론을 만들었다. 하지만 이 아이디어들과 구현을 위한 노력의 차이는 꽤 큰듯하다. 논문을 보면 아이디어에 대한 텍스트보다 최적화를 위한 텍스트가 2배가 될정도로 많다. 다음 글에서는 논문에서 나온 전체 과정과 디테일한 구현 사항에 대해 적어보겠다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://cwyman.org/papers/tvcg16_ftizbExtended.pdf&quot;&gt;Frustum-Traced Irregular Z-Buffers: Fast, Sub-pixel Accurate Hard Shadows&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Irregular_Z-buffer&quot;&gt;Wikipedia : Irregular Z-Buffer&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://cwyman.org/videos/sig1657-chris-wyman-magic-behind-gameworks-hybrid-frustum-traced-shadows-hfts.mp4&quot;&gt;cywman.org : HFTS Presentation Video&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://developer.nvidia.com/content/dont-be-conservative-conservative-rasterization&quot;&gt;NVidia : Don’t be conservative with Conservative Rasterization&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://developer.download.nvidia.com/gameworks/events/GDC2016/jstory_hfts.pdf&quot;&gt;NVidia : Advanced Geometrically Correct Shadows for Modern Game Engines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:C1&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;일반적으로 오브젝트를 그리는 것과 다른 &lt;em&gt;Conservative Rasterization&lt;/em&gt; 을 해주는 이유는 일반적인 &lt;em&gt;Rasterization&lt;/em&gt; 은 픽셀의 반이상을 차지해야 해당 픽셀을 처리해준다. 하지만 정확한 &lt;em&gt;Visibility&lt;/em&gt; 를 계산하기 위해서는 폴리곤이 해당되는 모든 픽셀들을 처리해주어야 한다. &lt;em&gt;Conservative Rasterization&lt;/em&gt; 은 앞에서 말한바와 같이 모든 부분을 픽셀로 처리한다. &lt;em&gt;Conservative Rasterization&lt;/em&gt; 에 대한 자세한 정보는 &lt;a href=&quot;https://developer.nvidia.com/content/dont-be-conservative-conservative-rasterization&quot;&gt;NVidia : Don’t be conservative with Conservative Rasterization&lt;/a&gt; 에서 확인할 수 있다. &lt;a href=&quot;#fnref:C1&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:C2&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;몬테카를로 시뮬레이션과 같은 방식의 점을 생성하는 방식이다. 쉽게 말하면 랜덤하게 생성하는 것이라고 생각하면 된다. 자세한 정보는 &lt;a href=&quot;https://en.wikipedia.org/wiki/Halton_sequence&quot;&gt;Wikipedia : Halton sequence&lt;/a&gt; 에서 확인할 수 있다. &lt;a href=&quot;#fnref:C2&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:C3&quot; role=&quot;doc-endnote&quot;&gt;
      &lt;p&gt;여기서는 각도와 반지름(거리)를 사용하여 나나탠다. 극좌표계에 대한 자세한 정보는 &lt;a href=&quot;https://ko.wikipedia.org/wiki/%EA%B7%B9%EC%A2%8C%ED%91%9C%EA%B3%84&quot;&gt;위키피디아 : 극좌표계&lt;/a&gt; 에서 확인할 수 있다. &lt;a href=&quot;#fnref:C3&quot; class=&quot;reversefootnote&quot; role=&quot;doc-backlink&quot;&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="shader" />
      
        <category term="shadow" />
      
        <category term="rendering" />
      
        <category term="fts" />
      

      

      
        <summary type="html">Percentage-Closer Filtering Shadows 에서 PCF 를 응용한 PCSS 라는 Soft Shadow 를 나타내는 기법에 대해서 알아보았다. 이번 글에서는 여태까지 알아본 것들에 비해 굉장히 최근에 나온 기법인 frustum-Traced Shadow 에 대해서 알아볼것이다.</summary>
      

      
      
    </entry>
  
  
  
    <entry>
      
      <title type="html">Unity Scripted Importer</title>
      
      <link href="https://suhyeokkim.github.io/2018/01/11/unity-scripted-importer" rel="alternate" type="text/html" title="Unity Scripted Importer" />
      <published>2018-01-11T00:00:00+00:00</published>
      <updated>2018-01-11T00:00:00+00:00</updated>
      <id>https://suhyeokkim.github.io/2018/01/11/unity-scripted-importer</id>
      <content type="html" xml:base="https://suhyeokkim.github.io/2018/01/11/unity-scripted-importer">&lt;p&gt;Unity 의 에디터 시스템은 꽤나 유연하다. 이번 글에서는 &lt;em&gt;AssetImporter&lt;/em&gt; 에 대한 기능들에 대하여 알아볼 것이다.&lt;/p&gt;

&lt;p&gt;Unity 의 각각의 Asset 들은 확장자의 이름에 따라서 &lt;em&gt;AssetImporter&lt;/em&gt; 가 하나씩 만들어지고, 해당 &lt;em&gt;AssetImporter&lt;/em&gt; 에 따라서 &lt;em&gt;Post-Process&lt;/em&gt; 가 진행된다. 필자가 많이 봤던 &lt;em&gt;AssetImporter&lt;/em&gt; 는 &lt;a href=&quot;https://docs.unity3d.com/ScriptReference/TextureImporter.html&quot;&gt;&lt;em&gt;TextureImporter&lt;/em&gt;&lt;/a&gt; 와 &lt;a href=&quot;https://docs.unity3d.com/ScriptReference/ModelImporter.html&quot;&gt;&lt;em&gt;ModelImporter&lt;/em&gt;&lt;/a&gt; 가 있었다. 확인할 당시에는 당연히 &lt;em&gt;AssetImporter&lt;/em&gt; 를 커스터마이징 할 수 있겠다는 생각이 들어 찾아봤지만 전혀 없었다.(Unity 5 버젼을 사용할 때다.) 이렇게 시스템을 만들어 놓고 왜 없냐는 의문이 들었지만 이는 정말 할수있는게 없었기에 넘어갔었다.&lt;/p&gt;

&lt;p&gt;그런데 이번에 Unity 2018.1 베타가 릴리즈 되면서 SRP 를 살펴보던 도중 &lt;em&gt;Expremental&lt;/em&gt; 기능들 중에 &lt;a href=&quot;https://docs.unity3d.com/2018.1/Documentation/Manual/ScriptedImporters.html&quot;&gt;&lt;em&gt;ScriptedImporter&lt;/em&gt;&lt;/a&gt; 라는 기능이 있는 것을 발견했다.&lt;/p&gt;

&lt;p&gt;이 기능은 말그대로 예전의 내가 원하던 기능이였다. &lt;em&gt;AssetImporter&lt;/em&gt; 클래스와 다른점은 딱 한가지다. 가상 &lt;em&gt;OnImportAsset&lt;/em&gt; 메소드가 존재하는 것이다. 즉 &lt;em&gt;ScriptedImporter&lt;/em&gt; 를 상속하여 &lt;em&gt;OnImportAsset&lt;/em&gt; 를 구현하면 간단하게 에셋을 &lt;em&gt;Customize&lt;/em&gt; 할 수 있는 것이다. 또한 에디터 기능을 지원하는 &lt;a href=&quot;https://docs.unity3d.com/2018.1/Documentation/ScriptReference/Experimental.AssetImporters.ScriptedImporterEditor.html&quot;&gt;ScriptedImporterEditor &lt;/a&gt; 라는 클래스를 사용하면 에디터를 손쉽게 바꿀 수 있다. 자세한 사항은 글에서 언급된 링크를 통해 보면 된다.&lt;/p&gt;

&lt;h2&gt;참조&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/2018.1/Documentation/Manual/ScriptedImporters.html&quot;&gt;Unity Documentation : ScriptedImporter &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/2018.1/Documentation/ScriptReference/Experimental.AssetImporters.ScriptedImporter.html&quot;&gt;Unity Reference : ScriptedImporter&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.unity3d.com/2018.1/Documentation/ScriptReference/Experimental.AssetImporters.ScriptedImporterEditor.html&quot;&gt;Unity Reference : ScriptedImporterEditor &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content>

      
      
      
      
      

      
        <author>
            <name>Su-Hyeok Kim</name>
          
          
        </author>
      

      
        <category term="unity" />
      

      

      
        <summary type="html">Unity 의 에디터 시스템은 꽤나 유연하다. 이번 글에서는 AssetImporter 에 대한 기능들에 대하여 알아볼 것이다. Unity 의 각각의 Asset 들은 확장자의 이름에 따라서 AssetImporter 가 하나씩 만들어지고, 해당 AssetImporter 에 따라서 Post-Process 가 진행된다. 필자가 많이 봤던 AssetImporter 는 TextureImporter 와 ModelImporter 가 있었다. 확인할 당시에는 당연히 AssetImporter 를 커스터마이징 할 수 있겠다는 생각이 들어 찾아봤지만 전혀 없었다.(Unity 5 버젼을 사용할 때다.) 이렇게 시스템을 만들어 놓고 왜 없냐는 의문이 들었지만 이는 정말 할수있는게 없었기에 넘어갔었다. 그런데 이번에 Unity 2018.1 베타가 릴리즈 되면서 SRP 를 살펴보던 도중 Expremental 기능들 중에 ScriptedImporter 라는 기능이 있는 것을 발견했다. 이 기능은 말그대로 예전의 내가 원하던 기능이였다. AssetImporter 클래스와 다른점은 딱 한가지다. 가상 OnImportAsset 메소드가 존재하는 것이다. 즉 ScriptedImporter 를 상속하여 OnImportAsset 를 구현하면 간단하게 에셋을 Customize 할 수 있는 것이다. 또한 에디터 기능을 지원하는 ScriptedImporterEditor 라는 클래스를 사용하면 에디터를 손쉽게 바꿀 수 있다. 자세한 사항은 글에서 언급된 링크를 통해 보면 된다. 참조 Unity Documentation : ScriptedImporter Unity Reference : ScriptedImporter Unity Reference : ScriptedImporterEditor</summary>
      

      
      
    </entry>
  
  
</feed>
